{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/ben/.cache/kagglehub/datasets/bestwater/wikitext-2-v1/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"bestwater/wikitext-2-v1\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**THEN MOVE THE FILE DIRECTORY TO THIS DIRECTORY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(2)\n",
    "np.random.seed(2)\n",
    "torch.manual_seed(2)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WikiText2 corpus paths\n",
    "corpus_path = './wikitext-2'\n",
    "train_path = os.path.join(corpus_path, 'wiki.train.tokens')\n",
    "valid_path = os.path.join(corpus_path, 'wiki.valid.tokens')\n",
    "test_path = os.path.join(corpus_path, 'wiki.test.tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "embed_dim = 100\n",
    "hidden_dim = 256\n",
    "dropout_prob = 0.5\n",
    "num_epochs = 20\n",
    "batch_size = 32\n",
    "seq_length = 29  # Number of unrolled time steps\n",
    "learning_rate = 0.001\n",
    "vocab_size = 10000  # Reduced vocabulary size\n",
    "unk_threshold = 5  # Frequency threshold for unknown tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(path):\n",
    "    \"\"\"Read corpus file and return list of whitespace-tokenized words\"\"\"\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read().replace('\\n', ' <eos> ')\n",
    "    return text.split(' ')\n",
    "\n",
    "def build_vocab(tokens, threshold=unk_threshold):\n",
    "    \"\"\"Build vocabulary from tokens with frequency threshold\"\"\"\n",
    "    counter = Counter(tokens)\n",
    "    # Sort tokens by frequency (descending)\n",
    "    sorted_tokens = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Create vocabulary: reserve 0 for padding, 1 for <unk>\n",
    "    vocab = {'<pad>': 0, '<unk>': 1, '<eos>': 2}\n",
    "    idx = 3\n",
    "    \n",
    "    # Add tokens that appear more than threshold times\n",
    "    for token, count in sorted_tokens:\n",
    "        if count >= threshold and idx < vocab_size:\n",
    "            if token and token != '<eos>':  # Skip empty tokens and already added special tokens\n",
    "                vocab[token] = idx\n",
    "                idx += 1\n",
    "        if idx >= vocab_size:\n",
    "            break\n",
    "    \n",
    "    return vocab\n",
    "\n",
    "def tokens_to_indices(tokens, vocab):\n",
    "    \"\"\"Convert tokens to indices using vocabulary\"\"\"\n",
    "    return [vocab.get(token, vocab['<unk>']) for token in tokens if token]\n",
    "\n",
    "def batchify(data, bsz):\n",
    "    \"\"\"Divide dataset into batches and arrange for back-propagation through time\"\"\"\n",
    "    # Work out how cleanly we can divide the dataset into bsz parts\n",
    "    nbatch = data.size(0) // bsz\n",
    "    # Trim off any extra elements that wouldn't cleanly fit\n",
    "    data = data[:nbatch * bsz]\n",
    "    # Evenly divide the data across the bsz batches\n",
    "    data = data.view(bsz, -1).t().contiguous()\n",
    "    return data.to(device)\n",
    "\n",
    "def get_batch(source, i, seq_length):\n",
    "    \"\"\"Get a batch for training\"\"\"\n",
    "    seq_len = min(seq_length, source.size(0) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, dropout_prob):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn = nn.RNN(embed_dim, hidden_dim, batch_first=False, dropout=dropout_prob)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.decoder = nn.Linear(hidden_dim, vocab_size)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        \"\"\"Initialize weights for better training\"\"\"\n",
    "        initrange = 0.1\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        \"\"\"Initialize hidden state\"\"\"\n",
    "        return torch.zeros(1, batch_size, self.hidden_dim).to(device)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        # x shape: (seq_len, batch_size)\n",
    "        emb = self.dropout(self.embedding(x))  # (seq_len, batch_size, embed_dim)\n",
    "        output, hidden = self.rnn(emb, hidden)  # output: (seq_len, batch_size, hidden_dim)\n",
    "        output = self.dropout(output)\n",
    "        decoded = self.decoder(output.view(-1, self.hidden_dim))  # (seq_len*batch_size, vocab_size)\n",
    "        return decoded, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, criterion, optimizer, seq_length):\n",
    "    \"\"\"Train model for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    \n",
    "    # Get total number of batches\n",
    "    num_batches = (train_data.size(0) - 1) // seq_length\n",
    "    \n",
    "    for batch, i in enumerate(range(0, train_data.size(0) - 1, seq_length)):\n",
    "        # Skip if we'd go out of bounds\n",
    "        if i > train_data.size(0) - 2:\n",
    "            continue\n",
    "            \n",
    "        data, targets = get_batch(train_data, i, seq_length)\n",
    "        \n",
    "        # Initialize hidden state for new batch\n",
    "        hidden = hidden.detach()\n",
    "        \n",
    "        # Forward pass\n",
    "        output, hidden = model(data, hidden)\n",
    "        loss = criterion(output, targets)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping to prevent exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if batch % 50 == 0 and batch > 0:\n",
    "            cur_loss = total_loss / 50\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f'| epoch {epoch:3d} | batch {batch:5d}/{num_batches:5d} | '\n",
    "                  f'ms/batch {elapsed * 1000 / 50:5.2f} | '\n",
    "                  f'loss {cur_loss:5.2f} | ppl {math.exp(cur_loss):8.2f}')\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "    \n",
    "def evaluate(model, eval_data, criterion, seq_length):\n",
    "    \"\"\"Evaluate the model\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    num_tokens = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, eval_data.size(0) - 1, seq_length):\n",
    "            # Skip if we'd go out of bounds\n",
    "            if i > eval_data.size(0) - 2:\n",
    "                continue\n",
    "                \n",
    "            data, targets = get_batch(eval_data, i, seq_length)\n",
    "            hidden = hidden.detach()\n",
    "            output, hidden = model(data, hidden)\n",
    "            \n",
    "            loss = criterion(output, targets)\n",
    "            total_loss += loss.item() * targets.size(0)\n",
    "            num_tokens += targets.size(0)\n",
    "    \n",
    "    # Calculate perplexity\n",
    "    avg_loss = total_loss / num_tokens if num_tokens > 0 else float('inf')\n",
    "    perplexity = math.exp(avg_loss)\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing corpus...\n",
      "Vocabulary size: 9999\n",
      "Warning: Found index 9999 but vocab size is 9999\n",
      "Fixing indices...\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Load and preprocess data\n",
    "    print(\"Loading and preprocessing corpus...\")\n",
    "    train_tokens = read_corpus(train_path)\n",
    "    valid_tokens = read_corpus(valid_path)\n",
    "    test_tokens = read_corpus(test_path)\n",
    "\n",
    "    # Build vocabulary from training tokens\n",
    "    vocab = build_vocab(train_tokens)\n",
    "    print(f\"Vocabulary size: {len(vocab)}\")\n",
    "\n",
    "    # Convert tokens to indices\n",
    "    train_indices = tokens_to_indices(train_tokens, vocab)\n",
    "    valid_indices = tokens_to_indices(valid_tokens, vocab)\n",
    "    test_indices = tokens_to_indices(test_tokens, vocab)\n",
    "\n",
    "    # Safety check: ensure all indices are valid\n",
    "    max_idx = max(train_indices + valid_indices + test_indices)\n",
    "    if max_idx >= len(vocab):\n",
    "        print(f\"Warning: Found index {max_idx} but vocab size is {len(vocab)}\")\n",
    "        print(\"Fixing indices...\")\n",
    "        train_indices = [min(idx, len(vocab) - 1) for idx in train_indices]\n",
    "        valid_indices = [min(idx, len(vocab) - 1) for idx in valid_indices]\n",
    "        test_indices = [min(idx, len(vocab) - 1) for idx in test_indices]\n",
    "\n",
    "    # Convert to tensors and batchify - use CPU first for safety\n",
    "    train_data = batchify(torch.tensor(train_indices, dtype=torch.long), batch_size)\n",
    "    valid_data = batchify(torch.tensor(valid_indices, dtype=torch.long), batch_size)\n",
    "    test_data = batchify(torch.tensor(test_indices, dtype=torch.long), batch_size)\n",
    "\n",
    "    # Initialize model\n",
    "    model = RNNModel(len(vocab), embed_dim, hidden_dim, dropout_prob).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "| epoch   1 | batch    50/ 2250 | ms/batch  5.32 | loss  7.18 | ppl  1312.70\n",
      "| epoch   1 | batch   100/ 2250 | ms/batch  4.73 | loss  6.37 | ppl   582.17\n",
      "| epoch   1 | batch   150/ 2250 | ms/batch  4.77 | loss  6.14 | ppl   466.26\n",
      "| epoch   1 | batch   200/ 2250 | ms/batch  4.73 | loss  5.99 | ppl   399.39\n",
      "| epoch   1 | batch   250/ 2250 | ms/batch  4.72 | loss  5.95 | ppl   384.58\n",
      "| epoch   1 | batch   300/ 2250 | ms/batch  4.72 | loss  5.95 | ppl   383.56\n",
      "| epoch   1 | batch   350/ 2250 | ms/batch  4.74 | loss  5.83 | ppl   341.99\n",
      "| epoch   1 | batch   400/ 2250 | ms/batch  4.72 | loss  5.80 | ppl   329.88\n",
      "| epoch   1 | batch   450/ 2250 | ms/batch  4.71 | loss  5.72 | ppl   303.80\n",
      "| epoch   1 | batch   500/ 2250 | ms/batch  4.71 | loss  5.69 | ppl   295.95\n",
      "| epoch   1 | batch   550/ 2250 | ms/batch  4.71 | loss  5.63 | ppl   277.63\n",
      "| epoch   1 | batch   600/ 2250 | ms/batch  4.71 | loss  5.60 | ppl   269.09\n",
      "| epoch   1 | batch   650/ 2250 | ms/batch  4.73 | loss  5.58 | ppl   266.04\n",
      "| epoch   1 | batch   700/ 2250 | ms/batch  4.93 | loss  5.61 | ppl   274.05\n",
      "| epoch   1 | batch   750/ 2250 | ms/batch  4.81 | loss  5.60 | ppl   270.61\n",
      "| epoch   1 | batch   800/ 2250 | ms/batch  4.72 | loss  5.63 | ppl   277.58\n",
      "| epoch   1 | batch   850/ 2250 | ms/batch  4.73 | loss  5.49 | ppl   241.22\n",
      "| epoch   1 | batch   900/ 2250 | ms/batch  4.76 | loss  5.54 | ppl   254.34\n",
      "| epoch   1 | batch   950/ 2250 | ms/batch  4.83 | loss  5.54 | ppl   255.77\n",
      "| epoch   1 | batch  1000/ 2250 | ms/batch  4.72 | loss  5.52 | ppl   250.86\n",
      "| epoch   1 | batch  1050/ 2250 | ms/batch  4.72 | loss  5.52 | ppl   249.41\n",
      "| epoch   1 | batch  1100/ 2250 | ms/batch  5.00 | loss  5.54 | ppl   255.08\n",
      "| epoch   1 | batch  1150/ 2250 | ms/batch  4.94 | loss  5.51 | ppl   248.22\n",
      "| epoch   1 | batch  1200/ 2250 | ms/batch  4.95 | loss  5.43 | ppl   227.45\n",
      "| epoch   1 | batch  1250/ 2250 | ms/batch  4.97 | loss  5.46 | ppl   234.49\n",
      "| epoch   1 | batch  1300/ 2250 | ms/batch  4.98 | loss  5.42 | ppl   226.95\n",
      "| epoch   1 | batch  1350/ 2250 | ms/batch  5.02 | loss  5.40 | ppl   222.22\n",
      "| epoch   1 | batch  1400/ 2250 | ms/batch  5.04 | loss  5.45 | ppl   233.01\n",
      "| epoch   1 | batch  1450/ 2250 | ms/batch  5.01 | loss  5.44 | ppl   229.67\n",
      "| epoch   1 | batch  1500/ 2250 | ms/batch  4.95 | loss  5.43 | ppl   228.99\n",
      "| epoch   1 | batch  1550/ 2250 | ms/batch  4.96 | loss  5.40 | ppl   221.54\n",
      "| epoch   1 | batch  1600/ 2250 | ms/batch  4.95 | loss  5.41 | ppl   222.72\n",
      "| epoch   1 | batch  1650/ 2250 | ms/batch  4.99 | loss  5.37 | ppl   214.17\n",
      "| epoch   1 | batch  1700/ 2250 | ms/batch  4.96 | loss  5.38 | ppl   217.67\n",
      "| epoch   1 | batch  1750/ 2250 | ms/batch  4.94 | loss  5.36 | ppl   211.91\n",
      "| epoch   1 | batch  1800/ 2250 | ms/batch  4.98 | loss  5.34 | ppl   207.73\n",
      "| epoch   1 | batch  1850/ 2250 | ms/batch  4.98 | loss  5.35 | ppl   210.37\n",
      "| epoch   1 | batch  1900/ 2250 | ms/batch  5.00 | loss  5.40 | ppl   221.19\n",
      "| epoch   1 | batch  1950/ 2250 | ms/batch  5.00 | loss  5.40 | ppl   222.48\n",
      "| epoch   1 | batch  2000/ 2250 | ms/batch  5.01 | loss  5.34 | ppl   209.38\n",
      "| epoch   1 | batch  2050/ 2250 | ms/batch  5.02 | loss  5.37 | ppl   214.99\n",
      "| epoch   1 | batch  2100/ 2250 | ms/batch  5.17 | loss  5.30 | ppl   200.32\n",
      "| epoch   1 | batch  2150/ 2250 | ms/batch  4.96 | loss  5.30 | ppl   199.83\n",
      "| epoch   1 | batch  2200/ 2250 | ms/batch  4.97 | loss  5.30 | ppl   199.92\n",
      "| epoch   1 | batch  2250/ 2250 | ms/batch  5.07 | loss  5.24 | ppl   188.51\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 13.98s | valid ppl   155.64\n",
      "-----------------------------------------------------------------------------------------\n",
      "New best model saved with perplexity:   155.64\n",
      "| epoch   2 | batch    50/ 2250 | ms/batch  5.08 | loss  5.33 | ppl   205.45\n",
      "| epoch   2 | batch   100/ 2250 | ms/batch  4.98 | loss  5.22 | ppl   184.14\n",
      "| epoch   2 | batch   150/ 2250 | ms/batch  4.97 | loss  5.20 | ppl   180.52\n",
      "| epoch   2 | batch   200/ 2250 | ms/batch  4.98 | loss  5.19 | ppl   178.79\n",
      "| epoch   2 | batch   250/ 2250 | ms/batch  4.99 | loss  5.20 | ppl   181.40\n",
      "| epoch   2 | batch   300/ 2250 | ms/batch  4.99 | loss  5.27 | ppl   194.53\n",
      "| epoch   2 | batch   350/ 2250 | ms/batch  4.90 | loss  5.20 | ppl   181.07\n",
      "| epoch   2 | batch   400/ 2250 | ms/batch  4.80 | loss  5.22 | ppl   184.08\n",
      "| epoch   2 | batch   450/ 2250 | ms/batch  4.78 | loss  5.16 | ppl   174.96\n",
      "| epoch   2 | batch   500/ 2250 | ms/batch  4.76 | loss  5.15 | ppl   172.05\n",
      "| epoch   2 | batch   550/ 2250 | ms/batch  4.77 | loss  5.14 | ppl   170.95\n",
      "| epoch   2 | batch   600/ 2250 | ms/batch  4.74 | loss  5.14 | ppl   170.80\n",
      "| epoch   2 | batch   650/ 2250 | ms/batch  4.78 | loss  5.17 | ppl   175.43\n",
      "| epoch   2 | batch   700/ 2250 | ms/batch  4.75 | loss  5.18 | ppl   177.47\n",
      "| epoch   2 | batch   750/ 2250 | ms/batch  4.77 | loss  5.16 | ppl   173.38\n",
      "| epoch   2 | batch   800/ 2250 | ms/batch  4.78 | loss  5.22 | ppl   184.06\n",
      "| epoch   2 | batch   850/ 2250 | ms/batch  4.97 | loss  5.12 | ppl   166.75\n",
      "| epoch   2 | batch   900/ 2250 | ms/batch  4.96 | loss  5.17 | ppl   175.86\n",
      "| epoch   2 | batch   950/ 2250 | ms/batch  5.04 | loss  5.18 | ppl   177.65\n",
      "| epoch   2 | batch  1000/ 2250 | ms/batch  4.97 | loss  5.16 | ppl   174.93\n",
      "| epoch   2 | batch  1050/ 2250 | ms/batch  5.01 | loss  5.17 | ppl   176.78\n",
      "| epoch   2 | batch  1100/ 2250 | ms/batch  5.01 | loss  5.20 | ppl   181.07\n",
      "| epoch   2 | batch  1150/ 2250 | ms/batch  4.84 | loss  5.20 | ppl   181.18\n",
      "| epoch   2 | batch  1200/ 2250 | ms/batch  4.78 | loss  5.12 | ppl   166.70\n",
      "| epoch   2 | batch  1250/ 2250 | ms/batch  4.78 | loss  5.15 | ppl   171.82\n",
      "| epoch   2 | batch  1300/ 2250 | ms/batch  4.77 | loss  5.14 | ppl   170.55\n",
      "| epoch   2 | batch  1350/ 2250 | ms/batch  4.77 | loss  5.13 | ppl   168.20\n",
      "| epoch   2 | batch  1400/ 2250 | ms/batch  4.73 | loss  5.17 | ppl   176.46\n",
      "| epoch   2 | batch  1450/ 2250 | ms/batch  4.74 | loss  5.17 | ppl   176.68\n",
      "| epoch   2 | batch  1500/ 2250 | ms/batch  4.74 | loss  5.16 | ppl   174.80\n",
      "| epoch   2 | batch  1550/ 2250 | ms/batch  4.72 | loss  5.09 | ppl   163.02\n",
      "| epoch   2 | batch  1600/ 2250 | ms/batch  4.94 | loss  5.11 | ppl   165.97\n",
      "| epoch   2 | batch  1650/ 2250 | ms/batch  5.00 | loss  5.09 | ppl   162.12\n",
      "| epoch   2 | batch  1700/ 2250 | ms/batch  5.01 | loss  5.10 | ppl   163.24\n",
      "| epoch   2 | batch  1750/ 2250 | ms/batch  5.08 | loss  5.08 | ppl   160.77\n",
      "| epoch   2 | batch  1800/ 2250 | ms/batch  5.01 | loss  5.07 | ppl   159.16\n",
      "| epoch   2 | batch  1850/ 2250 | ms/batch  4.98 | loss  5.08 | ppl   161.32\n",
      "| epoch   2 | batch  1900/ 2250 | ms/batch  4.99 | loss  5.13 | ppl   169.67\n",
      "| epoch   2 | batch  1950/ 2250 | ms/batch  5.25 | loss  5.16 | ppl   173.55\n",
      "| epoch   2 | batch  2000/ 2250 | ms/batch  5.04 | loss  5.10 | ppl   163.89\n",
      "| epoch   2 | batch  2050/ 2250 | ms/batch  5.08 | loss  5.12 | ppl   168.04\n",
      "| epoch   2 | batch  2100/ 2250 | ms/batch  4.96 | loss  5.08 | ppl   160.32\n",
      "| epoch   2 | batch  2150/ 2250 | ms/batch  4.85 | loss  5.08 | ppl   160.37\n",
      "| epoch   2 | batch  2200/ 2250 | ms/batch  4.96 | loss  5.09 | ppl   162.73\n",
      "| epoch   2 | batch  2250/ 2250 | ms/batch  4.75 | loss  5.06 | ppl   158.18\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 14.00s | valid ppl   132.61\n",
      "-----------------------------------------------------------------------------------------\n",
      "New best model saved with perplexity:   132.61\n",
      "| epoch   3 | batch    50/ 2250 | ms/batch  5.09 | loss  5.15 | ppl   172.61\n",
      "| epoch   3 | batch   100/ 2250 | ms/batch  5.17 | loss  5.02 | ppl   151.69\n",
      "| epoch   3 | batch   150/ 2250 | ms/batch  5.03 | loss  5.00 | ppl   148.22\n",
      "| epoch   3 | batch   200/ 2250 | ms/batch  5.03 | loss  5.01 | ppl   149.69\n",
      "| epoch   3 | batch   250/ 2250 | ms/batch  5.08 | loss  5.01 | ppl   149.88\n",
      "| epoch   3 | batch   300/ 2250 | ms/batch  5.03 | loss  5.08 | ppl   161.11\n",
      "| epoch   3 | batch   350/ 2250 | ms/batch  4.97 | loss  5.02 | ppl   151.37\n",
      "| epoch   3 | batch   400/ 2250 | ms/batch  5.01 | loss  5.04 | ppl   154.09\n",
      "| epoch   3 | batch   450/ 2250 | ms/batch  5.00 | loss  5.00 | ppl   149.10\n",
      "| epoch   3 | batch   500/ 2250 | ms/batch  5.20 | loss  5.00 | ppl   147.82\n",
      "| epoch   3 | batch   550/ 2250 | ms/batch  5.13 | loss  5.00 | ppl   147.81\n",
      "| epoch   3 | batch   600/ 2250 | ms/batch  4.98 | loss  4.99 | ppl   147.57\n",
      "| epoch   3 | batch   650/ 2250 | ms/batch  4.98 | loss  5.01 | ppl   149.45\n",
      "| epoch   3 | batch   700/ 2250 | ms/batch  5.09 | loss  5.02 | ppl   150.87\n",
      "| epoch   3 | batch   750/ 2250 | ms/batch  5.13 | loss  4.99 | ppl   147.00\n",
      "| epoch   3 | batch   800/ 2250 | ms/batch  5.21 | loss  5.05 | ppl   156.17\n",
      "| epoch   3 | batch   850/ 2250 | ms/batch  4.98 | loss  4.98 | ppl   145.04\n",
      "| epoch   3 | batch   900/ 2250 | ms/batch  5.00 | loss  5.03 | ppl   152.89\n",
      "| epoch   3 | batch   950/ 2250 | ms/batch  4.96 | loss  5.04 | ppl   154.07\n",
      "| epoch   3 | batch  1000/ 2250 | ms/batch  5.00 | loss  5.02 | ppl   151.14\n",
      "| epoch   3 | batch  1050/ 2250 | ms/batch  4.98 | loss  5.02 | ppl   151.31\n",
      "| epoch   3 | batch  1100/ 2250 | ms/batch  5.04 | loss  5.06 | ppl   157.08\n",
      "| epoch   3 | batch  1150/ 2250 | ms/batch  5.03 | loss  5.06 | ppl   157.71\n",
      "| epoch   3 | batch  1200/ 2250 | ms/batch  5.38 | loss  4.97 | ppl   143.84\n",
      "| epoch   3 | batch  1250/ 2250 | ms/batch  5.01 | loss  5.00 | ppl   148.65\n",
      "| epoch   3 | batch  1300/ 2250 | ms/batch  5.26 | loss  5.00 | ppl   148.37\n",
      "| epoch   3 | batch  1350/ 2250 | ms/batch  5.11 | loss  4.99 | ppl   146.65\n",
      "| epoch   3 | batch  1400/ 2250 | ms/batch  4.86 | loss  5.05 | ppl   156.75\n",
      "| epoch   3 | batch  1450/ 2250 | ms/batch  4.97 | loss  5.05 | ppl   155.80\n",
      "| epoch   3 | batch  1500/ 2250 | ms/batch  5.00 | loss  5.04 | ppl   155.08\n",
      "| epoch   3 | batch  1550/ 2250 | ms/batch  4.98 | loss  4.97 | ppl   144.52\n",
      "| epoch   3 | batch  1600/ 2250 | ms/batch  5.29 | loss  4.97 | ppl   143.45\n",
      "| epoch   3 | batch  1650/ 2250 | ms/batch  5.22 | loss  4.95 | ppl   140.79\n",
      "| epoch   3 | batch  1700/ 2250 | ms/batch  5.06 | loss  4.96 | ppl   141.92\n",
      "| epoch   3 | batch  1750/ 2250 | ms/batch  4.99 | loss  4.95 | ppl   141.73\n",
      "| epoch   3 | batch  1800/ 2250 | ms/batch  5.05 | loss  4.95 | ppl   141.63\n",
      "| epoch   3 | batch  1850/ 2250 | ms/batch  4.95 | loss  4.97 | ppl   143.94\n",
      "| epoch   3 | batch  1900/ 2250 | ms/batch  5.12 | loss  5.01 | ppl   150.27\n",
      "| epoch   3 | batch  1950/ 2250 | ms/batch  5.00 | loss  5.05 | ppl   155.50\n",
      "| epoch   3 | batch  2000/ 2250 | ms/batch  4.97 | loss  4.99 | ppl   146.96\n",
      "| epoch   3 | batch  2050/ 2250 | ms/batch  4.97 | loss  5.01 | ppl   149.23\n",
      "| epoch   3 | batch  2100/ 2250 | ms/batch  4.98 | loss  4.97 | ppl   144.03\n",
      "| epoch   3 | batch  2150/ 2250 | ms/batch  4.99 | loss  4.96 | ppl   142.64\n",
      "| epoch   3 | batch  2200/ 2250 | ms/batch  5.03 | loss  4.99 | ppl   146.97\n",
      "| epoch   3 | batch  2250/ 2250 | ms/batch  5.13 | loss  4.97 | ppl   143.87\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 14.34s | valid ppl   125.03\n",
      "-----------------------------------------------------------------------------------------\n",
      "New best model saved with perplexity:   125.03\n",
      "| epoch   4 | batch    50/ 2250 | ms/batch  5.57 | loss  5.04 | ppl   154.29\n",
      "| epoch   4 | batch   100/ 2250 | ms/batch  4.96 | loss  4.92 | ppl   136.88\n",
      "| epoch   4 | batch   150/ 2250 | ms/batch  4.95 | loss  4.90 | ppl   134.21\n",
      "| epoch   4 | batch   200/ 2250 | ms/batch  4.95 | loss  4.89 | ppl   133.14\n",
      "| epoch   4 | batch   250/ 2250 | ms/batch  4.97 | loss  4.90 | ppl   134.92\n",
      "| epoch   4 | batch   300/ 2250 | ms/batch  4.98 | loss  4.98 | ppl   145.92\n",
      "| epoch   4 | batch   350/ 2250 | ms/batch  4.99 | loss  4.92 | ppl   137.37\n",
      "| epoch   4 | batch   400/ 2250 | ms/batch  5.00 | loss  4.93 | ppl   138.16\n",
      "| epoch   4 | batch   450/ 2250 | ms/batch  5.13 | loss  4.90 | ppl   134.61\n",
      "| epoch   4 | batch   500/ 2250 | ms/batch  5.03 | loss  4.89 | ppl   133.11\n",
      "| epoch   4 | batch   550/ 2250 | ms/batch  5.03 | loss  4.91 | ppl   135.05\n",
      "| epoch   4 | batch   600/ 2250 | ms/batch  4.85 | loss  4.91 | ppl   135.88\n",
      "| epoch   4 | batch   650/ 2250 | ms/batch  4.84 | loss  4.91 | ppl   135.62\n",
      "| epoch   4 | batch   700/ 2250 | ms/batch  4.81 | loss  4.91 | ppl   136.13\n",
      "| epoch   4 | batch   750/ 2250 | ms/batch  4.79 | loss  4.89 | ppl   133.35\n",
      "| epoch   4 | batch   800/ 2250 | ms/batch  4.78 | loss  4.96 | ppl   142.89\n",
      "| epoch   4 | batch   850/ 2250 | ms/batch  4.79 | loss  4.91 | ppl   135.04\n",
      "| epoch   4 | batch   900/ 2250 | ms/batch  4.78 | loss  4.94 | ppl   139.71\n",
      "| epoch   4 | batch   950/ 2250 | ms/batch  4.75 | loss  4.94 | ppl   140.39\n",
      "| epoch   4 | batch  1000/ 2250 | ms/batch  4.74 | loss  4.93 | ppl   139.02\n",
      "| epoch   4 | batch  1050/ 2250 | ms/batch  4.73 | loss  4.95 | ppl   140.84\n",
      "| epoch   4 | batch  1100/ 2250 | ms/batch  4.75 | loss  4.96 | ppl   143.04\n",
      "| epoch   4 | batch  1150/ 2250 | ms/batch  4.92 | loss  4.99 | ppl   146.74\n",
      "| epoch   4 | batch  1200/ 2250 | ms/batch  5.04 | loss  4.89 | ppl   132.58\n",
      "| epoch   4 | batch  1250/ 2250 | ms/batch  4.98 | loss  4.91 | ppl   135.43\n",
      "| epoch   4 | batch  1300/ 2250 | ms/batch  5.12 | loss  4.92 | ppl   137.44\n",
      "| epoch   4 | batch  1350/ 2250 | ms/batch  5.02 | loss  4.93 | ppl   137.75\n",
      "| epoch   4 | batch  1400/ 2250 | ms/batch  5.00 | loss  4.97 | ppl   143.71\n",
      "| epoch   4 | batch  1450/ 2250 | ms/batch  5.01 | loss  4.97 | ppl   144.64\n",
      "| epoch   4 | batch  1500/ 2250 | ms/batch  4.96 | loss  4.98 | ppl   144.89\n",
      "| epoch   4 | batch  1550/ 2250 | ms/batch  4.76 | loss  4.90 | ppl   134.29\n",
      "| epoch   4 | batch  1600/ 2250 | ms/batch  4.80 | loss  4.89 | ppl   133.48\n",
      "| epoch   4 | batch  1650/ 2250 | ms/batch  4.80 | loss  4.87 | ppl   130.83\n",
      "| epoch   4 | batch  1700/ 2250 | ms/batch  4.77 | loss  4.87 | ppl   130.47\n",
      "| epoch   4 | batch  1750/ 2250 | ms/batch  4.97 | loss  4.88 | ppl   131.24\n",
      "| epoch   4 | batch  1800/ 2250 | ms/batch  4.95 | loss  4.88 | ppl   131.33\n",
      "| epoch   4 | batch  1850/ 2250 | ms/batch  5.00 | loss  4.90 | ppl   134.10\n",
      "| epoch   4 | batch  1900/ 2250 | ms/batch  5.01 | loss  4.94 | ppl   139.66\n",
      "| epoch   4 | batch  1950/ 2250 | ms/batch  5.01 | loss  4.97 | ppl   143.99\n",
      "| epoch   4 | batch  2000/ 2250 | ms/batch  5.04 | loss  4.92 | ppl   137.45\n",
      "| epoch   4 | batch  2050/ 2250 | ms/batch  5.04 | loss  4.93 | ppl   138.01\n",
      "| epoch   4 | batch  2100/ 2250 | ms/batch  5.02 | loss  4.90 | ppl   134.88\n",
      "| epoch   4 | batch  2150/ 2250 | ms/batch  5.04 | loss  4.89 | ppl   133.39\n",
      "| epoch   4 | batch  2200/ 2250 | ms/batch  5.05 | loss  4.94 | ppl   139.21\n",
      "| epoch   4 | batch  2250/ 2250 | ms/batch  5.14 | loss  4.90 | ppl   134.85\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 14.11s | valid ppl   119.42\n",
      "-----------------------------------------------------------------------------------------\n",
      "New best model saved with perplexity:   119.42\n",
      "| epoch   5 | batch    50/ 2250 | ms/batch  5.10 | loss  4.99 | ppl   146.75\n",
      "| epoch   5 | batch   100/ 2250 | ms/batch  4.73 | loss  4.85 | ppl   127.87\n",
      "| epoch   5 | batch   150/ 2250 | ms/batch  4.73 | loss  4.83 | ppl   125.26\n",
      "| epoch   5 | batch   200/ 2250 | ms/batch  4.73 | loss  4.82 | ppl   124.51\n",
      "| epoch   5 | batch   250/ 2250 | ms/batch  4.90 | loss  4.84 | ppl   127.06\n",
      "| epoch   5 | batch   300/ 2250 | ms/batch  5.02 | loss  4.91 | ppl   135.82\n",
      "| epoch   5 | batch   350/ 2250 | ms/batch  4.97 | loss  4.85 | ppl   127.26\n",
      "| epoch   5 | batch   400/ 2250 | ms/batch  4.99 | loss  4.86 | ppl   129.31\n",
      "| epoch   5 | batch   450/ 2250 | ms/batch  4.99 | loss  4.85 | ppl   127.85\n",
      "| epoch   5 | batch   500/ 2250 | ms/batch  4.85 | loss  4.83 | ppl   125.18\n",
      "| epoch   5 | batch   550/ 2250 | ms/batch  5.03 | loss  4.86 | ppl   128.65\n",
      "| epoch   5 | batch   600/ 2250 | ms/batch  4.86 | loss  4.85 | ppl   127.86\n",
      "| epoch   5 | batch   650/ 2250 | ms/batch  4.81 | loss  4.85 | ppl   127.95\n",
      "| epoch   5 | batch   700/ 2250 | ms/batch  4.78 | loss  4.86 | ppl   128.67\n",
      "| epoch   5 | batch   750/ 2250 | ms/batch  4.78 | loss  4.83 | ppl   124.93\n",
      "| epoch   5 | batch   800/ 2250 | ms/batch  4.76 | loss  4.89 | ppl   133.51\n",
      "| epoch   5 | batch   850/ 2250 | ms/batch  4.77 | loss  4.84 | ppl   126.65\n",
      "| epoch   5 | batch   900/ 2250 | ms/batch  4.76 | loss  4.88 | ppl   132.13\n",
      "| epoch   5 | batch   950/ 2250 | ms/batch  4.75 | loss  4.88 | ppl   132.14\n",
      "| epoch   5 | batch  1000/ 2250 | ms/batch  4.95 | loss  4.88 | ppl   131.13\n",
      "| epoch   5 | batch  1050/ 2250 | ms/batch  5.27 | loss  4.88 | ppl   131.19\n",
      "| epoch   5 | batch  1100/ 2250 | ms/batch  5.04 | loss  4.92 | ppl   136.86\n",
      "| epoch   5 | batch  1150/ 2250 | ms/batch  5.29 | loss  4.93 | ppl   137.80\n",
      "| epoch   5 | batch  1200/ 2250 | ms/batch  5.09 | loss  4.84 | ppl   126.66\n",
      "| epoch   5 | batch  1250/ 2250 | ms/batch  4.96 | loss  4.86 | ppl   129.29\n",
      "| epoch   5 | batch  1300/ 2250 | ms/batch  4.98 | loss  4.87 | ppl   130.29\n",
      "| epoch   5 | batch  1350/ 2250 | ms/batch  4.99 | loss  4.87 | ppl   130.30\n",
      "| epoch   5 | batch  1400/ 2250 | ms/batch  5.06 | loss  4.93 | ppl   137.89\n",
      "| epoch   5 | batch  1450/ 2250 | ms/batch  5.01 | loss  4.91 | ppl   135.56\n",
      "| epoch   5 | batch  1500/ 2250 | ms/batch  5.03 | loss  4.93 | ppl   138.14\n",
      "| epoch   5 | batch  1550/ 2250 | ms/batch  5.01 | loss  4.84 | ppl   127.06\n",
      "| epoch   5 | batch  1600/ 2250 | ms/batch  5.00 | loss  4.84 | ppl   126.62\n",
      "| epoch   5 | batch  1650/ 2250 | ms/batch  4.98 | loss  4.81 | ppl   122.88\n",
      "| epoch   5 | batch  1700/ 2250 | ms/batch  4.99 | loss  4.82 | ppl   123.56\n",
      "| epoch   5 | batch  1750/ 2250 | ms/batch  5.09 | loss  4.82 | ppl   123.92\n",
      "| epoch   5 | batch  1800/ 2250 | ms/batch  5.07 | loss  4.82 | ppl   124.17\n",
      "| epoch   5 | batch  1850/ 2250 | ms/batch  4.95 | loss  4.83 | ppl   124.90\n",
      "| epoch   5 | batch  1900/ 2250 | ms/batch  5.02 | loss  4.88 | ppl   130.98\n",
      "| epoch   5 | batch  1950/ 2250 | ms/batch  4.97 | loss  4.92 | ppl   137.17\n",
      "| epoch   5 | batch  2000/ 2250 | ms/batch  5.07 | loss  4.87 | ppl   130.10\n",
      "| epoch   5 | batch  2050/ 2250 | ms/batch  5.04 | loss  4.87 | ppl   129.99\n",
      "| epoch   5 | batch  2100/ 2250 | ms/batch  5.06 | loss  4.84 | ppl   126.18\n",
      "| epoch   5 | batch  2150/ 2250 | ms/batch  5.05 | loss  4.85 | ppl   127.72\n",
      "| epoch   5 | batch  2200/ 2250 | ms/batch  5.00 | loss  4.88 | ppl   131.97\n",
      "| epoch   5 | batch  2250/ 2250 | ms/batch  4.92 | loss  4.86 | ppl   129.32\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 14.15s | valid ppl   116.71\n",
      "-----------------------------------------------------------------------------------------\n",
      "New best model saved with perplexity:   116.71\n",
      "| epoch   6 | batch    50/ 2250 | ms/batch  5.08 | loss  4.95 | ppl   141.68\n",
      "| epoch   6 | batch   100/ 2250 | ms/batch  5.02 | loss  4.79 | ppl   120.56\n",
      "| epoch   6 | batch   150/ 2250 | ms/batch  4.98 | loss  4.78 | ppl   119.46\n",
      "| epoch   6 | batch   200/ 2250 | ms/batch  4.97 | loss  4.78 | ppl   119.44\n",
      "| epoch   6 | batch   250/ 2250 | ms/batch  5.02 | loss  4.80 | ppl   121.27\n",
      "| epoch   6 | batch   300/ 2250 | ms/batch  4.98 | loss  4.87 | ppl   129.71\n",
      "| epoch   6 | batch   350/ 2250 | ms/batch  5.01 | loss  4.80 | ppl   121.07\n",
      "| epoch   6 | batch   400/ 2250 | ms/batch  5.59 | loss  4.82 | ppl   123.52\n",
      "| epoch   6 | batch   450/ 2250 | ms/batch  5.17 | loss  4.80 | ppl   121.89\n",
      "| epoch   6 | batch   500/ 2250 | ms/batch  4.89 | loss  4.79 | ppl   120.32\n",
      "| epoch   6 | batch   550/ 2250 | ms/batch  4.98 | loss  4.81 | ppl   122.38\n",
      "| epoch   6 | batch   600/ 2250 | ms/batch  4.99 | loss  4.81 | ppl   122.86\n",
      "| epoch   6 | batch   650/ 2250 | ms/batch  5.00 | loss  4.81 | ppl   122.36\n",
      "| epoch   6 | batch   700/ 2250 | ms/batch  4.99 | loss  4.81 | ppl   122.20\n",
      "| epoch   6 | batch   750/ 2250 | ms/batch  5.08 | loss  4.77 | ppl   118.46\n",
      "| epoch   6 | batch   800/ 2250 | ms/batch  5.15 | loss  4.85 | ppl   128.20\n",
      "| epoch   6 | batch   850/ 2250 | ms/batch  5.02 | loss  4.79 | ppl   120.69\n",
      "| epoch   6 | batch   900/ 2250 | ms/batch  5.02 | loss  4.84 | ppl   126.88\n",
      "| epoch   6 | batch   950/ 2250 | ms/batch  5.21 | loss  4.83 | ppl   125.81\n",
      "| epoch   6 | batch  1000/ 2250 | ms/batch  4.99 | loss  4.83 | ppl   125.75\n",
      "| epoch   6 | batch  1050/ 2250 | ms/batch  5.05 | loss  4.83 | ppl   125.00\n",
      "| epoch   6 | batch  1100/ 2250 | ms/batch  4.98 | loss  4.86 | ppl   129.21\n",
      "| epoch   6 | batch  1150/ 2250 | ms/batch  5.00 | loss  4.89 | ppl   132.45\n",
      "| epoch   6 | batch  1200/ 2250 | ms/batch  5.01 | loss  4.80 | ppl   121.64\n",
      "| epoch   6 | batch  1250/ 2250 | ms/batch  5.13 | loss  4.81 | ppl   122.89\n",
      "| epoch   6 | batch  1300/ 2250 | ms/batch  4.97 | loss  4.82 | ppl   124.22\n",
      "| epoch   6 | batch  1350/ 2250 | ms/batch  5.36 | loss  4.84 | ppl   125.90\n",
      "| epoch   6 | batch  1400/ 2250 | ms/batch  4.99 | loss  4.89 | ppl   132.74\n",
      "| epoch   6 | batch  1450/ 2250 | ms/batch  4.96 | loss  4.88 | ppl   131.81\n",
      "| epoch   6 | batch  1500/ 2250 | ms/batch  4.98 | loss  4.88 | ppl   132.12\n",
      "| epoch   6 | batch  1550/ 2250 | ms/batch  4.98 | loss  4.79 | ppl   120.88\n",
      "| epoch   6 | batch  1600/ 2250 | ms/batch  5.03 | loss  4.79 | ppl   120.77\n",
      "| epoch   6 | batch  1650/ 2250 | ms/batch  5.04 | loss  4.76 | ppl   116.69\n",
      "| epoch   6 | batch  1700/ 2250 | ms/batch  5.03 | loss  4.77 | ppl   118.50\n",
      "| epoch   6 | batch  1750/ 2250 | ms/batch  5.04 | loss  4.79 | ppl   119.76\n",
      "| epoch   6 | batch  1800/ 2250 | ms/batch  5.06 | loss  4.78 | ppl   119.34\n",
      "| epoch   6 | batch  1850/ 2250 | ms/batch  5.17 | loss  4.80 | ppl   120.95\n",
      "| epoch   6 | batch  1900/ 2250 | ms/batch  5.03 | loss  4.83 | ppl   125.57\n",
      "| epoch   6 | batch  1950/ 2250 | ms/batch  5.01 | loss  4.88 | ppl   131.68\n",
      "| epoch   6 | batch  2000/ 2250 | ms/batch  5.07 | loss  4.84 | ppl   125.85\n",
      "| epoch   6 | batch  2050/ 2250 | ms/batch  5.02 | loss  4.83 | ppl   125.60\n",
      "| epoch   6 | batch  2100/ 2250 | ms/batch  5.14 | loss  4.81 | ppl   122.21\n",
      "| epoch   6 | batch  2150/ 2250 | ms/batch  4.81 | loss  4.82 | ppl   123.61\n",
      "| epoch   6 | batch  2200/ 2250 | ms/batch  4.78 | loss  4.85 | ppl   127.37\n",
      "| epoch   6 | batch  2250/ 2250 | ms/batch  4.74 | loss  4.83 | ppl   124.82\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 14.28s | valid ppl   113.25\n",
      "-----------------------------------------------------------------------------------------\n",
      "New best model saved with perplexity:   113.25\n",
      "| epoch   7 | batch    50/ 2250 | ms/batch  4.93 | loss  4.90 | ppl   134.53\n",
      "| epoch   7 | batch   100/ 2250 | ms/batch  4.76 | loss  4.76 | ppl   116.48\n",
      "| epoch   7 | batch   150/ 2250 | ms/batch  4.76 | loss  4.75 | ppl   115.03\n",
      "| epoch   7 | batch   200/ 2250 | ms/batch  4.76 | loss  4.74 | ppl   114.37\n",
      "| epoch   7 | batch   250/ 2250 | ms/batch  4.76 | loss  4.76 | ppl   116.88\n",
      "| epoch   7 | batch   300/ 2250 | ms/batch  4.74 | loss  4.84 | ppl   125.96\n",
      "| epoch   7 | batch   350/ 2250 | ms/batch  4.93 | loss  4.76 | ppl   116.27\n",
      "| epoch   7 | batch   400/ 2250 | ms/batch  4.76 | loss  4.79 | ppl   120.53\n",
      "| epoch   7 | batch   450/ 2250 | ms/batch  4.83 | loss  4.77 | ppl   118.36\n",
      "| epoch   7 | batch   500/ 2250 | ms/batch  4.80 | loss  4.76 | ppl   116.47\n",
      "| epoch   7 | batch   550/ 2250 | ms/batch  4.76 | loss  4.78 | ppl   119.34\n",
      "| epoch   7 | batch   600/ 2250 | ms/batch  4.77 | loss  4.77 | ppl   118.26\n",
      "| epoch   7 | batch   650/ 2250 | ms/batch  4.76 | loss  4.77 | ppl   117.97\n",
      "| epoch   7 | batch   700/ 2250 | ms/batch  4.75 | loss  4.77 | ppl   118.19\n",
      "| epoch   7 | batch   750/ 2250 | ms/batch  4.78 | loss  4.73 | ppl   113.79\n",
      "| epoch   7 | batch   800/ 2250 | ms/batch  4.75 | loss  4.82 | ppl   124.31\n",
      "| epoch   7 | batch   850/ 2250 | ms/batch  4.78 | loss  4.76 | ppl   116.73\n",
      "| epoch   7 | batch   900/ 2250 | ms/batch  4.87 | loss  4.81 | ppl   123.14\n",
      "| epoch   7 | batch   950/ 2250 | ms/batch  4.74 | loss  4.81 | ppl   122.46\n",
      "| epoch   7 | batch  1000/ 2250 | ms/batch  4.75 | loss  4.81 | ppl   122.38\n",
      "| epoch   7 | batch  1050/ 2250 | ms/batch  4.77 | loss  4.80 | ppl   121.85\n",
      "| epoch   7 | batch  1100/ 2250 | ms/batch  4.95 | loss  4.84 | ppl   125.92\n",
      "| epoch   7 | batch  1150/ 2250 | ms/batch  4.97 | loss  4.85 | ppl   127.71\n",
      "| epoch   7 | batch  1200/ 2250 | ms/batch  4.78 | loss  4.76 | ppl   116.75\n",
      "| epoch   7 | batch  1250/ 2250 | ms/batch  4.98 | loss  4.79 | ppl   120.35\n",
      "| epoch   7 | batch  1300/ 2250 | ms/batch  4.76 | loss  4.79 | ppl   120.67\n",
      "| epoch   7 | batch  1350/ 2250 | ms/batch  4.77 | loss  4.80 | ppl   121.63\n",
      "| epoch   7 | batch  1400/ 2250 | ms/batch  4.75 | loss  4.86 | ppl   129.03\n",
      "| epoch   7 | batch  1450/ 2250 | ms/batch  4.75 | loss  4.85 | ppl   128.37\n",
      "| epoch   7 | batch  1500/ 2250 | ms/batch  4.74 | loss  4.84 | ppl   126.83\n",
      "| epoch   7 | batch  1550/ 2250 | ms/batch  4.76 | loss  4.77 | ppl   117.77\n",
      "| epoch   7 | batch  1600/ 2250 | ms/batch  4.76 | loss  4.76 | ppl   116.49\n",
      "| epoch   7 | batch  1650/ 2250 | ms/batch  4.74 | loss  4.73 | ppl   113.75\n",
      "| epoch   7 | batch  1700/ 2250 | ms/batch  4.73 | loss  4.76 | ppl   116.23\n",
      "| epoch   7 | batch  1750/ 2250 | ms/batch  4.73 | loss  4.75 | ppl   115.38\n",
      "| epoch   7 | batch  1800/ 2250 | ms/batch  4.93 | loss  4.75 | ppl   115.33\n",
      "| epoch   7 | batch  1850/ 2250 | ms/batch  4.97 | loss  4.76 | ppl   117.21\n",
      "| epoch   7 | batch  1900/ 2250 | ms/batch  4.98 | loss  4.81 | ppl   123.22\n",
      "| epoch   7 | batch  1950/ 2250 | ms/batch  5.11 | loss  4.85 | ppl   128.35\n",
      "| epoch   7 | batch  2000/ 2250 | ms/batch  5.06 | loss  4.80 | ppl   122.10\n",
      "| epoch   7 | batch  2050/ 2250 | ms/batch  5.00 | loss  4.80 | ppl   122.07\n",
      "| epoch   7 | batch  2100/ 2250 | ms/batch  5.01 | loss  4.77 | ppl   118.50\n",
      "| epoch   7 | batch  2150/ 2250 | ms/batch  5.07 | loss  4.78 | ppl   119.20\n",
      "| epoch   7 | batch  2200/ 2250 | ms/batch  5.02 | loss  4.82 | ppl   123.70\n",
      "| epoch   7 | batch  2250/ 2250 | ms/batch  4.95 | loss  4.79 | ppl   120.24\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 13.87s | valid ppl   110.28\n",
      "-----------------------------------------------------------------------------------------\n",
      "New best model saved with perplexity:   110.28\n",
      "| epoch   8 | batch    50/ 2250 | ms/batch  4.91 | loss  4.87 | ppl   130.47\n",
      "| epoch   8 | batch   100/ 2250 | ms/batch  4.74 | loss  4.73 | ppl   112.74\n",
      "| epoch   8 | batch   150/ 2250 | ms/batch  4.74 | loss  4.72 | ppl   111.74\n",
      "| epoch   8 | batch   200/ 2250 | ms/batch  4.75 | loss  4.73 | ppl   113.14\n",
      "| epoch   8 | batch   250/ 2250 | ms/batch  4.86 | loss  4.73 | ppl   113.05\n",
      "| epoch   8 | batch   300/ 2250 | ms/batch  5.00 | loss  4.81 | ppl   122.89\n",
      "| epoch   8 | batch   350/ 2250 | ms/batch  4.98 | loss  4.74 | ppl   113.87\n",
      "| epoch   8 | batch   400/ 2250 | ms/batch  4.98 | loss  4.75 | ppl   115.66\n",
      "| epoch   8 | batch   450/ 2250 | ms/batch  5.02 | loss  4.74 | ppl   114.81\n",
      "| epoch   8 | batch   500/ 2250 | ms/batch  5.03 | loss  4.73 | ppl   113.21\n",
      "| epoch   8 | batch   550/ 2250 | ms/batch  5.01 | loss  4.75 | ppl   115.17\n",
      "| epoch   8 | batch   600/ 2250 | ms/batch  5.03 | loss  4.76 | ppl   116.34\n",
      "| epoch   8 | batch   650/ 2250 | ms/batch  4.93 | loss  4.75 | ppl   115.22\n",
      "| epoch   8 | batch   700/ 2250 | ms/batch  4.87 | loss  4.75 | ppl   115.52\n",
      "| epoch   8 | batch   750/ 2250 | ms/batch  4.84 | loss  4.71 | ppl   111.06\n",
      "| epoch   8 | batch   800/ 2250 | ms/batch  4.86 | loss  4.81 | ppl   122.25\n",
      "| epoch   8 | batch   850/ 2250 | ms/batch  4.92 | loss  4.74 | ppl   114.45\n",
      "| epoch   8 | batch   900/ 2250 | ms/batch  4.82 | loss  4.79 | ppl   120.67\n",
      "| epoch   8 | batch   950/ 2250 | ms/batch  4.82 | loss  4.79 | ppl   120.43\n",
      "| epoch   8 | batch  1000/ 2250 | ms/batch  4.81 | loss  4.78 | ppl   118.75\n",
      "| epoch   8 | batch  1050/ 2250 | ms/batch  4.82 | loss  4.78 | ppl   119.12\n",
      "| epoch   8 | batch  1100/ 2250 | ms/batch  4.98 | loss  4.80 | ppl   121.82\n",
      "| epoch   8 | batch  1150/ 2250 | ms/batch  4.95 | loss  4.82 | ppl   124.43\n",
      "| epoch   8 | batch  1200/ 2250 | ms/batch  4.77 | loss  4.74 | ppl   114.06\n",
      "| epoch   8 | batch  1250/ 2250 | ms/batch  4.79 | loss  4.76 | ppl   116.44\n",
      "| epoch   8 | batch  1300/ 2250 | ms/batch  4.78 | loss  4.78 | ppl   118.73\n",
      "| epoch   8 | batch  1350/ 2250 | ms/batch  4.77 | loss  4.78 | ppl   118.81\n",
      "| epoch   8 | batch  1400/ 2250 | ms/batch  4.76 | loss  4.84 | ppl   126.16\n",
      "| epoch   8 | batch  1450/ 2250 | ms/batch  4.75 | loss  4.83 | ppl   125.63\n",
      "| epoch   8 | batch  1500/ 2250 | ms/batch  4.81 | loss  4.82 | ppl   124.09\n",
      "| epoch   8 | batch  1550/ 2250 | ms/batch  4.76 | loss  4.74 | ppl   113.89\n",
      "| epoch   8 | batch  1600/ 2250 | ms/batch  4.76 | loss  4.74 | ppl   114.25\n",
      "| epoch   8 | batch  1650/ 2250 | ms/batch  4.76 | loss  4.71 | ppl   110.86\n",
      "| epoch   8 | batch  1700/ 2250 | ms/batch  4.77 | loss  4.71 | ppl   111.04\n",
      "| epoch   8 | batch  1750/ 2250 | ms/batch  4.76 | loss  4.72 | ppl   112.71\n",
      "| epoch   8 | batch  1800/ 2250 | ms/batch  4.87 | loss  4.72 | ppl   112.35\n",
      "| epoch   8 | batch  1850/ 2250 | ms/batch  4.96 | loss  4.75 | ppl   115.41\n",
      "| epoch   8 | batch  1900/ 2250 | ms/batch  5.03 | loss  4.78 | ppl   119.22\n",
      "| epoch   8 | batch  1950/ 2250 | ms/batch  5.03 | loss  4.82 | ppl   124.51\n",
      "| epoch   8 | batch  2000/ 2250 | ms/batch  5.02 | loss  4.78 | ppl   119.07\n",
      "| epoch   8 | batch  2050/ 2250 | ms/batch  5.11 | loss  4.78 | ppl   118.69\n",
      "| epoch   8 | batch  2100/ 2250 | ms/batch  5.06 | loss  4.75 | ppl   115.32\n",
      "| epoch   8 | batch  2150/ 2250 | ms/batch  4.91 | loss  4.75 | ppl   115.52\n",
      "| epoch   8 | batch  2200/ 2250 | ms/batch  4.82 | loss  4.80 | ppl   121.01\n",
      "| epoch   8 | batch  2250/ 2250 | ms/batch  4.84 | loss  4.78 | ppl   118.79\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 13.96s | valid ppl   109.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "New best model saved with perplexity:   109.95\n",
      "| epoch   9 | batch    50/ 2250 | ms/batch  5.15 | loss  4.84 | ppl   126.38\n",
      "| epoch   9 | batch   100/ 2250 | ms/batch  4.98 | loss  4.70 | ppl   110.26\n",
      "| epoch   9 | batch   150/ 2250 | ms/batch  5.01 | loss  4.68 | ppl   108.31\n",
      "| epoch   9 | batch   200/ 2250 | ms/batch  4.90 | loss  4.70 | ppl   110.36\n",
      "| epoch   9 | batch   250/ 2250 | ms/batch  4.89 | loss  4.71 | ppl   110.54\n",
      "| epoch   9 | batch   300/ 2250 | ms/batch  4.87 | loss  4.79 | ppl   120.20\n",
      "| epoch   9 | batch   350/ 2250 | ms/batch  4.81 | loss  4.71 | ppl   110.94\n",
      "| epoch   9 | batch   400/ 2250 | ms/batch  4.76 | loss  4.73 | ppl   113.00\n",
      "| epoch   9 | batch   450/ 2250 | ms/batch  4.75 | loss  4.72 | ppl   112.52\n",
      "| epoch   9 | batch   500/ 2250 | ms/batch  4.77 | loss  4.71 | ppl   110.72\n",
      "| epoch   9 | batch   550/ 2250 | ms/batch  4.77 | loss  4.73 | ppl   112.89\n",
      "| epoch   9 | batch   600/ 2250 | ms/batch  4.91 | loss  4.73 | ppl   113.72\n",
      "| epoch   9 | batch   650/ 2250 | ms/batch  4.77 | loss  4.73 | ppl   112.94\n",
      "| epoch   9 | batch   700/ 2250 | ms/batch  4.80 | loss  4.75 | ppl   115.36\n",
      "| epoch   9 | batch   750/ 2250 | ms/batch  4.82 | loss  4.70 | ppl   109.61\n",
      "| epoch   9 | batch   800/ 2250 | ms/batch  4.83 | loss  4.77 | ppl   118.35\n",
      "| epoch   9 | batch   850/ 2250 | ms/batch  4.79 | loss  4.71 | ppl   111.40\n",
      "| epoch   9 | batch   900/ 2250 | ms/batch  4.77 | loss  4.76 | ppl   116.90\n",
      "| epoch   9 | batch   950/ 2250 | ms/batch  4.77 | loss  4.76 | ppl   116.22\n",
      "| epoch   9 | batch  1000/ 2250 | ms/batch  4.78 | loss  4.75 | ppl   115.98\n",
      "| epoch   9 | batch  1050/ 2250 | ms/batch  4.75 | loss  4.76 | ppl   116.43\n",
      "| epoch   9 | batch  1100/ 2250 | ms/batch  4.81 | loss  4.78 | ppl   119.69\n",
      "| epoch   9 | batch  1150/ 2250 | ms/batch  4.75 | loss  4.80 | ppl   121.97\n",
      "| epoch   9 | batch  1200/ 2250 | ms/batch  4.75 | loss  4.72 | ppl   112.35\n",
      "| epoch   9 | batch  1250/ 2250 | ms/batch  4.87 | loss  4.74 | ppl   113.88\n",
      "| epoch   9 | batch  1300/ 2250 | ms/batch  4.97 | loss  4.75 | ppl   115.15\n",
      "| epoch   9 | batch  1350/ 2250 | ms/batch  4.91 | loss  4.75 | ppl   115.92\n",
      "| epoch   9 | batch  1400/ 2250 | ms/batch  4.78 | loss  4.81 | ppl   122.20\n",
      "| epoch   9 | batch  1450/ 2250 | ms/batch  5.00 | loss  4.80 | ppl   121.90\n",
      "| epoch   9 | batch  1500/ 2250 | ms/batch  4.79 | loss  4.80 | ppl   121.36\n",
      "| epoch   9 | batch  1550/ 2250 | ms/batch  4.76 | loss  4.72 | ppl   111.95\n",
      "| epoch   9 | batch  1600/ 2250 | ms/batch  4.76 | loss  4.71 | ppl   110.77\n",
      "| epoch   9 | batch  1650/ 2250 | ms/batch  4.77 | loss  4.70 | ppl   109.53\n",
      "| epoch   9 | batch  1700/ 2250 | ms/batch  5.02 | loss  4.69 | ppl   109.39\n",
      "| epoch   9 | batch  1750/ 2250 | ms/batch  4.93 | loss  4.71 | ppl   110.98\n",
      "| epoch   9 | batch  1800/ 2250 | ms/batch  4.96 | loss  4.71 | ppl   111.18\n",
      "| epoch   9 | batch  1850/ 2250 | ms/batch  5.01 | loss  4.73 | ppl   113.30\n",
      "| epoch   9 | batch  1900/ 2250 | ms/batch  5.04 | loss  4.76 | ppl   116.90\n",
      "| epoch   9 | batch  1950/ 2250 | ms/batch  5.01 | loss  4.80 | ppl   121.79\n",
      "| epoch   9 | batch  2000/ 2250 | ms/batch  5.01 | loss  4.76 | ppl   116.24\n",
      "| epoch   9 | batch  2050/ 2250 | ms/batch  5.06 | loss  4.77 | ppl   117.39\n",
      "| epoch   9 | batch  2100/ 2250 | ms/batch  4.93 | loss  4.75 | ppl   115.17\n",
      "| epoch   9 | batch  2150/ 2250 | ms/batch  4.83 | loss  4.73 | ppl   112.96\n",
      "| epoch   9 | batch  2200/ 2250 | ms/batch  4.81 | loss  4.77 | ppl   118.32\n",
      "| epoch   9 | batch  2250/ 2250 | ms/batch  4.81 | loss  4.76 | ppl   116.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time: 13.91s | valid ppl   108.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "New best model saved with perplexity:   108.92\n",
      "| epoch  10 | batch    50/ 2250 | ms/batch  4.88 | loss  4.82 | ppl   124.19\n",
      "| epoch  10 | batch   100/ 2250 | ms/batch  4.77 | loss  4.68 | ppl   108.22\n",
      "| epoch  10 | batch   150/ 2250 | ms/batch  4.75 | loss  4.68 | ppl   107.77\n",
      "| epoch  10 | batch   200/ 2250 | ms/batch  4.76 | loss  4.68 | ppl   107.91\n",
      "| epoch  10 | batch   250/ 2250 | ms/batch  4.75 | loss  4.70 | ppl   110.13\n",
      "| epoch  10 | batch   300/ 2250 | ms/batch  4.78 | loss  4.77 | ppl   117.51\n",
      "| epoch  10 | batch   350/ 2250 | ms/batch  4.75 | loss  4.69 | ppl   109.14\n",
      "| epoch  10 | batch   400/ 2250 | ms/batch  4.74 | loss  4.71 | ppl   111.38\n",
      "| epoch  10 | batch   450/ 2250 | ms/batch  4.72 | loss  4.71 | ppl   110.58\n",
      "| epoch  10 | batch   500/ 2250 | ms/batch  4.76 | loss  4.69 | ppl   108.60\n",
      "| epoch  10 | batch   550/ 2250 | ms/batch  4.74 | loss  4.71 | ppl   111.13\n",
      "| epoch  10 | batch   600/ 2250 | ms/batch  4.77 | loss  4.72 | ppl   112.25\n",
      "| epoch  10 | batch   650/ 2250 | ms/batch  4.78 | loss  4.71 | ppl   110.66\n",
      "| epoch  10 | batch   700/ 2250 | ms/batch  4.78 | loss  4.72 | ppl   111.91\n",
      "| epoch  10 | batch   750/ 2250 | ms/batch  4.80 | loss  4.67 | ppl   106.61\n",
      "| epoch  10 | batch   800/ 2250 | ms/batch  4.76 | loss  4.76 | ppl   117.20\n",
      "| epoch  10 | batch   850/ 2250 | ms/batch  4.79 | loss  4.69 | ppl   109.33\n",
      "| epoch  10 | batch   900/ 2250 | ms/batch  4.96 | loss  4.74 | ppl   114.64\n",
      "| epoch  10 | batch   950/ 2250 | ms/batch  4.76 | loss  4.74 | ppl   114.05\n",
      "| epoch  10 | batch  1000/ 2250 | ms/batch  4.76 | loss  4.73 | ppl   113.34\n",
      "| epoch  10 | batch  1050/ 2250 | ms/batch  4.74 | loss  4.74 | ppl   114.50\n",
      "| epoch  10 | batch  1100/ 2250 | ms/batch  4.74 | loss  4.77 | ppl   117.43\n",
      "| epoch  10 | batch  1150/ 2250 | ms/batch  4.75 | loss  4.78 | ppl   119.67\n",
      "| epoch  10 | batch  1200/ 2250 | ms/batch  4.77 | loss  4.70 | ppl   109.83\n",
      "| epoch  10 | batch  1250/ 2250 | ms/batch  4.75 | loss  4.72 | ppl   112.27\n",
      "| epoch  10 | batch  1300/ 2250 | ms/batch  4.76 | loss  4.73 | ppl   113.49\n",
      "| epoch  10 | batch  1350/ 2250 | ms/batch  4.75 | loss  4.74 | ppl   114.17\n",
      "| epoch  10 | batch  1400/ 2250 | ms/batch  4.76 | loss  4.80 | ppl   121.86\n",
      "| epoch  10 | batch  1450/ 2250 | ms/batch  4.92 | loss  4.79 | ppl   120.30\n",
      "| epoch  10 | batch  1500/ 2250 | ms/batch  4.79 | loss  4.78 | ppl   119.66\n",
      "| epoch  10 | batch  1550/ 2250 | ms/batch  4.74 | loss  4.70 | ppl   110.04\n",
      "| epoch  10 | batch  1600/ 2250 | ms/batch  4.74 | loss  4.69 | ppl   108.65\n",
      "| epoch  10 | batch  1650/ 2250 | ms/batch  4.74 | loss  4.67 | ppl   106.35\n",
      "| epoch  10 | batch  1700/ 2250 | ms/batch  4.76 | loss  4.68 | ppl   107.63\n",
      "| epoch  10 | batch  1750/ 2250 | ms/batch  4.92 | loss  4.69 | ppl   108.69\n",
      "| epoch  10 | batch  1800/ 2250 | ms/batch  4.78 | loss  4.69 | ppl   109.08\n",
      "| epoch  10 | batch  1850/ 2250 | ms/batch  4.86 | loss  4.72 | ppl   112.07\n",
      "| epoch  10 | batch  1900/ 2250 | ms/batch  4.76 | loss  4.75 | ppl   115.74\n",
      "| epoch  10 | batch  1950/ 2250 | ms/batch  4.76 | loss  4.79 | ppl   120.22\n",
      "| epoch  10 | batch  2000/ 2250 | ms/batch  4.73 | loss  4.74 | ppl   114.79\n",
      "| epoch  10 | batch  2050/ 2250 | ms/batch  4.72 | loss  4.74 | ppl   114.21\n",
      "| epoch  10 | batch  2100/ 2250 | ms/batch  4.74 | loss  4.71 | ppl   111.41\n",
      "| epoch  10 | batch  2150/ 2250 | ms/batch  4.97 | loss  4.71 | ppl   111.17\n",
      "| epoch  10 | batch  2200/ 2250 | ms/batch  5.28 | loss  4.75 | ppl   115.51\n",
      "| epoch  10 | batch  2250/ 2250 | ms/batch  5.01 | loss  4.74 | ppl   113.88\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time: 13.74s | valid ppl   108.33\n",
      "-----------------------------------------------------------------------------------------\n",
      "New best model saved with perplexity:   108.33\n",
      "| epoch  11 | batch    50/ 2250 | ms/batch  4.90 | loss  4.81 | ppl   122.79\n",
      "| epoch  11 | batch   100/ 2250 | ms/batch  4.76 | loss  4.67 | ppl   107.16\n",
      "| epoch  11 | batch   150/ 2250 | ms/batch  4.94 | loss  4.66 | ppl   105.86\n",
      "| epoch  11 | batch   200/ 2250 | ms/batch  4.74 | loss  4.66 | ppl   105.65\n",
      "| epoch  11 | batch   250/ 2250 | ms/batch  4.97 | loss  4.67 | ppl   106.36\n",
      "| epoch  11 | batch   300/ 2250 | ms/batch  5.24 | loss  4.77 | ppl   117.79\n",
      "| epoch  11 | batch   350/ 2250 | ms/batch  5.04 | loss  4.67 | ppl   106.67\n",
      "| epoch  11 | batch   400/ 2250 | ms/batch  4.98 | loss  4.70 | ppl   109.77\n",
      "| epoch  11 | batch   450/ 2250 | ms/batch  4.96 | loss  4.68 | ppl   108.25\n",
      "| epoch  11 | batch   500/ 2250 | ms/batch  4.97 | loss  4.67 | ppl   106.51\n",
      "| epoch  11 | batch   550/ 2250 | ms/batch  5.06 | loss  4.69 | ppl   109.21\n",
      "| epoch  11 | batch   600/ 2250 | ms/batch  5.03 | loss  4.70 | ppl   109.87\n",
      "| epoch  11 | batch   650/ 2250 | ms/batch  5.12 | loss  4.69 | ppl   109.28\n",
      "| epoch  11 | batch   700/ 2250 | ms/batch  5.12 | loss  4.70 | ppl   109.66\n",
      "| epoch  11 | batch   750/ 2250 | ms/batch  5.23 | loss  4.66 | ppl   105.27\n",
      "| epoch  11 | batch   800/ 2250 | ms/batch  4.97 | loss  4.75 | ppl   115.82\n",
      "| epoch  11 | batch   850/ 2250 | ms/batch  4.99 | loss  4.69 | ppl   108.69\n",
      "| epoch  11 | batch   900/ 2250 | ms/batch  5.07 | loss  4.73 | ppl   113.58\n",
      "| epoch  11 | batch   950/ 2250 | ms/batch  5.15 | loss  4.73 | ppl   113.25\n",
      "| epoch  11 | batch  1000/ 2250 | ms/batch  5.30 | loss  4.73 | ppl   112.80\n",
      "| epoch  11 | batch  1050/ 2250 | ms/batch  5.00 | loss  4.72 | ppl   111.91\n",
      "| epoch  11 | batch  1100/ 2250 | ms/batch  4.96 | loss  4.75 | ppl   115.27\n",
      "| epoch  11 | batch  1150/ 2250 | ms/batch  4.92 | loss  4.76 | ppl   116.89\n",
      "| epoch  11 | batch  1200/ 2250 | ms/batch  4.77 | loss  4.69 | ppl   108.75\n",
      "| epoch  11 | batch  1250/ 2250 | ms/batch  4.78 | loss  4.70 | ppl   109.86\n",
      "| epoch  11 | batch  1300/ 2250 | ms/batch  5.04 | loss  4.73 | ppl   112.74\n",
      "| epoch  11 | batch  1350/ 2250 | ms/batch  4.95 | loss  4.73 | ppl   113.12\n",
      "| epoch  11 | batch  1400/ 2250 | ms/batch  5.06 | loss  4.78 | ppl   119.50\n",
      "| epoch  11 | batch  1450/ 2250 | ms/batch  5.05 | loss  4.78 | ppl   118.93\n",
      "| epoch  11 | batch  1500/ 2250 | ms/batch  4.98 | loss  4.78 | ppl   119.09\n",
      "| epoch  11 | batch  1550/ 2250 | ms/batch  4.99 | loss  4.69 | ppl   108.93\n",
      "| epoch  11 | batch  1600/ 2250 | ms/batch  5.02 | loss  4.68 | ppl   107.28\n",
      "| epoch  11 | batch  1650/ 2250 | ms/batch  5.05 | loss  4.65 | ppl   104.95\n",
      "| epoch  11 | batch  1700/ 2250 | ms/batch  5.04 | loss  4.66 | ppl   105.81\n",
      "| epoch  11 | batch  1750/ 2250 | ms/batch  5.05 | loss  4.67 | ppl   106.99\n",
      "| epoch  11 | batch  1800/ 2250 | ms/batch  5.01 | loss  4.69 | ppl   108.68\n",
      "| epoch  11 | batch  1850/ 2250 | ms/batch  5.10 | loss  4.70 | ppl   109.93\n",
      "| epoch  11 | batch  1900/ 2250 | ms/batch  5.11 | loss  4.73 | ppl   113.06\n",
      "| epoch  11 | batch  1950/ 2250 | ms/batch  5.02 | loss  4.77 | ppl   118.02\n",
      "| epoch  11 | batch  2000/ 2250 | ms/batch  5.02 | loss  4.72 | ppl   111.69\n",
      "| epoch  11 | batch  2050/ 2250 | ms/batch  5.05 | loss  4.72 | ppl   111.88\n",
      "| epoch  11 | batch  2100/ 2250 | ms/batch  4.84 | loss  4.71 | ppl   110.56\n",
      "| epoch  11 | batch  2150/ 2250 | ms/batch  4.81 | loss  4.70 | ppl   110.17\n",
      "| epoch  11 | batch  2200/ 2250 | ms/batch  4.79 | loss  4.75 | ppl   115.24\n",
      "| epoch  11 | batch  2250/ 2250 | ms/batch  4.77 | loss  4.73 | ppl   113.10\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time: 14.20s | valid ppl   106.55\n",
      "-----------------------------------------------------------------------------------------\n",
      "New best model saved with perplexity:   106.55\n",
      "| epoch  12 | batch    50/ 2250 | ms/batch  5.16 | loss  4.80 | ppl   121.27\n",
      "| epoch  12 | batch   100/ 2250 | ms/batch  4.95 | loss  4.66 | ppl   105.87\n",
      "| epoch  12 | batch   150/ 2250 | ms/batch  4.97 | loss  4.65 | ppl   104.11\n",
      "| epoch  12 | batch   200/ 2250 | ms/batch  4.98 | loss  4.64 | ppl   103.87\n",
      "| epoch  12 | batch   250/ 2250 | ms/batch  4.82 | loss  4.66 | ppl   105.67\n",
      "| epoch  12 | batch   300/ 2250 | ms/batch  4.81 | loss  4.74 | ppl   114.48\n",
      "| epoch  12 | batch   350/ 2250 | ms/batch  4.83 | loss  4.65 | ppl   104.88\n",
      "| epoch  12 | batch   400/ 2250 | ms/batch  4.88 | loss  4.69 | ppl   108.78\n",
      "| epoch  12 | batch   450/ 2250 | ms/batch  4.98 | loss  4.67 | ppl   106.87\n",
      "| epoch  12 | batch   500/ 2250 | ms/batch  5.02 | loss  4.65 | ppl   104.62\n",
      "| epoch  12 | batch   550/ 2250 | ms/batch  5.04 | loss  4.68 | ppl   107.35\n",
      "| epoch  12 | batch   600/ 2250 | ms/batch  5.00 | loss  4.68 | ppl   107.96\n",
      "| epoch  12 | batch   650/ 2250 | ms/batch  5.03 | loss  4.67 | ppl   106.99\n",
      "| epoch  12 | batch   700/ 2250 | ms/batch  5.10 | loss  4.69 | ppl   108.75\n",
      "| epoch  12 | batch   750/ 2250 | ms/batch  5.09 | loss  4.65 | ppl   104.35\n",
      "| epoch  12 | batch   800/ 2250 | ms/batch  5.03 | loss  4.73 | ppl   113.81\n",
      "| epoch  12 | batch   850/ 2250 | ms/batch  5.06 | loss  4.68 | ppl   107.71\n",
      "| epoch  12 | batch   900/ 2250 | ms/batch  5.04 | loss  4.72 | ppl   111.84\n",
      "| epoch  12 | batch   950/ 2250 | ms/batch  5.02 | loss  4.71 | ppl   110.98\n",
      "| epoch  12 | batch  1000/ 2250 | ms/batch  5.06 | loss  4.71 | ppl   111.21\n",
      "| epoch  12 | batch  1050/ 2250 | ms/batch  5.07 | loss  4.71 | ppl   111.30\n",
      "| epoch  12 | batch  1100/ 2250 | ms/batch  5.15 | loss  4.74 | ppl   114.10\n",
      "| epoch  12 | batch  1150/ 2250 | ms/batch  5.07 | loss  4.76 | ppl   116.29\n",
      "| epoch  12 | batch  1200/ 2250 | ms/batch  5.02 | loss  4.67 | ppl   106.84\n",
      "| epoch  12 | batch  1250/ 2250 | ms/batch  5.15 | loss  4.70 | ppl   109.87\n",
      "| epoch  12 | batch  1300/ 2250 | ms/batch  5.03 | loss  4.70 | ppl   110.26\n",
      "| epoch  12 | batch  1350/ 2250 | ms/batch  5.01 | loss  4.72 | ppl   112.00\n",
      "| epoch  12 | batch  1400/ 2250 | ms/batch  5.07 | loss  4.77 | ppl   118.01\n",
      "| epoch  12 | batch  1450/ 2250 | ms/batch  5.20 | loss  4.77 | ppl   117.58\n",
      "| epoch  12 | batch  1500/ 2250 | ms/batch  5.00 | loss  4.77 | ppl   118.21\n",
      "| epoch  12 | batch  1550/ 2250 | ms/batch  5.02 | loss  4.67 | ppl   107.18\n",
      "| epoch  12 | batch  1600/ 2250 | ms/batch  5.00 | loss  4.66 | ppl   106.04\n",
      "| epoch  12 | batch  1650/ 2250 | ms/batch  5.07 | loss  4.64 | ppl   103.30\n",
      "| epoch  12 | batch  1700/ 2250 | ms/batch  5.03 | loss  4.65 | ppl   104.57\n",
      "| epoch  12 | batch  1750/ 2250 | ms/batch  5.04 | loss  4.67 | ppl   106.94\n",
      "| epoch  12 | batch  1800/ 2250 | ms/batch  5.11 | loss  4.66 | ppl   106.07\n",
      "| epoch  12 | batch  1850/ 2250 | ms/batch  5.05 | loss  4.69 | ppl   108.51\n",
      "| epoch  12 | batch  1900/ 2250 | ms/batch  5.00 | loss  4.71 | ppl   111.24\n",
      "| epoch  12 | batch  1950/ 2250 | ms/batch  5.04 | loss  4.76 | ppl   116.81\n",
      "| epoch  12 | batch  2000/ 2250 | ms/batch  5.03 | loss  4.71 | ppl   111.33\n",
      "| epoch  12 | batch  2050/ 2250 | ms/batch  5.05 | loss  4.73 | ppl   112.74\n",
      "| epoch  12 | batch  2100/ 2250 | ms/batch  5.05 | loss  4.68 | ppl   108.28\n",
      "| epoch  12 | batch  2150/ 2250 | ms/batch  5.38 | loss  4.68 | ppl   107.96\n",
      "| epoch  12 | batch  2200/ 2250 | ms/batch  5.25 | loss  4.72 | ppl   112.34\n",
      "| epoch  12 | batch  2250/ 2250 | ms/batch  5.35 | loss  4.71 | ppl   111.56\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time: 14.33s | valid ppl   104.78\n",
      "-----------------------------------------------------------------------------------------\n",
      "New best model saved with perplexity:   104.78\n",
      "| epoch  13 | batch    50/ 2250 | ms/batch  5.04 | loss  4.78 | ppl   119.68\n",
      "| epoch  13 | batch   100/ 2250 | ms/batch  4.73 | loss  4.65 | ppl   104.37\n",
      "| epoch  13 | batch   150/ 2250 | ms/batch  4.94 | loss  4.64 | ppl   103.34\n",
      "| epoch  13 | batch   200/ 2250 | ms/batch  4.94 | loss  4.63 | ppl   102.04\n",
      "| epoch  13 | batch   250/ 2250 | ms/batch  4.80 | loss  4.64 | ppl   103.75\n",
      "| epoch  13 | batch   300/ 2250 | ms/batch  4.78 | loss  4.73 | ppl   113.85\n",
      "| epoch  13 | batch   350/ 2250 | ms/batch  4.79 | loss  4.65 | ppl   104.21\n",
      "| epoch  13 | batch   400/ 2250 | ms/batch  4.85 | loss  4.67 | ppl   107.03\n",
      "| epoch  13 | batch   450/ 2250 | ms/batch  4.77 | loss  4.65 | ppl   104.67\n",
      "| epoch  13 | batch   500/ 2250 | ms/batch  4.76 | loss  4.64 | ppl   103.21\n",
      "| epoch  13 | batch   550/ 2250 | ms/batch  4.76 | loss  4.67 | ppl   106.94\n",
      "| epoch  13 | batch   600/ 2250 | ms/batch  4.81 | loss  4.68 | ppl   107.74\n",
      "| epoch  13 | batch   650/ 2250 | ms/batch  5.01 | loss  4.66 | ppl   106.01\n",
      "| epoch  13 | batch   700/ 2250 | ms/batch  4.94 | loss  4.67 | ppl   106.70\n",
      "| epoch  13 | batch   750/ 2250 | ms/batch  4.80 | loss  4.64 | ppl   103.27\n",
      "| epoch  13 | batch   800/ 2250 | ms/batch  4.79 | loss  4.73 | ppl   113.49\n",
      "| epoch  13 | batch   850/ 2250 | ms/batch  4.97 | loss  4.67 | ppl   106.51\n",
      "| epoch  13 | batch   900/ 2250 | ms/batch  4.79 | loss  4.71 | ppl   111.49\n",
      "| epoch  13 | batch   950/ 2250 | ms/batch  4.78 | loss  4.70 | ppl   109.75\n",
      "| epoch  13 | batch  1000/ 2250 | ms/batch  4.76 | loss  4.70 | ppl   109.84\n",
      "| epoch  13 | batch  1050/ 2250 | ms/batch  4.75 | loss  4.69 | ppl   109.37\n",
      "| epoch  13 | batch  1100/ 2250 | ms/batch  4.74 | loss  4.72 | ppl   112.71\n",
      "| epoch  13 | batch  1150/ 2250 | ms/batch  4.76 | loss  4.74 | ppl   114.73\n",
      "| epoch  13 | batch  1200/ 2250 | ms/batch  4.85 | loss  4.67 | ppl   106.45\n",
      "| epoch  13 | batch  1250/ 2250 | ms/batch  4.72 | loss  4.69 | ppl   108.75\n",
      "| epoch  13 | batch  1300/ 2250 | ms/batch  4.71 | loss  4.70 | ppl   110.15\n",
      "| epoch  13 | batch  1350/ 2250 | ms/batch  4.72 | loss  4.72 | ppl   112.39\n",
      "| epoch  13 | batch  1400/ 2250 | ms/batch  4.72 | loss  4.76 | ppl   116.95\n",
      "| epoch  13 | batch  1450/ 2250 | ms/batch  4.74 | loss  4.76 | ppl   117.09\n",
      "| epoch  13 | batch  1500/ 2250 | ms/batch  4.96 | loss  4.75 | ppl   115.19\n",
      "| epoch  13 | batch  1550/ 2250 | ms/batch  4.95 | loss  4.65 | ppl   105.03\n",
      "| epoch  13 | batch  1600/ 2250 | ms/batch  5.02 | loss  4.66 | ppl   105.48\n",
      "| epoch  13 | batch  1650/ 2250 | ms/batch  5.00 | loss  4.64 | ppl   103.19\n",
      "| epoch  13 | batch  1700/ 2250 | ms/batch  5.00 | loss  4.63 | ppl   103.02\n",
      "| epoch  13 | batch  1750/ 2250 | ms/batch  5.04 | loss  4.66 | ppl   105.20\n",
      "| epoch  13 | batch  1800/ 2250 | ms/batch  4.96 | loss  4.65 | ppl   104.78\n",
      "| epoch  13 | batch  1850/ 2250 | ms/batch  5.43 | loss  4.68 | ppl   108.17\n",
      "| epoch  13 | batch  1900/ 2250 | ms/batch  5.14 | loss  4.69 | ppl   109.20\n",
      "| epoch  13 | batch  1950/ 2250 | ms/batch  4.96 | loss  4.75 | ppl   115.74\n",
      "| epoch  13 | batch  2000/ 2250 | ms/batch  4.95 | loss  4.70 | ppl   110.16\n",
      "| epoch  13 | batch  2050/ 2250 | ms/batch  5.02 | loss  4.71 | ppl   110.84\n",
      "| epoch  13 | batch  2100/ 2250 | ms/batch  4.96 | loss  4.68 | ppl   107.24\n",
      "| epoch  13 | batch  2150/ 2250 | ms/batch  5.01 | loss  4.68 | ppl   107.36\n",
      "| epoch  13 | batch  2200/ 2250 | ms/batch  5.04 | loss  4.72 | ppl   112.01\n",
      "| epoch  13 | batch  2250/ 2250 | ms/batch  5.02 | loss  4.70 | ppl   109.67\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  13 | time: 13.99s | valid ppl   105.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  14 | batch    50/ 2250 | ms/batch  4.99 | loss  4.77 | ppl   118.34\n",
      "| epoch  14 | batch   100/ 2250 | ms/batch  4.77 | loss  4.63 | ppl   102.47\n",
      "| epoch  14 | batch   150/ 2250 | ms/batch  4.78 | loss  4.62 | ppl   101.57\n",
      "| epoch  14 | batch   200/ 2250 | ms/batch  4.75 | loss  4.64 | ppl   103.43\n",
      "| epoch  14 | batch   250/ 2250 | ms/batch  4.75 | loss  4.63 | ppl   102.44\n",
      "| epoch  14 | batch   300/ 2250 | ms/batch  4.76 | loss  4.72 | ppl   111.78\n",
      "| epoch  14 | batch   350/ 2250 | ms/batch  4.76 | loss  4.64 | ppl   103.60\n",
      "| epoch  14 | batch   400/ 2250 | ms/batch  4.77 | loss  4.66 | ppl   105.47\n",
      "| epoch  14 | batch   450/ 2250 | ms/batch  5.02 | loss  4.64 | ppl   103.64\n",
      "| epoch  14 | batch   500/ 2250 | ms/batch  4.99 | loss  4.62 | ppl   101.83\n",
      "| epoch  14 | batch   550/ 2250 | ms/batch  5.56 | loss  4.66 | ppl   105.63\n",
      "| epoch  14 | batch   600/ 2250 | ms/batch  5.05 | loss  4.66 | ppl   105.44\n",
      "| epoch  14 | batch   650/ 2250 | ms/batch  4.87 | loss  4.66 | ppl   105.80\n",
      "| epoch  14 | batch   700/ 2250 | ms/batch  5.02 | loss  4.66 | ppl   106.09\n",
      "| epoch  14 | batch   750/ 2250 | ms/batch  4.96 | loss  4.62 | ppl   101.65\n",
      "| epoch  14 | batch   800/ 2250 | ms/batch  5.00 | loss  4.72 | ppl   112.38\n",
      "| epoch  14 | batch   850/ 2250 | ms/batch  5.22 | loss  4.65 | ppl   104.42\n",
      "| epoch  14 | batch   900/ 2250 | ms/batch  4.97 | loss  4.70 | ppl   109.63\n",
      "| epoch  14 | batch   950/ 2250 | ms/batch  5.01 | loss  4.70 | ppl   109.58\n",
      "| epoch  14 | batch  1000/ 2250 | ms/batch  5.00 | loss  4.69 | ppl   108.79\n",
      "| epoch  14 | batch  1050/ 2250 | ms/batch  5.05 | loss  4.69 | ppl   108.61\n",
      "| epoch  14 | batch  1100/ 2250 | ms/batch  4.95 | loss  4.72 | ppl   112.58\n",
      "| epoch  14 | batch  1150/ 2250 | ms/batch  4.85 | loss  4.73 | ppl   113.57\n",
      "| epoch  14 | batch  1200/ 2250 | ms/batch  4.80 | loss  4.65 | ppl   104.98\n",
      "| epoch  14 | batch  1250/ 2250 | ms/batch  4.81 | loss  4.68 | ppl   107.94\n",
      "| epoch  14 | batch  1300/ 2250 | ms/batch  4.77 | loss  4.69 | ppl   108.56\n",
      "| epoch  14 | batch  1350/ 2250 | ms/batch  4.77 | loss  4.71 | ppl   110.64\n",
      "| epoch  14 | batch  1400/ 2250 | ms/batch  4.76 | loss  4.75 | ppl   115.06\n",
      "| epoch  14 | batch  1450/ 2250 | ms/batch  4.76 | loss  4.75 | ppl   115.37\n",
      "| epoch  14 | batch  1500/ 2250 | ms/batch  4.75 | loss  4.74 | ppl   114.83\n",
      "| epoch  14 | batch  1550/ 2250 | ms/batch  4.74 | loss  4.65 | ppl   104.58\n",
      "| epoch  14 | batch  1600/ 2250 | ms/batch  4.79 | loss  4.64 | ppl   103.70\n",
      "| epoch  14 | batch  1650/ 2250 | ms/batch  4.76 | loss  4.62 | ppl   101.55\n",
      "| epoch  14 | batch  1700/ 2250 | ms/batch  4.76 | loss  4.63 | ppl   102.17\n",
      "| epoch  14 | batch  1750/ 2250 | ms/batch  4.76 | loss  4.65 | ppl   104.38\n",
      "| epoch  14 | batch  1800/ 2250 | ms/batch  5.01 | loss  4.64 | ppl   103.99\n",
      "| epoch  14 | batch  1850/ 2250 | ms/batch  5.00 | loss  4.67 | ppl   106.92\n",
      "| epoch  14 | batch  1900/ 2250 | ms/batch  4.99 | loss  4.69 | ppl   109.19\n",
      "| epoch  14 | batch  1950/ 2250 | ms/batch  4.96 | loss  4.74 | ppl   114.79\n",
      "| epoch  14 | batch  2000/ 2250 | ms/batch  5.00 | loss  4.69 | ppl   109.21\n",
      "| epoch  14 | batch  2050/ 2250 | ms/batch  5.11 | loss  4.70 | ppl   109.40\n",
      "| epoch  14 | batch  2100/ 2250 | ms/batch  5.01 | loss  4.66 | ppl   105.18\n",
      "| epoch  14 | batch  2150/ 2250 | ms/batch  4.85 | loss  4.66 | ppl   105.58\n",
      "| epoch  14 | batch  2200/ 2250 | ms/batch  4.82 | loss  4.70 | ppl   110.48\n",
      "| epoch  14 | batch  2250/ 2250 | ms/batch  5.12 | loss  4.69 | ppl   109.32\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  14 | time: 14.04s | valid ppl   106.72\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  15 | batch    50/ 2250 | ms/batch  5.16 | loss  4.77 | ppl   117.91\n",
      "| epoch  15 | batch   100/ 2250 | ms/batch  5.05 | loss  4.62 | ppl   101.17\n",
      "| epoch  15 | batch   150/ 2250 | ms/batch  5.04 | loss  4.62 | ppl   101.03\n",
      "| epoch  15 | batch   200/ 2250 | ms/batch  5.07 | loss  4.63 | ppl   102.07\n",
      "| epoch  15 | batch   250/ 2250 | ms/batch  5.00 | loss  4.62 | ppl   101.47\n",
      "| epoch  15 | batch   300/ 2250 | ms/batch  5.08 | loss  4.69 | ppl   108.98\n",
      "| epoch  15 | batch   350/ 2250 | ms/batch  5.00 | loss  4.64 | ppl   103.20\n",
      "| epoch  15 | batch   400/ 2250 | ms/batch  5.07 | loss  4.65 | ppl   104.81\n",
      "| epoch  15 | batch   450/ 2250 | ms/batch  4.99 | loss  4.64 | ppl   103.39\n",
      "| epoch  15 | batch   500/ 2250 | ms/batch  5.00 | loss  4.62 | ppl   101.23\n",
      "| epoch  15 | batch   550/ 2250 | ms/batch  5.09 | loss  4.66 | ppl   105.34\n",
      "| epoch  15 | batch   600/ 2250 | ms/batch  5.03 | loss  4.65 | ppl   104.91\n",
      "| epoch  15 | batch   650/ 2250 | ms/batch  5.02 | loss  4.65 | ppl   104.32\n",
      "| epoch  15 | batch   700/ 2250 | ms/batch  5.06 | loss  4.65 | ppl   104.52\n",
      "| epoch  15 | batch   750/ 2250 | ms/batch  5.03 | loss  4.62 | ppl   101.60\n",
      "| epoch  15 | batch   800/ 2250 | ms/batch  5.06 | loss  4.71 | ppl   110.93\n",
      "| epoch  15 | batch   850/ 2250 | ms/batch  5.08 | loss  4.63 | ppl   102.96\n",
      "| epoch  15 | batch   900/ 2250 | ms/batch  5.06 | loss  4.69 | ppl   109.36\n",
      "| epoch  15 | batch   950/ 2250 | ms/batch  5.22 | loss  4.69 | ppl   108.39\n",
      "| epoch  15 | batch  1000/ 2250 | ms/batch  5.36 | loss  4.68 | ppl   108.16\n",
      "| epoch  15 | batch  1050/ 2250 | ms/batch  5.40 | loss  4.68 | ppl   107.44\n",
      "| epoch  15 | batch  1100/ 2250 | ms/batch  5.07 | loss  4.70 | ppl   109.88\n",
      "| epoch  15 | batch  1150/ 2250 | ms/batch  5.22 | loss  4.72 | ppl   112.12\n",
      "| epoch  15 | batch  1200/ 2250 | ms/batch  5.19 | loss  4.64 | ppl   103.25\n",
      "| epoch  15 | batch  1250/ 2250 | ms/batch  5.10 | loss  4.67 | ppl   106.84\n",
      "| epoch  15 | batch  1300/ 2250 | ms/batch  5.05 | loss  4.68 | ppl   108.17\n",
      "| epoch  15 | batch  1350/ 2250 | ms/batch  5.10 | loss  4.70 | ppl   109.53\n",
      "| epoch  15 | batch  1400/ 2250 | ms/batch  5.16 | loss  4.74 | ppl   114.25\n",
      "| epoch  15 | batch  1450/ 2250 | ms/batch  5.17 | loss  4.74 | ppl   114.45\n",
      "| epoch  15 | batch  1500/ 2250 | ms/batch  5.04 | loss  4.73 | ppl   113.46\n",
      "| epoch  15 | batch  1550/ 2250 | ms/batch  5.09 | loss  4.65 | ppl   104.19\n",
      "| epoch  15 | batch  1600/ 2250 | ms/batch  5.06 | loss  4.63 | ppl   102.86\n",
      "| epoch  15 | batch  1650/ 2250 | ms/batch  5.28 | loss  4.61 | ppl   100.15\n",
      "| epoch  15 | batch  1700/ 2250 | ms/batch  5.00 | loss  4.62 | ppl   101.14\n",
      "| epoch  15 | batch  1750/ 2250 | ms/batch  4.94 | loss  4.63 | ppl   102.71\n",
      "| epoch  15 | batch  1800/ 2250 | ms/batch  5.14 | loss  4.64 | ppl   103.63\n",
      "| epoch  15 | batch  1850/ 2250 | ms/batch  5.00 | loss  4.67 | ppl   106.34\n",
      "| epoch  15 | batch  1900/ 2250 | ms/batch  5.06 | loss  4.69 | ppl   108.89\n",
      "| epoch  15 | batch  1950/ 2250 | ms/batch  5.02 | loss  4.74 | ppl   114.30\n",
      "| epoch  15 | batch  2000/ 2250 | ms/batch  5.06 | loss  4.68 | ppl   107.59\n",
      "| epoch  15 | batch  2050/ 2250 | ms/batch  5.06 | loss  4.68 | ppl   108.22\n",
      "| epoch  15 | batch  2100/ 2250 | ms/batch  5.07 | loss  4.65 | ppl   104.27\n",
      "| epoch  15 | batch  2150/ 2250 | ms/batch  5.03 | loss  4.66 | ppl   105.37\n",
      "| epoch  15 | batch  2200/ 2250 | ms/batch  4.98 | loss  4.69 | ppl   109.19\n",
      "| epoch  15 | batch  2250/ 2250 | ms/batch  4.98 | loss  4.68 | ppl   108.31\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  15 | time: 14.42s | valid ppl   103.18\n",
      "-----------------------------------------------------------------------------------------\n",
      "New best model saved with perplexity:   103.18\n",
      "| epoch  16 | batch    50/ 2250 | ms/batch  5.01 | loss  4.76 | ppl   116.62\n",
      "| epoch  16 | batch   100/ 2250 | ms/batch  4.97 | loss  4.62 | ppl   101.05\n",
      "| epoch  16 | batch   150/ 2250 | ms/batch  4.95 | loss  4.61 | ppl   100.68\n",
      "| epoch  16 | batch   200/ 2250 | ms/batch  4.95 | loss  4.62 | ppl   101.12\n",
      "| epoch  16 | batch   250/ 2250 | ms/batch  4.99 | loss  4.61 | ppl   100.50\n",
      "| epoch  16 | batch   300/ 2250 | ms/batch  5.07 | loss  4.70 | ppl   109.44\n",
      "| epoch  16 | batch   350/ 2250 | ms/batch  5.08 | loss  4.62 | ppl   101.03\n",
      "| epoch  16 | batch   400/ 2250 | ms/batch  4.98 | loss  4.65 | ppl   104.16\n",
      "| epoch  16 | batch   450/ 2250 | ms/batch  4.96 | loss  4.62 | ppl   101.63\n",
      "| epoch  16 | batch   500/ 2250 | ms/batch  5.00 | loss  4.61 | ppl   100.81\n",
      "| epoch  16 | batch   550/ 2250 | ms/batch  5.02 | loss  4.64 | ppl   103.60\n",
      "| epoch  16 | batch   600/ 2250 | ms/batch  5.04 | loss  4.65 | ppl   104.11\n",
      "| epoch  16 | batch   650/ 2250 | ms/batch  5.03 | loss  4.64 | ppl   103.47\n",
      "| epoch  16 | batch   700/ 2250 | ms/batch  5.06 | loss  4.65 | ppl   104.23\n",
      "| epoch  16 | batch   750/ 2250 | ms/batch  5.07 | loss  4.61 | ppl   100.61\n",
      "| epoch  16 | batch   800/ 2250 | ms/batch  5.06 | loss  4.69 | ppl   109.22\n",
      "| epoch  16 | batch   850/ 2250 | ms/batch  5.08 | loss  4.63 | ppl   102.27\n",
      "| epoch  16 | batch   900/ 2250 | ms/batch  5.18 | loss  4.68 | ppl   108.25\n",
      "| epoch  16 | batch   950/ 2250 | ms/batch  5.00 | loss  4.68 | ppl   108.10\n",
      "| epoch  16 | batch  1000/ 2250 | ms/batch  5.01 | loss  4.66 | ppl   106.16\n",
      "| epoch  16 | batch  1050/ 2250 | ms/batch  5.01 | loss  4.66 | ppl   105.58\n",
      "| epoch  16 | batch  1100/ 2250 | ms/batch  5.05 | loss  4.70 | ppl   109.72\n",
      "| epoch  16 | batch  1150/ 2250 | ms/batch  5.07 | loss  4.71 | ppl   111.46\n",
      "| epoch  16 | batch  1200/ 2250 | ms/batch  5.07 | loss  4.64 | ppl   103.84\n",
      "| epoch  16 | batch  1250/ 2250 | ms/batch  5.29 | loss  4.66 | ppl   105.52\n",
      "| epoch  16 | batch  1300/ 2250 | ms/batch  5.03 | loss  4.67 | ppl   106.84\n",
      "| epoch  16 | batch  1350/ 2250 | ms/batch  5.05 | loss  4.68 | ppl   107.57\n",
      "| epoch  16 | batch  1400/ 2250 | ms/batch  5.28 | loss  4.72 | ppl   112.58\n",
      "| epoch  16 | batch  1450/ 2250 | ms/batch  4.97 | loss  4.74 | ppl   114.77\n",
      "| epoch  16 | batch  1500/ 2250 | ms/batch  5.03 | loss  4.73 | ppl   113.14\n",
      "| epoch  16 | batch  1550/ 2250 | ms/batch  5.01 | loss  4.65 | ppl   104.37\n",
      "| epoch  16 | batch  1600/ 2250 | ms/batch  5.02 | loss  4.63 | ppl   102.05\n",
      "| epoch  16 | batch  1650/ 2250 | ms/batch  5.10 | loss  4.61 | ppl   100.35\n",
      "| epoch  16 | batch  1700/ 2250 | ms/batch  5.06 | loss  4.60 | ppl    99.78\n",
      "| epoch  16 | batch  1750/ 2250 | ms/batch  5.21 | loss  4.63 | ppl   102.54\n",
      "| epoch  16 | batch  1800/ 2250 | ms/batch  5.01 | loss  4.63 | ppl   102.73\n",
      "| epoch  16 | batch  1850/ 2250 | ms/batch  4.99 | loss  4.64 | ppl   103.93\n",
      "| epoch  16 | batch  1900/ 2250 | ms/batch  5.23 | loss  4.67 | ppl   107.13\n",
      "| epoch  16 | batch  1950/ 2250 | ms/batch  5.29 | loss  4.73 | ppl   113.51\n",
      "| epoch  16 | batch  2000/ 2250 | ms/batch  5.05 | loss  4.67 | ppl   106.98\n",
      "| epoch  16 | batch  2050/ 2250 | ms/batch  5.06 | loss  4.68 | ppl   107.35\n",
      "| epoch  16 | batch  2100/ 2250 | ms/batch  5.28 | loss  4.65 | ppl   104.51\n",
      "| epoch  16 | batch  2150/ 2250 | ms/batch  5.07 | loss  4.65 | ppl   104.14\n",
      "| epoch  16 | batch  2200/ 2250 | ms/batch  5.10 | loss  4.69 | ppl   108.84\n",
      "| epoch  16 | batch  2250/ 2250 | ms/batch  5.36 | loss  4.67 | ppl   106.85\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  16 | time: 14.38s | valid ppl   103.94\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  17 | batch    50/ 2250 | ms/batch  5.13 | loss  4.75 | ppl   115.83\n",
      "| epoch  17 | batch   100/ 2250 | ms/batch  4.96 | loss  4.60 | ppl    99.78\n",
      "| epoch  17 | batch   150/ 2250 | ms/batch  4.94 | loss  4.61 | ppl   100.46\n",
      "| epoch  17 | batch   200/ 2250 | ms/batch  5.09 | loss  4.60 | ppl    99.42\n",
      "| epoch  17 | batch   250/ 2250 | ms/batch  5.05 | loss  4.60 | ppl    99.06\n",
      "| epoch  17 | batch   300/ 2250 | ms/batch  4.99 | loss  4.68 | ppl   108.18\n",
      "| epoch  17 | batch   350/ 2250 | ms/batch  5.00 | loss  4.63 | ppl   102.32\n",
      "| epoch  17 | batch   400/ 2250 | ms/batch  4.98 | loss  4.64 | ppl   103.29\n",
      "| epoch  17 | batch   450/ 2250 | ms/batch  4.86 | loss  4.62 | ppl   101.11\n",
      "| epoch  17 | batch   500/ 2250 | ms/batch  4.82 | loss  4.60 | ppl    99.67\n",
      "| epoch  17 | batch   550/ 2250 | ms/batch  4.83 | loss  4.63 | ppl   102.74\n",
      "| epoch  17 | batch   600/ 2250 | ms/batch  4.79 | loss  4.64 | ppl   103.44\n",
      "| epoch  17 | batch   650/ 2250 | ms/batch  4.86 | loss  4.63 | ppl   102.48\n",
      "| epoch  17 | batch   700/ 2250 | ms/batch  4.77 | loss  4.63 | ppl   103.02\n",
      "| epoch  17 | batch   750/ 2250 | ms/batch  4.95 | loss  4.60 | ppl    99.56\n",
      "| epoch  17 | batch   800/ 2250 | ms/batch  4.79 | loss  4.70 | ppl   109.69\n",
      "| epoch  17 | batch   850/ 2250 | ms/batch  4.78 | loss  4.63 | ppl   102.49\n",
      "| epoch  17 | batch   900/ 2250 | ms/batch  4.77 | loss  4.67 | ppl   106.99\n",
      "| epoch  17 | batch   950/ 2250 | ms/batch  4.78 | loss  4.66 | ppl   105.73\n",
      "| epoch  17 | batch  1000/ 2250 | ms/batch  4.81 | loss  4.66 | ppl   105.68\n",
      "| epoch  17 | batch  1050/ 2250 | ms/batch  4.81 | loss  4.66 | ppl   105.78\n",
      "| epoch  17 | batch  1100/ 2250 | ms/batch  4.73 | loss  4.69 | ppl   109.21\n",
      "| epoch  17 | batch  1150/ 2250 | ms/batch  4.74 | loss  4.70 | ppl   110.17\n",
      "| epoch  17 | batch  1200/ 2250 | ms/batch  4.76 | loss  4.63 | ppl   102.71\n",
      "| epoch  17 | batch  1250/ 2250 | ms/batch  4.76 | loss  4.65 | ppl   104.33\n",
      "| epoch  17 | batch  1300/ 2250 | ms/batch  4.76 | loss  4.68 | ppl   107.87\n",
      "| epoch  17 | batch  1350/ 2250 | ms/batch  4.77 | loss  4.68 | ppl   107.93\n",
      "| epoch  17 | batch  1400/ 2250 | ms/batch  4.76 | loss  4.73 | ppl   112.86\n",
      "| epoch  17 | batch  1450/ 2250 | ms/batch  4.78 | loss  4.73 | ppl   113.03\n",
      "| epoch  17 | batch  1500/ 2250 | ms/batch  4.75 | loss  4.71 | ppl   111.48\n",
      "| epoch  17 | batch  1550/ 2250 | ms/batch  4.74 | loss  4.63 | ppl   102.85\n",
      "| epoch  17 | batch  1600/ 2250 | ms/batch  4.76 | loss  4.62 | ppl   101.80\n",
      "| epoch  17 | batch  1650/ 2250 | ms/batch  4.76 | loss  4.60 | ppl    99.14\n",
      "| epoch  17 | batch  1700/ 2250 | ms/batch  4.78 | loss  4.61 | ppl   100.09\n",
      "| epoch  17 | batch  1750/ 2250 | ms/batch  4.75 | loss  4.61 | ppl   100.28\n",
      "| epoch  17 | batch  1800/ 2250 | ms/batch  4.84 | loss  4.63 | ppl   102.35\n",
      "| epoch  17 | batch  1850/ 2250 | ms/batch  4.76 | loss  4.64 | ppl   103.44\n",
      "| epoch  17 | batch  1900/ 2250 | ms/batch  4.76 | loss  4.66 | ppl   105.93\n",
      "| epoch  17 | batch  1950/ 2250 | ms/batch  4.75 | loss  4.73 | ppl   112.76\n",
      "| epoch  17 | batch  2000/ 2250 | ms/batch  4.78 | loss  4.67 | ppl   106.38\n",
      "| epoch  17 | batch  2050/ 2250 | ms/batch  4.75 | loss  4.67 | ppl   106.34\n",
      "| epoch  17 | batch  2100/ 2250 | ms/batch  4.84 | loss  4.65 | ppl   104.87\n",
      "| epoch  17 | batch  2150/ 2250 | ms/batch  4.98 | loss  4.65 | ppl   104.77\n",
      "| epoch  17 | batch  2200/ 2250 | ms/batch  4.74 | loss  4.68 | ppl   107.98\n",
      "| epoch  17 | batch  2250/ 2250 | ms/batch  4.72 | loss  4.67 | ppl   106.45\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  17 | time: 13.82s | valid ppl   104.53\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  18 | batch    50/ 2250 | ms/batch  4.91 | loss  4.75 | ppl   115.81\n",
      "| epoch  18 | batch   100/ 2250 | ms/batch  4.89 | loss  4.59 | ppl    98.80\n",
      "| epoch  18 | batch   150/ 2250 | ms/batch  4.80 | loss  4.60 | ppl    99.20\n",
      "| epoch  18 | batch   200/ 2250 | ms/batch  4.77 | loss  4.59 | ppl    98.47\n",
      "| epoch  18 | batch   250/ 2250 | ms/batch  4.77 | loss  4.60 | ppl    99.32\n",
      "| epoch  18 | batch   300/ 2250 | ms/batch  4.78 | loss  4.68 | ppl   107.45\n",
      "| epoch  18 | batch   350/ 2250 | ms/batch  4.76 | loss  4.60 | ppl    99.28\n",
      "| epoch  18 | batch   400/ 2250 | ms/batch  4.76 | loss  4.63 | ppl   103.00\n",
      "| epoch  18 | batch   450/ 2250 | ms/batch  4.81 | loss  4.61 | ppl   100.59\n",
      "| epoch  18 | batch   500/ 2250 | ms/batch  4.99 | loss  4.60 | ppl    99.83\n",
      "| epoch  18 | batch   550/ 2250 | ms/batch  4.94 | loss  4.63 | ppl   102.46\n",
      "| epoch  18 | batch   600/ 2250 | ms/batch  4.84 | loss  4.64 | ppl   103.28\n",
      "| epoch  18 | batch   650/ 2250 | ms/batch  4.81 | loss  4.62 | ppl   101.04\n",
      "| epoch  18 | batch   700/ 2250 | ms/batch  4.82 | loss  4.62 | ppl   101.34\n",
      "| epoch  18 | batch   750/ 2250 | ms/batch  4.83 | loss  4.60 | ppl    99.05\n",
      "| epoch  18 | batch   800/ 2250 | ms/batch  4.76 | loss  4.69 | ppl   108.38\n",
      "| epoch  18 | batch   850/ 2250 | ms/batch  4.96 | loss  4.62 | ppl   101.51\n",
      "| epoch  18 | batch   900/ 2250 | ms/batch  4.86 | loss  4.67 | ppl   106.26\n",
      "| epoch  18 | batch   950/ 2250 | ms/batch  4.80 | loss  4.65 | ppl   105.05\n",
      "| epoch  18 | batch  1000/ 2250 | ms/batch  4.77 | loss  4.67 | ppl   106.17\n",
      "| epoch  18 | batch  1050/ 2250 | ms/batch  4.79 | loss  4.65 | ppl   104.62\n",
      "| epoch  18 | batch  1100/ 2250 | ms/batch  4.79 | loss  4.69 | ppl   108.42\n",
      "| epoch  18 | batch  1150/ 2250 | ms/batch  4.79 | loss  4.70 | ppl   109.63\n",
      "| epoch  18 | batch  1200/ 2250 | ms/batch  4.97 | loss  4.62 | ppl   101.51\n",
      "| epoch  18 | batch  1250/ 2250 | ms/batch  4.80 | loss  4.66 | ppl   106.16\n",
      "| epoch  18 | batch  1300/ 2250 | ms/batch  4.80 | loss  4.67 | ppl   106.30\n",
      "| epoch  18 | batch  1350/ 2250 | ms/batch  4.76 | loss  4.66 | ppl   105.62\n",
      "| epoch  18 | batch  1400/ 2250 | ms/batch  4.78 | loss  4.71 | ppl   111.50\n",
      "| epoch  18 | batch  1450/ 2250 | ms/batch  4.75 | loss  4.71 | ppl   111.38\n",
      "| epoch  18 | batch  1500/ 2250 | ms/batch  4.75 | loss  4.71 | ppl   111.35\n",
      "| epoch  18 | batch  1550/ 2250 | ms/batch  4.77 | loss  4.62 | ppl   101.55\n",
      "| epoch  18 | batch  1600/ 2250 | ms/batch  4.74 | loss  4.62 | ppl   101.17\n",
      "| epoch  18 | batch  1650/ 2250 | ms/batch  4.78 | loss  4.59 | ppl    98.27\n",
      "| epoch  18 | batch  1700/ 2250 | ms/batch  4.78 | loss  4.59 | ppl    98.88\n",
      "| epoch  18 | batch  1750/ 2250 | ms/batch  4.76 | loss  4.61 | ppl    99.99\n",
      "| epoch  18 | batch  1800/ 2250 | ms/batch  4.77 | loss  4.62 | ppl   101.40\n",
      "| epoch  18 | batch  1850/ 2250 | ms/batch  4.78 | loss  4.64 | ppl   103.14\n",
      "| epoch  18 | batch  1900/ 2250 | ms/batch  4.77 | loss  4.66 | ppl   106.01\n",
      "| epoch  18 | batch  1950/ 2250 | ms/batch  4.78 | loss  4.71 | ppl   111.48\n",
      "| epoch  18 | batch  2000/ 2250 | ms/batch  4.76 | loss  4.66 | ppl   105.86\n",
      "| epoch  18 | batch  2050/ 2250 | ms/batch  4.80 | loss  4.66 | ppl   105.41\n",
      "| epoch  18 | batch  2100/ 2250 | ms/batch  4.76 | loss  4.64 | ppl   103.94\n",
      "| epoch  18 | batch  2150/ 2250 | ms/batch  4.85 | loss  4.63 | ppl   102.62\n",
      "| epoch  18 | batch  2200/ 2250 | ms/batch  4.75 | loss  4.68 | ppl   107.66\n",
      "| epoch  18 | batch  2250/ 2250 | ms/batch  4.75 | loss  4.67 | ppl   106.81\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  18 | time: 13.75s | valid ppl   102.19\n",
      "-----------------------------------------------------------------------------------------\n",
      "New best model saved with perplexity:   102.19\n",
      "| epoch  19 | batch    50/ 2250 | ms/batch  4.90 | loss  4.74 | ppl   114.94\n",
      "| epoch  19 | batch   100/ 2250 | ms/batch  4.83 | loss  4.60 | ppl    99.35\n",
      "| epoch  19 | batch   150/ 2250 | ms/batch  4.90 | loss  4.59 | ppl    98.85\n",
      "| epoch  19 | batch   200/ 2250 | ms/batch  4.74 | loss  4.59 | ppl    98.28\n",
      "| epoch  19 | batch   250/ 2250 | ms/batch  4.75 | loss  4.60 | ppl    99.06\n",
      "| epoch  19 | batch   300/ 2250 | ms/batch  4.96 | loss  4.67 | ppl   106.43\n",
      "| epoch  19 | batch   350/ 2250 | ms/batch  4.77 | loss  4.61 | ppl   100.83\n",
      "| epoch  19 | batch   400/ 2250 | ms/batch  4.77 | loss  4.63 | ppl   102.43\n",
      "| epoch  19 | batch   450/ 2250 | ms/batch  5.08 | loss  4.60 | ppl    99.05\n",
      "| epoch  19 | batch   500/ 2250 | ms/batch  5.24 | loss  4.60 | ppl    99.07\n",
      "| epoch  19 | batch   550/ 2250 | ms/batch  4.97 | loss  4.62 | ppl   101.34\n",
      "| epoch  19 | batch   600/ 2250 | ms/batch  5.02 | loss  4.63 | ppl   102.49\n",
      "| epoch  19 | batch   650/ 2250 | ms/batch  5.12 | loss  4.61 | ppl   100.91\n",
      "| epoch  19 | batch   700/ 2250 | ms/batch  4.83 | loss  4.63 | ppl   102.37\n",
      "| epoch  19 | batch   750/ 2250 | ms/batch  5.00 | loss  4.60 | ppl    99.18\n",
      "| epoch  19 | batch   800/ 2250 | ms/batch  4.97 | loss  4.67 | ppl   106.45\n",
      "| epoch  19 | batch   850/ 2250 | ms/batch  4.82 | loss  4.60 | ppl    99.77\n",
      "| epoch  19 | batch   900/ 2250 | ms/batch  4.81 | loss  4.66 | ppl   105.62\n",
      "| epoch  19 | batch   950/ 2250 | ms/batch  4.79 | loss  4.65 | ppl   104.72\n",
      "| epoch  19 | batch  1000/ 2250 | ms/batch  4.78 | loss  4.65 | ppl   104.45\n",
      "| epoch  19 | batch  1050/ 2250 | ms/batch  4.75 | loss  4.64 | ppl   104.00\n",
      "| epoch  19 | batch  1100/ 2250 | ms/batch  4.76 | loss  4.68 | ppl   107.62\n",
      "| epoch  19 | batch  1150/ 2250 | ms/batch  4.76 | loss  4.69 | ppl   108.89\n",
      "| epoch  19 | batch  1200/ 2250 | ms/batch  4.87 | loss  4.61 | ppl   100.26\n",
      "| epoch  19 | batch  1250/ 2250 | ms/batch  4.95 | loss  4.64 | ppl   103.89\n",
      "| epoch  19 | batch  1300/ 2250 | ms/batch  4.82 | loss  4.66 | ppl   105.51\n",
      "| epoch  19 | batch  1350/ 2250 | ms/batch  4.77 | loss  4.66 | ppl   105.56\n",
      "| epoch  19 | batch  1400/ 2250 | ms/batch  4.74 | loss  4.71 | ppl   111.52\n",
      "| epoch  19 | batch  1450/ 2250 | ms/batch  4.74 | loss  4.72 | ppl   112.11\n",
      "| epoch  19 | batch  1500/ 2250 | ms/batch  4.82 | loss  4.72 | ppl   111.88\n",
      "| epoch  19 | batch  1550/ 2250 | ms/batch  5.14 | loss  4.62 | ppl   101.72\n",
      "| epoch  19 | batch  1600/ 2250 | ms/batch  4.99 | loss  4.60 | ppl    99.59\n",
      "| epoch  19 | batch  1650/ 2250 | ms/batch  5.01 | loss  4.59 | ppl    98.25\n",
      "| epoch  19 | batch  1700/ 2250 | ms/batch  4.96 | loss  4.60 | ppl    99.07\n",
      "| epoch  19 | batch  1750/ 2250 | ms/batch  5.04 | loss  4.60 | ppl    99.13\n",
      "| epoch  19 | batch  1800/ 2250 | ms/batch  4.99 | loss  4.61 | ppl   100.20\n",
      "| epoch  19 | batch  1850/ 2250 | ms/batch  4.98 | loss  4.63 | ppl   102.81\n",
      "| epoch  19 | batch  1900/ 2250 | ms/batch  5.14 | loss  4.65 | ppl   104.88\n",
      "| epoch  19 | batch  1950/ 2250 | ms/batch  5.05 | loss  4.71 | ppl   111.06\n",
      "| epoch  19 | batch  2000/ 2250 | ms/batch  5.00 | loss  4.65 | ppl   104.76\n",
      "| epoch  19 | batch  2050/ 2250 | ms/batch  5.00 | loss  4.65 | ppl   105.02\n",
      "| epoch  19 | batch  2100/ 2250 | ms/batch  5.02 | loss  4.64 | ppl   103.40\n",
      "| epoch  19 | batch  2150/ 2250 | ms/batch  5.03 | loss  4.63 | ppl   102.31\n",
      "| epoch  19 | batch  2200/ 2250 | ms/batch  5.06 | loss  4.67 | ppl   106.89\n",
      "| epoch  19 | batch  2250/ 2250 | ms/batch  5.09 | loss  4.65 | ppl   104.80\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  19 | time: 14.07s | valid ppl   103.03\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  20 | batch    50/ 2250 | ms/batch  5.12 | loss  4.73 | ppl   113.28\n",
      "| epoch  20 | batch   100/ 2250 | ms/batch  4.98 | loss  4.59 | ppl    98.24\n",
      "| epoch  20 | batch   150/ 2250 | ms/batch  5.02 | loss  4.58 | ppl    97.95\n",
      "| epoch  20 | batch   200/ 2250 | ms/batch  4.92 | loss  4.59 | ppl    98.34\n",
      "| epoch  20 | batch   250/ 2250 | ms/batch  4.98 | loss  4.59 | ppl    98.31\n",
      "| epoch  20 | batch   300/ 2250 | ms/batch  4.84 | loss  4.66 | ppl   105.68\n",
      "| epoch  20 | batch   350/ 2250 | ms/batch  4.80 | loss  4.60 | ppl    99.12\n",
      "| epoch  20 | batch   400/ 2250 | ms/batch  4.90 | loss  4.62 | ppl   101.96\n",
      "| epoch  20 | batch   450/ 2250 | ms/batch  4.97 | loss  4.60 | ppl    99.82\n",
      "| epoch  20 | batch   500/ 2250 | ms/batch  4.95 | loss  4.59 | ppl    98.70\n",
      "| epoch  20 | batch   550/ 2250 | ms/batch  4.99 | loss  4.62 | ppl   101.91\n",
      "| epoch  20 | batch   600/ 2250 | ms/batch  5.04 | loss  4.62 | ppl   101.61\n",
      "| epoch  20 | batch   650/ 2250 | ms/batch  5.05 | loss  4.62 | ppl   101.18\n",
      "| epoch  20 | batch   700/ 2250 | ms/batch  5.22 | loss  4.62 | ppl   101.54\n",
      "| epoch  20 | batch   750/ 2250 | ms/batch  5.36 | loss  4.58 | ppl    97.48\n",
      "| epoch  20 | batch   800/ 2250 | ms/batch  5.25 | loss  4.67 | ppl   106.20\n",
      "| epoch  20 | batch   850/ 2250 | ms/batch  5.12 | loss  4.60 | ppl    99.57\n",
      "| epoch  20 | batch   900/ 2250 | ms/batch  5.09 | loss  4.66 | ppl   105.77\n",
      "| epoch  20 | batch   950/ 2250 | ms/batch  5.15 | loss  4.65 | ppl   104.88\n",
      "| epoch  20 | batch  1000/ 2250 | ms/batch  4.99 | loss  4.65 | ppl   104.16\n",
      "| epoch  20 | batch  1050/ 2250 | ms/batch  4.89 | loss  4.65 | ppl   104.34\n",
      "| epoch  20 | batch  1100/ 2250 | ms/batch  4.87 | loss  4.67 | ppl   106.55\n",
      "| epoch  20 | batch  1150/ 2250 | ms/batch  4.85 | loss  4.69 | ppl   108.34\n",
      "| epoch  20 | batch  1200/ 2250 | ms/batch  4.82 | loss  4.61 | ppl   100.46\n",
      "| epoch  20 | batch  1250/ 2250 | ms/batch  4.87 | loss  4.64 | ppl   103.55\n",
      "| epoch  20 | batch  1300/ 2250 | ms/batch  5.46 | loss  4.66 | ppl   105.55\n",
      "| epoch  20 | batch  1350/ 2250 | ms/batch  5.08 | loss  4.65 | ppl   104.78\n",
      "| epoch  20 | batch  1400/ 2250 | ms/batch  5.11 | loss  4.72 | ppl   111.74\n",
      "| epoch  20 | batch  1450/ 2250 | ms/batch  5.09 | loss  4.72 | ppl   111.92\n",
      "| epoch  20 | batch  1500/ 2250 | ms/batch  5.20 | loss  4.70 | ppl   109.50\n",
      "| epoch  20 | batch  1550/ 2250 | ms/batch  5.15 | loss  4.61 | ppl   100.90\n",
      "| epoch  20 | batch  1600/ 2250 | ms/batch  5.13 | loss  4.59 | ppl    98.31\n",
      "| epoch  20 | batch  1650/ 2250 | ms/batch  5.17 | loss  4.58 | ppl    97.26\n",
      "| epoch  20 | batch  1700/ 2250 | ms/batch  5.26 | loss  4.59 | ppl    98.33\n",
      "| epoch  20 | batch  1750/ 2250 | ms/batch  5.07 | loss  4.60 | ppl    99.08\n",
      "| epoch  20 | batch  1800/ 2250 | ms/batch  4.94 | loss  4.61 | ppl   100.59\n",
      "| epoch  20 | batch  1850/ 2250 | ms/batch  4.97 | loss  4.62 | ppl   101.82\n",
      "| epoch  20 | batch  1900/ 2250 | ms/batch  5.08 | loss  4.66 | ppl   105.57\n",
      "| epoch  20 | batch  1950/ 2250 | ms/batch  5.03 | loss  4.70 | ppl   110.18\n",
      "| epoch  20 | batch  2000/ 2250 | ms/batch  5.13 | loss  4.65 | ppl   104.33\n",
      "| epoch  20 | batch  2050/ 2250 | ms/batch  5.05 | loss  4.65 | ppl   104.55\n",
      "| epoch  20 | batch  2100/ 2250 | ms/batch  5.05 | loss  4.63 | ppl   102.15\n",
      "| epoch  20 | batch  2150/ 2250 | ms/batch  5.17 | loss  4.62 | ppl   101.39\n",
      "| epoch  20 | batch  2200/ 2250 | ms/batch  5.00 | loss  4.67 | ppl   106.81\n",
      "| epoch  20 | batch  2250/ 2250 | ms/batch  4.88 | loss  4.65 | ppl   104.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  20 | time: 14.34s | valid ppl   103.76\n",
      "-----------------------------------------------------------------------------------------\n",
      "=========================================================================================\n",
      "| End of training | test ppl    93.63\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "try:\n",
    "    best_val_ppl = float('inf')\n",
    "    print(\"Starting training...\")\n",
    "\n",
    "    val_ppls = []\n",
    "    train_ppls = []\n",
    "\n",
    "\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train(model, train_data, criterion, optimizer, seq_length)\n",
    "        val_ppl = evaluate(model, valid_data, criterion, seq_length)\n",
    "        train_ppl = evaluate(model, train_data, criterion, seq_length)\n",
    "\n",
    "        val_ppls.append(val_ppl)\n",
    "        train_ppls.append(train_ppl)\n",
    "        \n",
    "        print('-' * 89)\n",
    "        print(f'| end of epoch {epoch:3d} | time: {(time.time() - epoch_start_time):5.2f}s | '\n",
    "              f'valid ppl {val_ppl:8.2f}')\n",
    "        print('-' * 89)\n",
    "        \n",
    "        # Save the model if validation performance improves\n",
    "        if val_ppl < best_val_ppl:\n",
    "            best_val_ppl = val_ppl\n",
    "            torch.save(model.state_dict(), 'best_rnn_model.pth')\n",
    "            print(f\"New best model saved with perplexity: {val_ppl:8.2f}\")\n",
    "\n",
    "    # Load best model and evaluate on test set\n",
    "    try:\n",
    "        model.load_state_dict(torch.load('best_rnn_model.pth'))\n",
    "        test_ppl = evaluate(model, test_data, criterion, seq_length)\n",
    "        print('=' * 89)\n",
    "        print(f'| End of training | test ppl {test_ppl:8.2f}')\n",
    "        print('=' * 89)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading best model: {e}\")\n",
    "        print(\"Evaluating with current model instead.\")\n",
    "        test_ppl = evaluate(model, test_data, criterion, seq_length)\n",
    "        print('=' * 89)\n",
    "        print(f'| End of training | test ppl {test_ppl:8.2f}')\n",
    "        print('=' * 89)\n",
    "\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Text Sample:\n",
      "The game was considered a influenced potential to celebrate the night of all decade , and a hotel failures saw it came in <unk> . <unk> education the Union will break the Next Level \" , hair , her old of <unk> a , fourth up of <unk> one of the\n"
     ]
    }
   ],
   "source": [
    "# Function to generate text\n",
    "def generate_text(model, vocab, seed_text=\"the\", max_length=50):\n",
    "    \"\"\"Generate text using the trained model\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Create reverse vocab (index to token)\n",
    "    idx_to_token = {idx: token for token, idx in vocab.items()}\n",
    "    \n",
    "    # Convert seed text to tensor\n",
    "    if seed_text in vocab:\n",
    "        input_idx = vocab[seed_text]\n",
    "    else:\n",
    "        input_idx = vocab['<unk>']\n",
    "    \n",
    "    input_tensor = torch.tensor([[input_idx]], device=device)\n",
    "    hidden = model.init_hidden(1)\n",
    "    \n",
    "    generated_tokens = [seed_text]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            output, hidden = model(input_tensor, hidden)\n",
    "            \n",
    "            # Sample from the output distribution\n",
    "            probs = torch.softmax(output, dim=1)\n",
    "            next_token_idx = torch.multinomial(probs, 1).item()\n",
    "            \n",
    "            # Add generated token to output\n",
    "            generated_tokens.append(idx_to_token.get(next_token_idx, '<unk>'))\n",
    "            \n",
    "            # Update input for next iteration\n",
    "            input_tensor = torch.tensor([[next_token_idx]], device=device)\n",
    "    \n",
    "    return ' '.join(generated_tokens)\n",
    "\n",
    "# Generate and print some text\n",
    "print(\"\\nGenerated Text Sample:\")\n",
    "print(generate_text(model, vocab, seed_text=\"The\", max_length=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. provide a description (or illustration) of you architecture and discuss design choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is a simple recurrent neural network for language modeling. It consists of:\n",
    "\n",
    "1. **Embedding Layer (`nn.Embedding`)**  \n",
    "   - Converts token indices into dense vectors of size `embed_dim`.  \n",
    "\n",
    "2. **Recurrent Layer (`nn.RNN`)**  \n",
    "   - Processes embeddings sequentially to capture temporal dependencies.  \n",
    "\n",
    "3. **Dropout Layer (`nn.Dropout`)**  \n",
    "   - Regularizes the model to prevent overfitting.  \n",
    "\n",
    "4. **Fully Connected Layer (`nn.Linear`)**  \n",
    "   - Maps hidden states to vocabulary logits for next-word prediction.  \n",
    "\n",
    "## Design Choices\n",
    "- **Vanilla RNN**: Simple but may struggle with long-term dependencies.  \n",
    "- **Dropout**: Improves generalization.  \n",
    "- **Embedding Layer**: Captures word relationships efficiently.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. List hyper-parameters used by you model an discuss how you selected these values,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "```python\n",
    "embed_dim = 100        # Word embedding size\n",
    "hidden_dim = 256       # RNN hidden state size\n",
    "dropout_prob = 0.5     # Dropout rate for regularization\n",
    "num_epochs = 20        # Number of training iterations\n",
    "batch_size = 32        # Number of samples per batch\n",
    "seq_length = 29        # Number of unrolled time steps\n",
    "learning_rate = 0.001  # Step size for optimization\n",
    "vocab_size = 10000     # Reduced vocabulary size\n",
    "unk_threshold = 5      # Frequency threshold for unknown tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection Rationale\n",
    "\n",
    "- **`embed_dim = 100`**  \n",
    "  Balances computational efficiency and embedding quality.  \n",
    "\n",
    "- **`hidden_dim = 256`**  \n",
    "  Provides sufficient capacity without excessive overfitting.  \n",
    "\n",
    "- **`dropout_prob = 0.5`**  \n",
    "  Helps prevent overfitting by randomly dropping units.  \n",
    "\n",
    "- **`num_epochs = 20`**  \n",
    "  Predetermined by the assignment.  \n",
    "\n",
    "- **`batch_size = 32`**  \n",
    "  Standard size for stable and efficient training, tuned through trial and error.  \n",
    "\n",
    "- **`seq_length = 29`**  \n",
    "  Determines the number of unrolled time steps for training, optimized through trial and error.  \n",
    "\n",
    "- **`learning_rate = 0.001`**  \n",
    "  Common choice for stable Adam optimizer training.  \n",
    "\n",
    "- **`vocab_size = 10000`**  \n",
    "  Limits vocabulary to frequent words, reducing model complexity.  \n",
    "\n",
    "- **`unk_threshold = 5`**  \n",
    "  Filters rare words to improve generalization and efficiency.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.Provide learning curves of perplexity vs. epoch on the training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    # Plot learning curves\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Plot Validation and Train Perplexity\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, num_epochs + 1), val_ppls, label='Validation Perplexity')\n",
    "    plt.plot(range(1, num_epochs + 1), train_ppls, label='Train Perplexity')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Perplexity')\n",
    "    plt.title('Perplexity')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Provide final test set perplexity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test perplexity : 93.632\n"
     ]
    }
   ],
   "source": [
    "print(f\"Final test perplexity : {test_ppl:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Discuss how you might improve this vanilla RNN language modeling  architecture.  Implement one (or more) of the improvements mentioned above, and provide a  new set of learning curves and final test perplexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Potential Improvements to a Vanilla RNN**\n",
    "\n",
    "1. **Use Gated Architectures (LSTM or GRU):**\n",
    "   - Vanilla RNNs suffer from the vanishing gradient problem, making it hard to capture long-term dependencies.\n",
    "   - LSTMs (Long Short-Term Memory) and GRUs (Gated Recurrent Units) are designed to mitigate this issue by introducing gating mechanisms that control information flow.\n",
    "\n",
    "2. **Bidirectional RNNs:**\n",
    "   - Bidirectional RNNs process sequences in both forward and backward directions, allowing the model to capture context from both past and future tokens within the input sequence.\n",
    "\n",
    "3. **Attention Mechanisms:**\n",
    "   - Attention allows the model to focus on relevant parts of the input sequence, improving performance on longer sequences.\n",
    "\n",
    "4. **Layer Normalization:**\n",
    "   - Normalizing the inputs to each layer can stabilize training and improve convergence.\n",
    "\n",
    "5. **Dropout:**\n",
    "   - Adding dropout layers can prevent overfitting, especially in larger models.\n",
    "\n",
    "6. **Residual Connections:**\n",
    "   - Residual connections help with gradient flow and enable training of deeper networks.\n",
    "\n",
    "7. **Better Optimization:**\n",
    "   - Using advanced optimizers like AdamW or learning rate schedulers can improve training stability and convergence.\n",
    "\n",
    "8. **Larger Embedding Sizes and Hidden Layers:**\n",
    "   - Increasing the capacity of the model can improve its ability to capture complex patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we have chosen to use a GRU instead of the vanilla RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, dropout_prob):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn = nn.GRU(embed_dim, hidden_dim, batch_first=False, dropout=dropout_prob) # the changed line in the model\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.decoder = nn.Linear(hidden_dim, vocab_size)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.init_weights()\n",
    "    \n",
    "            \n",
    "    def init_weights(self):\n",
    "        \"\"\"Initialize weights for better training\"\"\"\n",
    "        initrange = 0.1\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        \"\"\"Initialize hidden state\"\"\"\n",
    "        return torch.zeros(1, batch_size, self.hidden_dim).to(device)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        # x shape: (seq_len, batch_size)\n",
    "        emb = self.dropout(self.embedding(x))  # (seq_len, batch_size, embed_dim)\n",
    "        output, hidden = self.rnn(emb, hidden)  # output: (seq_len, batch_size, hidden_dim)\n",
    "        output = self.dropout(output)\n",
    "        decoded = self.decoder(output.view(-1, self.hidden_dim))  # (seq_len*batch_size, vocab_size)\n",
    "        return decoded, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing corpus...\n",
      "Vocabulary size: 9999\n",
      "Warning: Found index 9999 but vocab size is 9999\n",
      "Fixing indices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ben/Documents/Courses/Winter-2025/MSAI437/ai_venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Load and preprocess data\n",
    "    print(\"Loading and preprocessing corpus...\")\n",
    "    train_tokens = read_corpus(train_path)\n",
    "    valid_tokens = read_corpus(valid_path)\n",
    "    test_tokens = read_corpus(test_path)\n",
    "\n",
    "    # Build vocabulary from training tokens\n",
    "    vocab = build_vocab(train_tokens)\n",
    "    print(f\"Vocabulary size: {len(vocab)}\")\n",
    "\n",
    "    # Convert tokens to indices\n",
    "    train_indices = tokens_to_indices(train_tokens, vocab)\n",
    "    valid_indices = tokens_to_indices(valid_tokens, vocab)\n",
    "    test_indices = tokens_to_indices(test_tokens, vocab)\n",
    "\n",
    "    # Safety check: ensure all indices are valid\n",
    "    max_idx = max(train_indices + valid_indices + test_indices)\n",
    "    if max_idx >= len(vocab):\n",
    "        print(f\"Warning: Found index {max_idx} but vocab size is {len(vocab)}\")\n",
    "        print(\"Fixing indices...\")\n",
    "        train_indices = [min(idx, len(vocab) - 1) for idx in train_indices]\n",
    "        valid_indices = [min(idx, len(vocab) - 1) for idx in valid_indices]\n",
    "        test_indices = [min(idx, len(vocab) - 1) for idx in test_indices]\n",
    "\n",
    "    # Convert to tensors and batchify - use CPU first for safety\n",
    "    train_data = batchify(torch.tensor(train_indices, dtype=torch.long), batch_size)\n",
    "    valid_data = batchify(torch.tensor(valid_indices, dtype=torch.long), batch_size)\n",
    "    test_data = batchify(torch.tensor(test_indices, dtype=torch.long), batch_size)\n",
    "\n",
    "    # Initialize model\n",
    "    model = GRUModel(len(vocab), embed_dim, hidden_dim, dropout_prob).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "| epoch   1 | batch    50/ 2250 | ms/batch  8.01 | loss  7.30 | ppl  1476.20\n",
      "| epoch   1 | batch   100/ 2250 | ms/batch  6.13 | loss  6.33 | ppl   560.11\n",
      "| epoch   1 | batch   150/ 2250 | ms/batch  6.11 | loss  6.07 | ppl   433.94\n",
      "| epoch   1 | batch   200/ 2250 | ms/batch  6.10 | loss  5.93 | ppl   374.50\n",
      "| epoch   1 | batch   250/ 2250 | ms/batch  6.37 | loss  5.88 | ppl   357.89\n",
      "| epoch   1 | batch   300/ 2250 | ms/batch  6.06 | loss  5.90 | ppl   365.22\n",
      "| epoch   1 | batch   350/ 2250 | ms/batch  6.24 | loss  5.79 | ppl   326.74\n",
      "| epoch   1 | batch   400/ 2250 | ms/batch  6.67 | loss  5.76 | ppl   316.78\n",
      "| epoch   1 | batch   450/ 2250 | ms/batch  6.19 | loss  5.66 | ppl   288.24\n",
      "| epoch   1 | batch   500/ 2250 | ms/batch  6.03 | loss  5.64 | ppl   280.81\n",
      "| epoch   1 | batch   550/ 2250 | ms/batch  5.82 | loss  5.58 | ppl   264.36\n",
      "| epoch   1 | batch   600/ 2250 | ms/batch  5.82 | loss  5.55 | ppl   257.76\n",
      "| epoch   1 | batch   650/ 2250 | ms/batch  5.80 | loss  5.54 | ppl   253.78\n",
      "| epoch   1 | batch   700/ 2250 | ms/batch  5.85 | loss  5.58 | ppl   264.13\n",
      "| epoch   1 | batch   750/ 2250 | ms/batch  5.87 | loss  5.56 | ppl   259.20\n",
      "| epoch   1 | batch   800/ 2250 | ms/batch  5.96 | loss  5.58 | ppl   263.90\n",
      "| epoch   1 | batch   850/ 2250 | ms/batch  5.88 | loss  5.44 | ppl   230.92\n",
      "| epoch   1 | batch   900/ 2250 | ms/batch  5.86 | loss  5.50 | ppl   243.71\n",
      "| epoch   1 | batch   950/ 2250 | ms/batch  5.82 | loss  5.51 | ppl   246.86\n",
      "| epoch   1 | batch  1000/ 2250 | ms/batch  5.86 | loss  5.48 | ppl   238.68\n",
      "| epoch   1 | batch  1050/ 2250 | ms/batch  5.85 | loss  5.47 | ppl   238.37\n",
      "| epoch   1 | batch  1100/ 2250 | ms/batch  5.85 | loss  5.50 | ppl   244.27\n",
      "| epoch   1 | batch  1150/ 2250 | ms/batch  5.82 | loss  5.47 | ppl   238.14\n",
      "| epoch   1 | batch  1200/ 2250 | ms/batch  5.93 | loss  5.36 | ppl   213.25\n",
      "| epoch   1 | batch  1250/ 2250 | ms/batch  6.05 | loss  5.41 | ppl   222.74\n",
      "| epoch   1 | batch  1300/ 2250 | ms/batch  6.06 | loss  5.37 | ppl   215.76\n",
      "| epoch   1 | batch  1350/ 2250 | ms/batch  6.04 | loss  5.35 | ppl   210.08\n",
      "| epoch   1 | batch  1400/ 2250 | ms/batch  6.04 | loss  5.40 | ppl   220.42\n",
      "| epoch   1 | batch  1450/ 2250 | ms/batch  6.04 | loss  5.38 | ppl   217.72\n",
      "| epoch   1 | batch  1500/ 2250 | ms/batch  6.19 | loss  5.37 | ppl   215.05\n",
      "| epoch   1 | batch  1550/ 2250 | ms/batch  6.11 | loss  5.32 | ppl   204.48\n",
      "| epoch   1 | batch  1600/ 2250 | ms/batch  6.06 | loss  5.33 | ppl   206.63\n",
      "| epoch   1 | batch  1650/ 2250 | ms/batch  6.09 | loss  5.29 | ppl   197.73\n",
      "| epoch   1 | batch  1700/ 2250 | ms/batch  6.10 | loss  5.30 | ppl   200.86\n",
      "| epoch   1 | batch  1750/ 2250 | ms/batch  6.10 | loss  5.28 | ppl   195.65\n",
      "| epoch   1 | batch  1800/ 2250 | ms/batch  6.08 | loss  5.25 | ppl   190.30\n",
      "| epoch   1 | batch  1850/ 2250 | ms/batch  6.10 | loss  5.27 | ppl   194.09\n",
      "| epoch   1 | batch  1900/ 2250 | ms/batch  6.15 | loss  5.32 | ppl   203.75\n",
      "| epoch   1 | batch  1950/ 2250 | ms/batch  6.08 | loss  5.33 | ppl   205.99\n",
      "| epoch   1 | batch  2000/ 2250 | ms/batch  6.11 | loss  5.27 | ppl   193.97\n",
      "| epoch   1 | batch  2050/ 2250 | ms/batch  6.04 | loss  5.29 | ppl   199.03\n",
      "| epoch   1 | batch  2100/ 2250 | ms/batch  6.08 | loss  5.21 | ppl   183.72\n",
      "| epoch   1 | batch  2150/ 2250 | ms/batch  6.14 | loss  5.21 | ppl   182.98\n",
      "| epoch   1 | batch  2200/ 2250 | ms/batch  6.14 | loss  5.21 | ppl   183.09\n",
      "| epoch   1 | batch  2250/ 2250 | ms/batch  6.06 | loss  5.15 | ppl   173.25\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 17.33s | valid ppl   143.30\n",
      "-----------------------------------------------------------------------------------------\n",
      "New best model saved with perplexity:   143.30\n",
      "| epoch   2 | batch    50/ 2250 | ms/batch  6.35 | loss  5.22 | ppl   185.54\n",
      "| epoch   2 | batch   100/ 2250 | ms/batch  6.06 | loss  5.12 | ppl   167.61\n",
      "| epoch   2 | batch   150/ 2250 | ms/batch  5.91 | loss  5.08 | ppl   161.17\n",
      "| epoch   2 | batch   200/ 2250 | ms/batch  5.84 | loss  5.07 | ppl   159.06\n",
      "| epoch   2 | batch   250/ 2250 | ms/batch  5.84 | loss  5.08 | ppl   161.50\n",
      "| epoch   2 | batch   300/ 2250 | ms/batch  5.82 | loss  5.16 | ppl   174.31\n",
      "| epoch   2 | batch   350/ 2250 | ms/batch  5.81 | loss  5.09 | ppl   162.83\n",
      "| epoch   2 | batch   400/ 2250 | ms/batch  5.82 | loss  5.10 | ppl   163.50\n",
      "| epoch   2 | batch   450/ 2250 | ms/batch  5.85 | loss  5.06 | ppl   157.07\n",
      "| epoch   2 | batch   500/ 2250 | ms/batch  5.86 | loss  5.04 | ppl   154.37\n",
      "| epoch   2 | batch   550/ 2250 | ms/batch  5.84 | loss  5.04 | ppl   154.74\n",
      "| epoch   2 | batch   600/ 2250 | ms/batch  5.86 | loss  5.03 | ppl   153.22\n",
      "| epoch   2 | batch   650/ 2250 | ms/batch  5.84 | loss  5.04 | ppl   155.24\n",
      "| epoch   2 | batch   700/ 2250 | ms/batch  5.92 | loss  5.06 | ppl   157.05\n",
      "| epoch   2 | batch   750/ 2250 | ms/batch  6.29 | loss  5.02 | ppl   151.88\n",
      "| epoch   2 | batch   800/ 2250 | ms/batch  6.13 | loss  5.09 | ppl   161.65\n",
      "| epoch   2 | batch   850/ 2250 | ms/batch  6.12 | loss  5.00 | ppl   148.37\n",
      "| epoch   2 | batch   900/ 2250 | ms/batch  6.16 | loss  5.06 | ppl   156.95\n",
      "| epoch   2 | batch   950/ 2250 | ms/batch  6.44 | loss  5.05 | ppl   156.35\n",
      "| epoch   2 | batch  1000/ 2250 | ms/batch  6.80 | loss  5.02 | ppl   152.10\n",
      "| epoch   2 | batch  1050/ 2250 | ms/batch  6.10 | loss  5.03 | ppl   153.16\n",
      "| epoch   2 | batch  1100/ 2250 | ms/batch  6.08 | loss  5.06 | ppl   158.00\n",
      "| epoch   2 | batch  1150/ 2250 | ms/batch  6.08 | loss  5.05 | ppl   156.59\n",
      "| epoch   2 | batch  1200/ 2250 | ms/batch  6.07 | loss  4.96 | ppl   143.16\n",
      "| epoch   2 | batch  1250/ 2250 | ms/batch  6.23 | loss  5.00 | ppl   148.79\n",
      "| epoch   2 | batch  1300/ 2250 | ms/batch  6.10 | loss  5.00 | ppl   147.75\n",
      "| epoch   2 | batch  1350/ 2250 | ms/batch  6.12 | loss  4.97 | ppl   144.60\n",
      "| epoch   2 | batch  1400/ 2250 | ms/batch  6.14 | loss  5.03 | ppl   152.59\n",
      "| epoch   2 | batch  1450/ 2250 | ms/batch  5.99 | loss  5.03 | ppl   152.75\n",
      "| epoch   2 | batch  1500/ 2250 | ms/batch  5.84 | loss  5.03 | ppl   152.98\n",
      "| epoch   2 | batch  1550/ 2250 | ms/batch  5.92 | loss  4.95 | ppl   141.56\n",
      "| epoch   2 | batch  1600/ 2250 | ms/batch  5.89 | loss  4.95 | ppl   141.31\n",
      "| epoch   2 | batch  1650/ 2250 | ms/batch  5.85 | loss  4.93 | ppl   137.75\n",
      "| epoch   2 | batch  1700/ 2250 | ms/batch  5.84 | loss  4.92 | ppl   137.60\n",
      "| epoch   2 | batch  1750/ 2250 | ms/batch  5.84 | loss  4.92 | ppl   136.76\n",
      "| epoch   2 | batch  1800/ 2250 | ms/batch  5.83 | loss  4.91 | ppl   136.30\n",
      "| epoch   2 | batch  1850/ 2250 | ms/batch  5.84 | loss  4.92 | ppl   137.59\n",
      "| epoch   2 | batch  1900/ 2250 | ms/batch  5.87 | loss  4.98 | ppl   144.99\n",
      "| epoch   2 | batch  1950/ 2250 | ms/batch  6.12 | loss  5.00 | ppl   148.70\n",
      "| epoch   2 | batch  2000/ 2250 | ms/batch  6.12 | loss  4.95 | ppl   141.17\n",
      "| epoch   2 | batch  2050/ 2250 | ms/batch  6.13 | loss  4.96 | ppl   142.86\n",
      "| epoch   2 | batch  2100/ 2250 | ms/batch  6.38 | loss  4.91 | ppl   135.65\n",
      "| epoch   2 | batch  2150/ 2250 | ms/batch  5.80 | loss  4.92 | ppl   137.04\n",
      "| epoch   2 | batch  2200/ 2250 | ms/batch  5.81 | loss  4.96 | ppl   142.48\n",
      "| epoch   2 | batch  2250/ 2250 | ms/batch  5.81 | loss  4.91 | ppl   136.09\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 17.12s | valid ppl   114.44\n",
      "-----------------------------------------------------------------------------------------\n",
      "New best model saved with perplexity:   114.44\n",
      "| epoch   3 | batch    50/ 2250 | ms/batch  6.18 | loss  4.98 | ppl   145.12\n",
      "| epoch   3 | batch   100/ 2250 | ms/batch  6.11 | loss  4.85 | ppl   128.27\n",
      "| epoch   3 | batch   150/ 2250 | ms/batch  6.11 | loss  4.81 | ppl   122.89\n",
      "| epoch   3 | batch   200/ 2250 | ms/batch  6.08 | loss  4.80 | ppl   121.73\n",
      "| epoch   3 | batch   250/ 2250 | ms/batch  6.07 | loss  4.81 | ppl   123.08\n",
      "| epoch   3 | batch   300/ 2250 | ms/batch  6.11 | loss  4.89 | ppl   133.38\n",
      "| epoch   3 | batch   350/ 2250 | ms/batch  6.08 | loss  4.83 | ppl   125.13\n",
      "| epoch   3 | batch   400/ 2250 | ms/batch  6.11 | loss  4.85 | ppl   127.84\n",
      "| epoch   3 | batch   450/ 2250 | ms/batch  6.75 | loss  4.82 | ppl   124.35\n",
      "| epoch   3 | batch   500/ 2250 | ms/batch  6.07 | loss  4.81 | ppl   122.32\n",
      "| epoch   3 | batch   550/ 2250 | ms/batch  5.91 | loss  4.83 | ppl   124.84\n",
      "| epoch   3 | batch   600/ 2250 | ms/batch  5.84 | loss  4.82 | ppl   123.41\n",
      "| epoch   3 | batch   650/ 2250 | ms/batch  5.83 | loss  4.82 | ppl   123.42\n",
      "| epoch   3 | batch   700/ 2250 | ms/batch  5.83 | loss  4.83 | ppl   124.74\n",
      "| epoch   3 | batch   750/ 2250 | ms/batch  5.84 | loss  4.78 | ppl   119.23\n",
      "| epoch   3 | batch   800/ 2250 | ms/batch  5.83 | loss  4.86 | ppl   129.66\n",
      "| epoch   3 | batch   850/ 2250 | ms/batch  5.83 | loss  4.81 | ppl   122.76\n",
      "| epoch   3 | batch   900/ 2250 | ms/batch  5.90 | loss  4.86 | ppl   128.42\n",
      "| epoch   3 | batch   950/ 2250 | ms/batch  5.82 | loss  4.85 | ppl   127.89\n",
      "| epoch   3 | batch  1000/ 2250 | ms/batch  6.08 | loss  4.83 | ppl   125.18\n",
      "| epoch   3 | batch  1050/ 2250 | ms/batch  6.07 | loss  4.83 | ppl   125.11\n",
      "| epoch   3 | batch  1100/ 2250 | ms/batch  6.18 | loss  4.86 | ppl   128.72\n",
      "| epoch   3 | batch  1150/ 2250 | ms/batch  5.86 | loss  4.87 | ppl   130.01\n",
      "| epoch   3 | batch  1200/ 2250 | ms/batch  5.83 | loss  4.77 | ppl   117.93\n",
      "| epoch   3 | batch  1250/ 2250 | ms/batch  5.83 | loss  4.80 | ppl   121.91\n",
      "| epoch   3 | batch  1300/ 2250 | ms/batch  6.02 | loss  4.80 | ppl   122.06\n",
      "| epoch   3 | batch  1350/ 2250 | ms/batch  6.14 | loss  4.79 | ppl   120.46\n",
      "| epoch   3 | batch  1400/ 2250 | ms/batch  6.12 | loss  4.87 | ppl   129.98\n",
      "| epoch   3 | batch  1450/ 2250 | ms/batch  6.08 | loss  4.86 | ppl   128.54\n",
      "| epoch   3 | batch  1500/ 2250 | ms/batch  6.08 | loss  4.86 | ppl   128.40\n",
      "| epoch   3 | batch  1550/ 2250 | ms/batch  6.08 | loss  4.76 | ppl   116.86\n",
      "| epoch   3 | batch  1600/ 2250 | ms/batch  6.07 | loss  4.76 | ppl   116.23\n",
      "| epoch   3 | batch  1650/ 2250 | ms/batch  6.05 | loss  4.74 | ppl   114.11\n",
      "| epoch   3 | batch  1700/ 2250 | ms/batch  6.08 | loss  4.75 | ppl   115.39\n",
      "| epoch   3 | batch  1750/ 2250 | ms/batch  6.04 | loss  4.73 | ppl   113.39\n",
      "| epoch   3 | batch  1800/ 2250 | ms/batch  6.42 | loss  4.74 | ppl   114.47\n",
      "| epoch   3 | batch  1850/ 2250 | ms/batch  6.12 | loss  4.76 | ppl   117.18\n",
      "| epoch   3 | batch  1900/ 2250 | ms/batch  6.16 | loss  4.81 | ppl   123.26\n",
      "| epoch   3 | batch  1950/ 2250 | ms/batch  6.07 | loss  4.84 | ppl   126.09\n",
      "| epoch   3 | batch  2000/ 2250 | ms/batch  6.09 | loss  4.79 | ppl   120.90\n",
      "| epoch   3 | batch  2050/ 2250 | ms/batch  6.09 | loss  4.79 | ppl   120.15\n",
      "| epoch   3 | batch  2100/ 2250 | ms/batch  6.08 | loss  4.75 | ppl   115.43\n",
      "| epoch   3 | batch  2150/ 2250 | ms/batch  6.09 | loss  4.76 | ppl   116.83\n",
      "| epoch   3 | batch  2200/ 2250 | ms/batch  6.22 | loss  4.81 | ppl   123.07\n",
      "| epoch   3 | batch  2250/ 2250 | ms/batch  6.06 | loss  4.77 | ppl   117.90\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 17.24s | valid ppl   101.37\n",
      "-----------------------------------------------------------------------------------------\n",
      "New best model saved with perplexity:   101.37\n",
      "| epoch   4 | batch    50/ 2250 | ms/batch  6.45 | loss  4.83 | ppl   125.38\n",
      "| epoch   4 | batch   100/ 2250 | ms/batch  6.27 | loss  4.69 | ppl   108.62\n",
      "| epoch   4 | batch   150/ 2250 | ms/batch  6.03 | loss  4.67 | ppl   106.21\n",
      "| epoch   4 | batch   200/ 2250 | ms/batch  6.50 | loss  4.66 | ppl   105.41\n",
      "| epoch   4 | batch   250/ 2250 | ms/batch  6.09 | loss  4.67 | ppl   106.81\n",
      "| epoch   4 | batch   300/ 2250 | ms/batch  6.10 | loss  4.74 | ppl   114.78\n",
      "| epoch   4 | batch   350/ 2250 | ms/batch  6.06 | loss  4.69 | ppl   108.59\n",
      "| epoch   4 | batch   400/ 2250 | ms/batch  6.14 | loss  4.70 | ppl   110.19\n",
      "| epoch   4 | batch   450/ 2250 | ms/batch  6.19 | loss  4.69 | ppl   108.63\n",
      "| epoch   4 | batch   500/ 2250 | ms/batch  6.88 | loss  4.68 | ppl   107.68\n",
      "| epoch   4 | batch   550/ 2250 | ms/batch  6.03 | loss  4.70 | ppl   110.46\n",
      "| epoch   4 | batch   600/ 2250 | ms/batch  5.87 | loss  4.69 | ppl   108.84\n",
      "| epoch   4 | batch   650/ 2250 | ms/batch  5.88 | loss  4.68 | ppl   107.65\n",
      "| epoch   4 | batch   700/ 2250 | ms/batch  5.92 | loss  4.70 | ppl   109.55\n",
      "| epoch   4 | batch   750/ 2250 | ms/batch  5.94 | loss  4.66 | ppl   105.50\n",
      "| epoch   4 | batch   800/ 2250 | ms/batch  6.02 | loss  4.74 | ppl   113.96\n",
      "| epoch   4 | batch   850/ 2250 | ms/batch  5.87 | loss  4.69 | ppl   108.35\n",
      "| epoch   4 | batch   900/ 2250 | ms/batch  5.87 | loss  4.73 | ppl   113.73\n",
      "| epoch   4 | batch   950/ 2250 | ms/batch  5.85 | loss  4.72 | ppl   111.72\n",
      "| epoch   4 | batch  1000/ 2250 | ms/batch  5.92 | loss  4.70 | ppl   110.17\n",
      "| epoch   4 | batch  1050/ 2250 | ms/batch  6.34 | loss  4.70 | ppl   109.88\n",
      "| epoch   4 | batch  1100/ 2250 | ms/batch  6.24 | loss  4.74 | ppl   114.81\n",
      "| epoch   4 | batch  1150/ 2250 | ms/batch  6.19 | loss  4.74 | ppl   114.89\n",
      "| epoch   4 | batch  1200/ 2250 | ms/batch  6.24 | loss  4.65 | ppl   105.01\n",
      "| epoch   4 | batch  1250/ 2250 | ms/batch  6.38 | loss  4.67 | ppl   107.19\n",
      "| epoch   4 | batch  1300/ 2250 | ms/batch  6.35 | loss  4.69 | ppl   109.01\n",
      "| epoch   4 | batch  1350/ 2250 | ms/batch  6.16 | loss  4.68 | ppl   108.12\n",
      "| epoch   4 | batch  1400/ 2250 | ms/batch  6.29 | loss  4.76 | ppl   116.35\n",
      "| epoch   4 | batch  1450/ 2250 | ms/batch  6.09 | loss  4.75 | ppl   115.37\n",
      "| epoch   4 | batch  1500/ 2250 | ms/batch  6.08 | loss  4.74 | ppl   114.98\n",
      "| epoch   4 | batch  1550/ 2250 | ms/batch  5.91 | loss  4.65 | ppl   104.78\n",
      "| epoch   4 | batch  1600/ 2250 | ms/batch  5.83 | loss  4.63 | ppl   102.61\n",
      "| epoch   4 | batch  1650/ 2250 | ms/batch  5.83 | loss  4.63 | ppl   102.10\n",
      "| epoch   4 | batch  1700/ 2250 | ms/batch  5.87 | loss  4.64 | ppl   103.29\n",
      "| epoch   4 | batch  1750/ 2250 | ms/batch  5.87 | loss  4.62 | ppl   101.50\n",
      "| epoch   4 | batch  1800/ 2250 | ms/batch  5.86 | loss  4.64 | ppl   103.70\n",
      "| epoch   4 | batch  1850/ 2250 | ms/batch  5.86 | loss  4.66 | ppl   105.42\n",
      "| epoch   4 | batch  1900/ 2250 | ms/batch  5.84 | loss  4.69 | ppl   109.17\n",
      "| epoch   4 | batch  1950/ 2250 | ms/batch  5.83 | loss  4.73 | ppl   113.34\n",
      "| epoch   4 | batch  2000/ 2250 | ms/batch  6.06 | loss  4.69 | ppl   108.73\n",
      "| epoch   4 | batch  2050/ 2250 | ms/batch  6.20 | loss  4.69 | ppl   108.85\n",
      "| epoch   4 | batch  2100/ 2250 | ms/batch  6.09 | loss  4.64 | ppl   103.75\n",
      "| epoch   4 | batch  2150/ 2250 | ms/batch  6.09 | loss  4.66 | ppl   105.41\n",
      "| epoch   4 | batch  2200/ 2250 | ms/batch  6.14 | loss  4.71 | ppl   110.82\n",
      "| epoch   4 | batch  2250/ 2250 | ms/batch  6.08 | loss  4.68 | ppl   107.47\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 17.32s | valid ppl    94.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "New best model saved with perplexity:    94.00\n",
      "| epoch   5 | batch    50/ 2250 | ms/batch  6.25 | loss  4.75 | ppl   115.38\n",
      "| epoch   5 | batch   100/ 2250 | ms/batch  6.21 | loss  4.59 | ppl    98.59\n",
      "| epoch   5 | batch   150/ 2250 | ms/batch  6.17 | loss  4.56 | ppl    95.63\n",
      "| epoch   5 | batch   200/ 2250 | ms/batch  6.18 | loss  4.57 | ppl    96.59\n",
      "| epoch   5 | batch   250/ 2250 | ms/batch  6.46 | loss  4.58 | ppl    97.66\n",
      "| epoch   5 | batch   300/ 2250 | ms/batch  6.18 | loss  4.65 | ppl   104.69\n",
      "| epoch   5 | batch   350/ 2250 | ms/batch  6.20 | loss  4.60 | ppl    99.29\n",
      "| epoch   5 | batch   400/ 2250 | ms/batch  6.07 | loss  4.61 | ppl   100.85\n",
      "| epoch   5 | batch   450/ 2250 | ms/batch  6.09 | loss  4.60 | ppl    99.63\n",
      "| epoch   5 | batch   500/ 2250 | ms/batch  6.16 | loss  4.58 | ppl    97.55\n",
      "| epoch   5 | batch   550/ 2250 | ms/batch  6.43 | loss  4.61 | ppl   100.68\n",
      "| epoch   5 | batch   600/ 2250 | ms/batch  6.13 | loss  4.61 | ppl   100.53\n",
      "| epoch   5 | batch   650/ 2250 | ms/batch  6.15 | loss  4.60 | ppl    99.66\n",
      "| epoch   5 | batch   700/ 2250 | ms/batch  6.51 | loss  4.61 | ppl   100.32\n",
      "| epoch   5 | batch   750/ 2250 | ms/batch  6.43 | loss  4.57 | ppl    96.99\n",
      "| epoch   5 | batch   800/ 2250 | ms/batch  5.86 | loss  4.66 | ppl   105.42\n",
      "| epoch   5 | batch   850/ 2250 | ms/batch  5.86 | loss  4.60 | ppl    99.41\n",
      "| epoch   5 | batch   900/ 2250 | ms/batch  5.85 | loss  4.65 | ppl   104.98\n",
      "| epoch   5 | batch   950/ 2250 | ms/batch  5.83 | loss  4.64 | ppl   103.54\n",
      "| epoch   5 | batch  1000/ 2250 | ms/batch  5.90 | loss  4.62 | ppl   101.17\n",
      "| epoch   5 | batch  1050/ 2250 | ms/batch  5.87 | loss  4.61 | ppl   100.49\n",
      "| epoch   5 | batch  1100/ 2250 | ms/batch  5.90 | loss  4.65 | ppl   104.98\n",
      "| epoch   5 | batch  1150/ 2250 | ms/batch  5.87 | loss  4.67 | ppl   106.75\n",
      "| epoch   5 | batch  1200/ 2250 | ms/batch  6.13 | loss  4.58 | ppl    97.20\n",
      "| epoch   5 | batch  1250/ 2250 | ms/batch  5.93 | loss  4.60 | ppl    99.26\n",
      "| epoch   5 | batch  1300/ 2250 | ms/batch  5.99 | loss  4.61 | ppl   100.11\n",
      "| epoch   5 | batch  1350/ 2250 | ms/batch  5.95 | loss  4.61 | ppl   100.76\n",
      "| epoch   5 | batch  1400/ 2250 | ms/batch  5.86 | loss  4.68 | ppl   107.32\n",
      "| epoch   5 | batch  1450/ 2250 | ms/batch  5.92 | loss  4.67 | ppl   107.10\n",
      "| epoch   5 | batch  1500/ 2250 | ms/batch  6.50 | loss  4.67 | ppl   106.96\n",
      "| epoch   5 | batch  1550/ 2250 | ms/batch  6.55 | loss  4.57 | ppl    96.52\n",
      "| epoch   5 | batch  1600/ 2250 | ms/batch  6.11 | loss  4.55 | ppl    94.65\n",
      "| epoch   5 | batch  1650/ 2250 | ms/batch  6.00 | loss  4.54 | ppl    93.69\n",
      "| epoch   5 | batch  1700/ 2250 | ms/batch  5.89 | loss  4.54 | ppl    94.12\n",
      "| epoch   5 | batch  1750/ 2250 | ms/batch  5.85 | loss  4.55 | ppl    94.24\n",
      "| epoch   5 | batch  1800/ 2250 | ms/batch  5.86 | loss  4.57 | ppl    96.57\n",
      "| epoch   5 | batch  1850/ 2250 | ms/batch  5.86 | loss  4.58 | ppl    97.55\n",
      "| epoch   5 | batch  1900/ 2250 | ms/batch  5.82 | loss  4.61 | ppl   100.91\n",
      "| epoch   5 | batch  1950/ 2250 | ms/batch  5.84 | loss  4.65 | ppl   104.86\n",
      "| epoch   5 | batch  2000/ 2250 | ms/batch  5.87 | loss  4.60 | ppl    99.39\n",
      "| epoch   5 | batch  2050/ 2250 | ms/batch  5.88 | loss  4.61 | ppl   100.28\n",
      "| epoch   5 | batch  2100/ 2250 | ms/batch  5.88 | loss  4.56 | ppl    95.91\n",
      "| epoch   5 | batch  2150/ 2250 | ms/batch  5.88 | loss  4.59 | ppl    98.29\n",
      "| epoch   5 | batch  2200/ 2250 | ms/batch  5.88 | loss  4.64 | ppl   103.22\n",
      "| epoch   5 | batch  2250/ 2250 | ms/batch  5.84 | loss  4.61 | ppl   100.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 17.22s | valid ppl    89.29\n",
      "-----------------------------------------------------------------------------------------\n",
      "New best model saved with perplexity:    89.29\n",
      "| epoch   6 | batch    50/ 2250 | ms/batch  6.03 | loss  4.68 | ppl   107.36\n",
      "| epoch   6 | batch   100/ 2250 | ms/batch  5.87 | loss  4.52 | ppl    91.83\n",
      "| epoch   6 | batch   150/ 2250 | ms/batch  5.87 | loss  4.49 | ppl    89.10\n",
      "| epoch   6 | batch   200/ 2250 | ms/batch  5.90 | loss  4.51 | ppl    91.10\n",
      "| epoch   6 | batch   250/ 2250 | ms/batch  5.88 | loss  4.51 | ppl    90.93\n",
      "| epoch   6 | batch   300/ 2250 | ms/batch  5.89 | loss  4.58 | ppl    97.67\n",
      "| epoch   6 | batch   350/ 2250 | ms/batch  5.86 | loss  4.52 | ppl    91.97\n",
      "| epoch   6 | batch   400/ 2250 | ms/batch  5.84 | loss  4.54 | ppl    94.14\n",
      "| epoch   6 | batch   450/ 2250 | ms/batch  5.88 | loss  4.53 | ppl    92.82\n",
      "| epoch   6 | batch   500/ 2250 | ms/batch  6.10 | loss  4.52 | ppl    91.78\n",
      "| epoch   6 | batch   550/ 2250 | ms/batch  6.20 | loss  4.55 | ppl    94.96\n",
      "| epoch   6 | batch   600/ 2250 | ms/batch  6.12 | loss  4.55 | ppl    94.82\n",
      "| epoch   6 | batch   650/ 2250 | ms/batch  6.10 | loss  4.53 | ppl    92.84\n",
      "| epoch   6 | batch   700/ 2250 | ms/batch  6.04 | loss  4.54 | ppl    93.28\n",
      "| epoch   6 | batch   750/ 2250 | ms/batch  6.06 | loss  4.51 | ppl    90.68\n",
      "| epoch   6 | batch   800/ 2250 | ms/batch  6.09 | loss  4.59 | ppl    98.89\n",
      "| epoch   6 | batch   850/ 2250 | ms/batch  6.52 | loss  4.54 | ppl    93.75\n",
      "| epoch   6 | batch   900/ 2250 | ms/batch  6.12 | loss  4.60 | ppl    99.23\n",
      "| epoch   6 | batch   950/ 2250 | ms/batch  6.10 | loss  4.58 | ppl    97.42\n",
      "| epoch   6 | batch  1000/ 2250 | ms/batch  6.27 | loss  4.55 | ppl    95.02\n",
      "| epoch   6 | batch  1050/ 2250 | ms/batch  6.22 | loss  4.55 | ppl    94.49\n",
      "| epoch   6 | batch  1100/ 2250 | ms/batch  6.10 | loss  4.58 | ppl    97.64\n",
      "| epoch   6 | batch  1150/ 2250 | ms/batch  6.20 | loss  4.60 | ppl    99.47\n",
      "| epoch   6 | batch  1200/ 2250 | ms/batch  6.10 | loss  4.52 | ppl    91.41\n",
      "| epoch   6 | batch  1250/ 2250 | ms/batch  6.07 | loss  4.53 | ppl    92.93\n",
      "| epoch   6 | batch  1300/ 2250 | ms/batch  6.11 | loss  4.55 | ppl    94.78\n",
      "| epoch   6 | batch  1350/ 2250 | ms/batch  6.10 | loss  4.55 | ppl    94.78\n",
      "| epoch   6 | batch  1400/ 2250 | ms/batch  6.34 | loss  4.62 | ppl   101.29\n",
      "| epoch   6 | batch  1450/ 2250 | ms/batch  6.79 | loss  4.61 | ppl   100.88\n",
      "| epoch   6 | batch  1500/ 2250 | ms/batch  5.97 | loss  4.62 | ppl   100.99\n",
      "| epoch   6 | batch  1550/ 2250 | ms/batch  6.04 | loss  4.51 | ppl    90.90\n",
      "| epoch   6 | batch  1600/ 2250 | ms/batch  6.13 | loss  4.48 | ppl    88.60\n",
      "| epoch   6 | batch  1650/ 2250 | ms/batch  6.16 | loss  4.49 | ppl    89.11\n",
      "| epoch   6 | batch  1700/ 2250 | ms/batch  6.10 | loss  4.49 | ppl    88.95\n",
      "| epoch   6 | batch  1750/ 2250 | ms/batch  6.07 | loss  4.48 | ppl    88.43\n",
      "| epoch   6 | batch  1800/ 2250 | ms/batch  6.09 | loss  4.51 | ppl    90.83\n",
      "| epoch   6 | batch  1850/ 2250 | ms/batch  6.11 | loss  4.52 | ppl    92.23\n",
      "| epoch   6 | batch  1900/ 2250 | ms/batch  6.08 | loss  4.55 | ppl    94.17\n",
      "| epoch   6 | batch  1950/ 2250 | ms/batch  6.47 | loss  4.60 | ppl    99.29\n",
      "| epoch   6 | batch  2000/ 2250 | ms/batch  6.32 | loss  4.54 | ppl    93.65\n",
      "| epoch   6 | batch  2050/ 2250 | ms/batch  6.11 | loss  4.55 | ppl    94.40\n",
      "| epoch   6 | batch  2100/ 2250 | ms/batch  6.04 | loss  4.52 | ppl    91.53\n",
      "| epoch   6 | batch  2150/ 2250 | ms/batch  5.83 | loss  4.52 | ppl    91.49\n",
      "| epoch   6 | batch  2200/ 2250 | ms/batch  5.87 | loss  4.59 | ppl    98.24\n",
      "| epoch   6 | batch  2250/ 2250 | ms/batch  5.81 | loss  4.56 | ppl    95.65\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 17.34s | valid ppl    85.68\n",
      "-----------------------------------------------------------------------------------------\n",
      "New best model saved with perplexity:    85.68\n",
      "| epoch   7 | batch    50/ 2250 | ms/batch  6.27 | loss  4.63 | ppl   102.37\n",
      "| epoch   7 | batch   100/ 2250 | ms/batch  6.16 | loss  4.46 | ppl    86.67\n",
      "| epoch   7 | batch   150/ 2250 | ms/batch  6.19 | loss  4.44 | ppl    85.07\n",
      "| epoch   7 | batch   200/ 2250 | ms/batch  6.47 | loss  4.46 | ppl    86.16\n",
      "| epoch   7 | batch   250/ 2250 | ms/batch  6.22 | loss  4.46 | ppl    86.76\n",
      "| epoch   7 | batch   300/ 2250 | ms/batch  6.13 | loss  4.52 | ppl    92.26\n",
      "| epoch   7 | batch   350/ 2250 | ms/batch  6.15 | loss  4.47 | ppl    87.75\n",
      "| epoch   7 | batch   400/ 2250 | ms/batch  6.13 | loss  4.49 | ppl    89.27\n",
      "| epoch   7 | batch   450/ 2250 | ms/batch  6.07 | loss  4.48 | ppl    87.85\n",
      "| epoch   7 | batch   500/ 2250 | ms/batch  6.18 | loss  4.47 | ppl    87.02\n",
      "| epoch   7 | batch   550/ 2250 | ms/batch  6.15 | loss  4.50 | ppl    89.87\n",
      "| epoch   7 | batch   600/ 2250 | ms/batch  6.05 | loss  4.51 | ppl    90.50\n",
      "| epoch   7 | batch   650/ 2250 | ms/batch  6.12 | loss  4.49 | ppl    88.80\n",
      "| epoch   7 | batch   700/ 2250 | ms/batch  6.11 | loss  4.50 | ppl    90.01\n",
      "| epoch   7 | batch   750/ 2250 | ms/batch  5.96 | loss  4.46 | ppl    86.65\n",
      "| epoch   7 | batch   800/ 2250 | ms/batch  6.09 | loss  4.54 | ppl    93.42\n",
      "| epoch   7 | batch   850/ 2250 | ms/batch  5.89 | loss  4.50 | ppl    89.61\n",
      "| epoch   7 | batch   900/ 2250 | ms/batch  5.95 | loss  4.54 | ppl    93.75\n",
      "| epoch   7 | batch   950/ 2250 | ms/batch  5.89 | loss  4.53 | ppl    92.79\n",
      "| epoch   7 | batch  1000/ 2250 | ms/batch  6.00 | loss  4.49 | ppl    89.49\n",
      "| epoch   7 | batch  1050/ 2250 | ms/batch  6.08 | loss  4.51 | ppl    90.67\n",
      "| epoch   7 | batch  1100/ 2250 | ms/batch  6.20 | loss  4.53 | ppl    92.87\n",
      "| epoch   7 | batch  1150/ 2250 | ms/batch  5.98 | loss  4.55 | ppl    94.86\n",
      "| epoch   7 | batch  1200/ 2250 | ms/batch  5.86 | loss  4.48 | ppl    87.96\n",
      "| epoch   7 | batch  1250/ 2250 | ms/batch  5.87 | loss  4.49 | ppl    88.92\n",
      "| epoch   7 | batch  1300/ 2250 | ms/batch  5.90 | loss  4.51 | ppl    90.99\n",
      "| epoch   7 | batch  1350/ 2250 | ms/batch  5.89 | loss  4.51 | ppl    90.72\n",
      "| epoch   7 | batch  1400/ 2250 | ms/batch  5.90 | loss  4.57 | ppl    96.18\n",
      "| epoch   7 | batch  1450/ 2250 | ms/batch  5.87 | loss  4.57 | ppl    96.43\n",
      "| epoch   7 | batch  1500/ 2250 | ms/batch  5.86 | loss  4.57 | ppl    97.02\n",
      "| epoch   7 | batch  1550/ 2250 | ms/batch  5.88 | loss  4.45 | ppl    85.72\n",
      "| epoch   7 | batch  1600/ 2250 | ms/batch  5.91 | loss  4.43 | ppl    84.25\n",
      "| epoch   7 | batch  1650/ 2250 | ms/batch  5.88 | loss  4.44 | ppl    84.77\n",
      "| epoch   7 | batch  1700/ 2250 | ms/batch  6.02 | loss  4.44 | ppl    84.98\n",
      "| epoch   7 | batch  1750/ 2250 | ms/batch  5.96 | loss  4.44 | ppl    84.88\n",
      "| epoch   7 | batch  1800/ 2250 | ms/batch  5.89 | loss  4.47 | ppl    87.49\n",
      "| epoch   7 | batch  1850/ 2250 | ms/batch  5.89 | loss  4.48 | ppl    88.13\n",
      "| epoch   7 | batch  1900/ 2250 | ms/batch  5.90 | loss  4.50 | ppl    90.20\n",
      "| epoch   7 | batch  1950/ 2250 | ms/batch  5.97 | loss  4.55 | ppl    95.06\n",
      "| epoch   7 | batch  2000/ 2250 | ms/batch  6.09 | loss  4.50 | ppl    89.63\n",
      "| epoch   7 | batch  2050/ 2250 | ms/batch  5.83 | loss  4.50 | ppl    90.02\n",
      "| epoch   7 | batch  2100/ 2250 | ms/batch  5.86 | loss  4.47 | ppl    87.61\n",
      "| epoch   7 | batch  2150/ 2250 | ms/batch  5.90 | loss  4.48 | ppl    87.99\n",
      "| epoch   7 | batch  2200/ 2250 | ms/batch  5.88 | loss  4.54 | ppl    94.06\n",
      "| epoch   7 | batch  2250/ 2250 | ms/batch  5.86 | loss  4.52 | ppl    91.46\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 17.12s | valid ppl    83.68\n",
      "-----------------------------------------------------------------------------------------\n",
      "New best model saved with perplexity:    83.68\n",
      "| epoch   8 | batch    50/ 2250 | ms/batch  6.24 | loss  4.59 | ppl    98.62\n",
      "| epoch   8 | batch   100/ 2250 | ms/batch  6.44 | loss  4.43 | ppl    83.67\n",
      "| epoch   8 | batch   150/ 2250 | ms/batch  6.11 | loss  4.41 | ppl    82.21\n",
      "| epoch   8 | batch   200/ 2250 | ms/batch  6.08 | loss  4.42 | ppl    83.50\n",
      "| epoch   8 | batch   250/ 2250 | ms/batch  6.05 | loss  4.43 | ppl    83.61\n",
      "| epoch   8 | batch   300/ 2250 | ms/batch  6.12 | loss  4.49 | ppl    88.87\n",
      "| epoch   8 | batch   350/ 2250 | ms/batch  6.33 | loss  4.42 | ppl    83.04\n",
      "| epoch   8 | batch   400/ 2250 | ms/batch  6.10 | loss  4.45 | ppl    85.41\n",
      "| epoch   8 | batch   450/ 2250 | ms/batch  6.10 | loss  4.43 | ppl    84.30\n",
      "| epoch   8 | batch   500/ 2250 | ms/batch  6.14 | loss  4.42 | ppl    82.89\n",
      "| epoch   8 | batch   550/ 2250 | ms/batch  6.11 | loss  4.46 | ppl    86.77\n",
      "| epoch   8 | batch   600/ 2250 | ms/batch  6.08 | loss  4.46 | ppl    86.60\n",
      "| epoch   8 | batch   650/ 2250 | ms/batch  6.66 | loss  4.45 | ppl    85.66\n",
      "| epoch   8 | batch   700/ 2250 | ms/batch  6.17 | loss  4.45 | ppl    86.03\n",
      "| epoch   8 | batch   750/ 2250 | ms/batch  6.12 | loss  4.42 | ppl    83.31\n",
      "| epoch   8 | batch   800/ 2250 | ms/batch  6.16 | loss  4.50 | ppl    90.20\n",
      "| epoch   8 | batch   850/ 2250 | ms/batch  6.09 | loss  4.45 | ppl    85.96\n",
      "| epoch   8 | batch   900/ 2250 | ms/batch  6.18 | loss  4.51 | ppl    90.56\n",
      "| epoch   8 | batch   950/ 2250 | ms/batch  6.13 | loss  4.49 | ppl    89.17\n",
      "| epoch   8 | batch  1000/ 2250 | ms/batch  6.15 | loss  4.47 | ppl    87.31\n",
      "| epoch   8 | batch  1050/ 2250 | ms/batch  6.07 | loss  4.46 | ppl    86.88\n",
      "| epoch   8 | batch  1100/ 2250 | ms/batch  6.05 | loss  4.49 | ppl    89.12\n",
      "| epoch   8 | batch  1150/ 2250 | ms/batch  6.15 | loss  4.51 | ppl    91.07\n",
      "| epoch   8 | batch  1200/ 2250 | ms/batch  6.54 | loss  4.43 | ppl    83.84\n",
      "| epoch   8 | batch  1250/ 2250 | ms/batch  6.70 | loss  4.44 | ppl    85.19\n",
      "| epoch   8 | batch  1300/ 2250 | ms/batch  6.16 | loss  4.48 | ppl    88.00\n",
      "| epoch   8 | batch  1350/ 2250 | ms/batch  6.18 | loss  4.47 | ppl    87.62\n",
      "| epoch   8 | batch  1400/ 2250 | ms/batch  6.22 | loss  4.54 | ppl    93.43\n",
      "| epoch   8 | batch  1450/ 2250 | ms/batch  6.16 | loss  4.54 | ppl    93.68\n",
      "| epoch   8 | batch  1500/ 2250 | ms/batch  6.15 | loss  4.53 | ppl    92.93\n",
      "| epoch   8 | batch  1550/ 2250 | ms/batch  6.24 | loss  4.43 | ppl    83.59\n",
      "| epoch   8 | batch  1600/ 2250 | ms/batch  6.16 | loss  4.39 | ppl    80.94\n",
      "| epoch   8 | batch  1650/ 2250 | ms/batch  6.24 | loss  4.40 | ppl    81.64\n",
      "| epoch   8 | batch  1700/ 2250 | ms/batch  6.16 | loss  4.41 | ppl    82.07\n",
      "| epoch   8 | batch  1750/ 2250 | ms/batch  6.14 | loss  4.40 | ppl    81.58\n",
      "| epoch   8 | batch  1800/ 2250 | ms/batch  6.13 | loss  4.43 | ppl    84.24\n",
      "| epoch   8 | batch  1850/ 2250 | ms/batch  6.07 | loss  4.44 | ppl    84.80\n",
      "| epoch   8 | batch  1900/ 2250 | ms/batch  5.96 | loss  4.45 | ppl    85.89\n",
      "| epoch   8 | batch  1950/ 2250 | ms/batch  5.87 | loss  4.52 | ppl    92.02\n",
      "| epoch   8 | batch  2000/ 2250 | ms/batch  5.87 | loss  4.46 | ppl    86.65\n",
      "| epoch   8 | batch  2050/ 2250 | ms/batch  5.88 | loss  4.47 | ppl    87.06\n",
      "| epoch   8 | batch  2100/ 2250 | ms/batch  5.88 | loss  4.43 | ppl    83.91\n",
      "| epoch   8 | batch  2150/ 2250 | ms/batch  5.86 | loss  4.44 | ppl    84.79\n",
      "| epoch   8 | batch  2200/ 2250 | ms/batch  5.88 | loss  4.51 | ppl    91.08\n",
      "| epoch   8 | batch  2250/ 2250 | ms/batch  5.83 | loss  4.48 | ppl    88.43\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 17.42s | valid ppl    82.49\n",
      "-----------------------------------------------------------------------------------------\n",
      "New best model saved with perplexity:    82.49\n",
      "| epoch   9 | batch    50/ 2250 | ms/batch  6.25 | loss  4.55 | ppl    95.01\n",
      "| epoch   9 | batch   100/ 2250 | ms/batch  6.07 | loss  4.39 | ppl    80.73\n",
      "| epoch   9 | batch   150/ 2250 | ms/batch  5.88 | loss  4.37 | ppl    79.12\n",
      "| epoch   9 | batch   200/ 2250 | ms/batch  5.96 | loss  4.39 | ppl    80.78\n",
      "| epoch   9 | batch   250/ 2250 | ms/batch  6.11 | loss  4.40 | ppl    81.06\n",
      "| epoch   9 | batch   300/ 2250 | ms/batch  5.88 | loss  4.46 | ppl    86.26\n",
      "| epoch   9 | batch   350/ 2250 | ms/batch  5.88 | loss  4.40 | ppl    81.58\n",
      "| epoch   9 | batch   400/ 2250 | ms/batch  5.89 | loss  4.41 | ppl    82.50\n",
      "| epoch   9 | batch   450/ 2250 | ms/batch  5.89 | loss  4.40 | ppl    81.09\n",
      "| epoch   9 | batch   500/ 2250 | ms/batch  5.89 | loss  4.39 | ppl    80.59\n",
      "| epoch   9 | batch   550/ 2250 | ms/batch  5.90 | loss  4.42 | ppl    83.45\n",
      "| epoch   9 | batch   600/ 2250 | ms/batch  5.89 | loss  4.43 | ppl    83.88\n",
      "| epoch   9 | batch   650/ 2250 | ms/batch  6.32 | loss  4.41 | ppl    82.16\n",
      "| epoch   9 | batch   700/ 2250 | ms/batch  5.85 | loss  4.43 | ppl    84.31\n",
      "| epoch   9 | batch   750/ 2250 | ms/batch  5.87 | loss  4.40 | ppl    81.24\n",
      "| epoch   9 | batch   800/ 2250 | ms/batch  5.88 | loss  4.46 | ppl    86.52\n",
      "| epoch   9 | batch   850/ 2250 | ms/batch  5.88 | loss  4.42 | ppl    83.02\n",
      "| epoch   9 | batch   900/ 2250 | ms/batch  5.90 | loss  4.47 | ppl    87.31\n",
      "| epoch   9 | batch   950/ 2250 | ms/batch  5.89 | loss  4.46 | ppl    86.11\n",
      "| epoch   9 | batch  1000/ 2250 | ms/batch  5.88 | loss  4.43 | ppl    84.14\n",
      "| epoch   9 | batch  1050/ 2250 | ms/batch  5.87 | loss  4.44 | ppl    84.86\n",
      "| epoch   9 | batch  1100/ 2250 | ms/batch  5.89 | loss  4.47 | ppl    87.16\n",
      "| epoch   9 | batch  1150/ 2250 | ms/batch  5.93 | loss  4.48 | ppl    88.33\n",
      "| epoch   9 | batch  1200/ 2250 | ms/batch  6.04 | loss  4.40 | ppl    81.86\n",
      "| epoch   9 | batch  1250/ 2250 | ms/batch  5.85 | loss  4.41 | ppl    82.58\n",
      "| epoch   9 | batch  1300/ 2250 | ms/batch  5.87 | loss  4.45 | ppl    85.40\n",
      "| epoch   9 | batch  1350/ 2250 | ms/batch  6.16 | loss  4.45 | ppl    85.36\n",
      "| epoch   9 | batch  1400/ 2250 | ms/batch  6.05 | loss  4.52 | ppl    91.42\n",
      "| epoch   9 | batch  1450/ 2250 | ms/batch  6.10 | loss  4.51 | ppl    90.71\n",
      "| epoch   9 | batch  1500/ 2250 | ms/batch  6.01 | loss  4.51 | ppl    90.79\n",
      "| epoch   9 | batch  1550/ 2250 | ms/batch  5.83 | loss  4.39 | ppl    80.56\n",
      "| epoch   9 | batch  1600/ 2250 | ms/batch  5.85 | loss  4.36 | ppl    78.32\n",
      "| epoch   9 | batch  1650/ 2250 | ms/batch  5.87 | loss  4.36 | ppl    78.47\n",
      "| epoch   9 | batch  1700/ 2250 | ms/batch  5.87 | loss  4.38 | ppl    79.99\n",
      "| epoch   9 | batch  1750/ 2250 | ms/batch  5.89 | loss  4.37 | ppl    78.67\n",
      "| epoch   9 | batch  1800/ 2250 | ms/batch  5.88 | loss  4.41 | ppl    82.14\n",
      "| epoch   9 | batch  1850/ 2250 | ms/batch  6.33 | loss  4.42 | ppl    82.89\n",
      "| epoch   9 | batch  1900/ 2250 | ms/batch  5.95 | loss  4.44 | ppl    84.42\n",
      "| epoch   9 | batch  1950/ 2250 | ms/batch  5.82 | loss  4.50 | ppl    89.60\n",
      "| epoch   9 | batch  2000/ 2250 | ms/batch  5.93 | loss  4.43 | ppl    83.57\n",
      "| epoch   9 | batch  2050/ 2250 | ms/batch  5.86 | loss  4.43 | ppl    83.67\n",
      "| epoch   9 | batch  2100/ 2250 | ms/batch  5.90 | loss  4.41 | ppl    81.89\n",
      "| epoch   9 | batch  2150/ 2250 | ms/batch  5.87 | loss  4.40 | ppl    81.39\n",
      "| epoch   9 | batch  2200/ 2250 | ms/batch  5.91 | loss  4.48 | ppl    88.34\n",
      "| epoch   9 | batch  2250/ 2250 | ms/batch  5.86 | loss  4.45 | ppl    86.02\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time: 16.97s | valid ppl    79.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "New best model saved with perplexity:    79.91\n",
      "| epoch  10 | batch    50/ 2250 | ms/batch  6.19 | loss  4.52 | ppl    91.76\n",
      "| epoch  10 | batch   100/ 2250 | ms/batch  6.06 | loss  4.36 | ppl    78.22\n",
      "| epoch  10 | batch   150/ 2250 | ms/batch  6.08 | loss  4.35 | ppl    77.23\n",
      "| epoch  10 | batch   200/ 2250 | ms/batch  6.07 | loss  4.37 | ppl    78.80\n",
      "| epoch  10 | batch   250/ 2250 | ms/batch  5.87 | loss  4.36 | ppl    78.51\n",
      "| epoch  10 | batch   300/ 2250 | ms/batch  5.88 | loss  4.42 | ppl    83.30\n",
      "| epoch  10 | batch   350/ 2250 | ms/batch  5.88 | loss  4.37 | ppl    78.91\n",
      "| epoch  10 | batch   400/ 2250 | ms/batch  5.90 | loss  4.39 | ppl    80.28\n",
      "| epoch  10 | batch   450/ 2250 | ms/batch  5.86 | loss  4.37 | ppl    79.19\n",
      "| epoch  10 | batch   500/ 2250 | ms/batch  5.90 | loss  4.36 | ppl    78.21\n",
      "| epoch  10 | batch   550/ 2250 | ms/batch  5.92 | loss  4.41 | ppl    82.23\n",
      "| epoch  10 | batch   600/ 2250 | ms/batch  5.93 | loss  4.40 | ppl    81.63\n",
      "| epoch  10 | batch   650/ 2250 | ms/batch  5.92 | loss  4.39 | ppl    80.78\n",
      "| epoch  10 | batch   700/ 2250 | ms/batch  5.89 | loss  4.39 | ppl    80.87\n",
      "| epoch  10 | batch   750/ 2250 | ms/batch  5.84 | loss  4.37 | ppl    78.84\n",
      "| epoch  10 | batch   800/ 2250 | ms/batch  5.87 | loss  4.44 | ppl    84.45\n",
      "| epoch  10 | batch   850/ 2250 | ms/batch  5.94 | loss  4.39 | ppl    80.53\n",
      "| epoch  10 | batch   900/ 2250 | ms/batch  5.90 | loss  4.45 | ppl    85.93\n",
      "| epoch  10 | batch   950/ 2250 | ms/batch  5.94 | loss  4.43 | ppl    84.03\n",
      "| epoch  10 | batch  1000/ 2250 | ms/batch  5.94 | loss  4.41 | ppl    82.28\n",
      "| epoch  10 | batch  1050/ 2250 | ms/batch  5.95 | loss  4.41 | ppl    82.11\n",
      "| epoch  10 | batch  1100/ 2250 | ms/batch  5.93 | loss  4.44 | ppl    84.38\n",
      "| epoch  10 | batch  1150/ 2250 | ms/batch  6.00 | loss  4.46 | ppl    86.10\n",
      "| epoch  10 | batch  1200/ 2250 | ms/batch  5.98 | loss  4.39 | ppl    80.43\n",
      "| epoch  10 | batch  1250/ 2250 | ms/batch  5.95 | loss  4.39 | ppl    80.82\n",
      "| epoch  10 | batch  1300/ 2250 | ms/batch  5.93 | loss  4.42 | ppl    82.87\n",
      "| epoch  10 | batch  1350/ 2250 | ms/batch  5.97 | loss  4.41 | ppl    82.44\n",
      "| epoch  10 | batch  1400/ 2250 | ms/batch  6.00 | loss  4.49 | ppl    88.74\n",
      "| epoch  10 | batch  1450/ 2250 | ms/batch  6.36 | loss  4.48 | ppl    87.93\n",
      "| epoch  10 | batch  1500/ 2250 | ms/batch  6.14 | loss  4.48 | ppl    88.59\n",
      "| epoch  10 | batch  1550/ 2250 | ms/batch  6.22 | loss  4.37 | ppl    79.25\n",
      "| epoch  10 | batch  1600/ 2250 | ms/batch  6.05 | loss  4.34 | ppl    76.89\n",
      "| epoch  10 | batch  1650/ 2250 | ms/batch  6.08 | loss  4.35 | ppl    77.33\n",
      "| epoch  10 | batch  1700/ 2250 | ms/batch  6.05 | loss  4.36 | ppl    77.91\n",
      "| epoch  10 | batch  1750/ 2250 | ms/batch  6.06 | loss  4.35 | ppl    77.57\n",
      "| epoch  10 | batch  1800/ 2250 | ms/batch  6.04 | loss  4.39 | ppl    80.86\n",
      "| epoch  10 | batch  1850/ 2250 | ms/batch  5.94 | loss  4.39 | ppl    80.77\n",
      "| epoch  10 | batch  1900/ 2250 | ms/batch  5.97 | loss  4.40 | ppl    81.58\n",
      "| epoch  10 | batch  1950/ 2250 | ms/batch  5.98 | loss  4.46 | ppl    86.22\n",
      "| epoch  10 | batch  2000/ 2250 | ms/batch  6.06 | loss  4.41 | ppl    81.91\n",
      "| epoch  10 | batch  2050/ 2250 | ms/batch  5.92 | loss  4.39 | ppl    80.83\n",
      "| epoch  10 | batch  2100/ 2250 | ms/batch  5.89 | loss  4.38 | ppl    79.77\n",
      "| epoch  10 | batch  2150/ 2250 | ms/batch  5.86 | loss  4.39 | ppl    80.28\n",
      "| epoch  10 | batch  2200/ 2250 | ms/batch  5.95 | loss  4.46 | ppl    86.67\n",
      "| epoch  10 | batch  2250/ 2250 | ms/batch  5.84 | loss  4.43 | ppl    84.32\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time: 17.05s | valid ppl    78.84\n",
      "-----------------------------------------------------------------------------------------\n",
      "New best model saved with perplexity:    78.84\n",
      "| epoch  11 | batch    50/ 2250 | ms/batch  6.03 | loss  4.50 | ppl    90.14\n",
      "| epoch  11 | batch   100/ 2250 | ms/batch  5.90 | loss  4.34 | ppl    76.75\n",
      "| epoch  11 | batch   150/ 2250 | ms/batch  5.89 | loss  4.32 | ppl    75.02\n",
      "| epoch  11 | batch   200/ 2250 | ms/batch  5.88 | loss  4.34 | ppl    76.91\n",
      "| epoch  11 | batch   250/ 2250 | ms/batch  5.95 | loss  4.35 | ppl    77.46\n",
      "| epoch  11 | batch   300/ 2250 | ms/batch  6.08 | loss  4.40 | ppl    81.44\n",
      "| epoch  11 | batch   350/ 2250 | ms/batch  6.30 | loss  4.34 | ppl    76.96\n",
      "| epoch  11 | batch   400/ 2250 | ms/batch  6.03 | loss  4.36 | ppl    78.28\n",
      "| epoch  11 | batch   450/ 2250 | ms/batch  6.11 | loss  4.35 | ppl    77.55\n",
      "| epoch  11 | batch   500/ 2250 | ms/batch  6.07 | loss  4.34 | ppl    76.38\n",
      "| epoch  11 | batch   550/ 2250 | ms/batch  6.09 | loss  4.39 | ppl    80.44\n",
      "| epoch  11 | batch   600/ 2250 | ms/batch  6.10 | loss  4.37 | ppl    79.43\n",
      "| epoch  11 | batch   650/ 2250 | ms/batch  6.06 | loss  4.37 | ppl    78.70\n",
      "| epoch  11 | batch   700/ 2250 | ms/batch  6.08 | loss  4.38 | ppl    79.66\n",
      "| epoch  11 | batch   750/ 2250 | ms/batch  6.09 | loss  4.35 | ppl    77.58\n",
      "| epoch  11 | batch   800/ 2250 | ms/batch  6.09 | loss  4.41 | ppl    82.04\n",
      "| epoch  11 | batch   850/ 2250 | ms/batch  6.09 | loss  4.37 | ppl    78.65\n",
      "| epoch  11 | batch   900/ 2250 | ms/batch  6.21 | loss  4.42 | ppl    83.18\n",
      "| epoch  11 | batch   950/ 2250 | ms/batch  6.10 | loss  4.41 | ppl    82.63\n",
      "| epoch  11 | batch  1000/ 2250 | ms/batch  6.13 | loss  4.38 | ppl    80.01\n",
      "| epoch  11 | batch  1050/ 2250 | ms/batch  6.91 | loss  4.39 | ppl    80.24\n",
      "| epoch  11 | batch  1100/ 2250 | ms/batch  6.21 | loss  4.42 | ppl    83.11\n",
      "| epoch  11 | batch  1150/ 2250 | ms/batch  6.06 | loss  4.44 | ppl    84.67\n",
      "| epoch  11 | batch  1200/ 2250 | ms/batch  6.11 | loss  4.36 | ppl    78.16\n",
      "| epoch  11 | batch  1250/ 2250 | ms/batch  6.10 | loss  4.38 | ppl    79.79\n",
      "| epoch  11 | batch  1300/ 2250 | ms/batch  6.28 | loss  4.40 | ppl    81.77\n",
      "| epoch  11 | batch  1350/ 2250 | ms/batch  6.54 | loss  4.41 | ppl    82.03\n",
      "| epoch  11 | batch  1400/ 2250 | ms/batch  5.97 | loss  4.46 | ppl    86.71\n",
      "| epoch  11 | batch  1450/ 2250 | ms/batch  5.86 | loss  4.46 | ppl    86.30\n",
      "| epoch  11 | batch  1500/ 2250 | ms/batch  5.83 | loss  4.46 | ppl    86.51\n",
      "| epoch  11 | batch  1550/ 2250 | ms/batch  5.82 | loss  4.35 | ppl    77.49\n",
      "| epoch  11 | batch  1600/ 2250 | ms/batch  5.84 | loss  4.31 | ppl    74.59\n",
      "| epoch  11 | batch  1650/ 2250 | ms/batch  5.84 | loss  4.33 | ppl    75.67\n",
      "| epoch  11 | batch  1700/ 2250 | ms/batch  5.94 | loss  4.34 | ppl    76.60\n",
      "| epoch  11 | batch  1750/ 2250 | ms/batch  5.83 | loss  4.33 | ppl    75.97\n",
      "| epoch  11 | batch  1800/ 2250 | ms/batch  5.86 | loss  4.37 | ppl    79.32\n",
      "| epoch  11 | batch  1850/ 2250 | ms/batch  5.94 | loss  4.37 | ppl    79.04\n",
      "| epoch  11 | batch  1900/ 2250 | ms/batch  5.88 | loss  4.38 | ppl    79.92\n",
      "| epoch  11 | batch  1950/ 2250 | ms/batch  5.84 | loss  4.44 | ppl    84.95\n",
      "| epoch  11 | batch  2000/ 2250 | ms/batch  6.25 | loss  4.38 | ppl    79.95\n",
      "| epoch  11 | batch  2050/ 2250 | ms/batch  6.18 | loss  4.38 | ppl    79.85\n",
      "| epoch  11 | batch  2100/ 2250 | ms/batch  6.13 | loss  4.35 | ppl    77.43\n",
      "| epoch  11 | batch  2150/ 2250 | ms/batch  5.92 | loss  4.36 | ppl    78.01\n",
      "| epoch  11 | batch  2200/ 2250 | ms/batch  5.95 | loss  4.44 | ppl    84.40\n",
      "| epoch  11 | batch  2250/ 2250 | ms/batch  5.90 | loss  4.41 | ppl    82.53\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time: 17.29s | valid ppl    77.72\n",
      "-----------------------------------------------------------------------------------------\n",
      "New best model saved with perplexity:    77.72\n",
      "| epoch  12 | batch    50/ 2250 | ms/batch  6.02 | loss  4.48 | ppl    87.97\n",
      "| epoch  12 | batch   100/ 2250 | ms/batch  5.99 | loss  4.32 | ppl    75.12\n",
      "| epoch  12 | batch   150/ 2250 | ms/batch  6.26 | loss  4.30 | ppl    73.87\n",
      "| epoch  12 | batch   200/ 2250 | ms/batch  6.14 | loss  4.33 | ppl    75.73\n",
      "| epoch  12 | batch   250/ 2250 | ms/batch  6.14 | loss  4.33 | ppl    75.93\n",
      "| epoch  12 | batch   300/ 2250 | ms/batch  6.27 | loss  4.38 | ppl    79.80\n",
      "| epoch  12 | batch   350/ 2250 | ms/batch  6.14 | loss  4.33 | ppl    76.03\n",
      "| epoch  12 | batch   400/ 2250 | ms/batch  6.24 | loss  4.34 | ppl    76.34\n",
      "| epoch  12 | batch   450/ 2250 | ms/batch  6.09 | loss  4.33 | ppl    75.88\n",
      "| epoch  12 | batch   500/ 2250 | ms/batch  6.05 | loss  4.32 | ppl    75.28\n",
      "| epoch  12 | batch   550/ 2250 | ms/batch  5.94 | loss  4.36 | ppl    78.38\n",
      "| epoch  12 | batch   600/ 2250 | ms/batch  5.93 | loss  4.36 | ppl    78.08\n",
      "| epoch  12 | batch   650/ 2250 | ms/batch  5.94 | loss  4.34 | ppl    76.77\n",
      "| epoch  12 | batch   700/ 2250 | ms/batch  5.89 | loss  4.37 | ppl    78.72\n",
      "| epoch  12 | batch   750/ 2250 | ms/batch  5.95 | loss  4.33 | ppl    75.98\n",
      "| epoch  12 | batch   800/ 2250 | ms/batch  5.99 | loss  4.40 | ppl    81.17\n",
      "| epoch  12 | batch   850/ 2250 | ms/batch  6.00 | loss  4.35 | ppl    77.32\n",
      "| epoch  12 | batch   900/ 2250 | ms/batch  6.13 | loss  4.40 | ppl    81.70\n",
      "| epoch  12 | batch   950/ 2250 | ms/batch  6.52 | loss  4.39 | ppl    80.95\n",
      "| epoch  12 | batch  1000/ 2250 | ms/batch  6.64 | loss  4.36 | ppl    78.52\n",
      "| epoch  12 | batch  1050/ 2250 | ms/batch  6.26 | loss  4.37 | ppl    78.93\n",
      "| epoch  12 | batch  1100/ 2250 | ms/batch  6.13 | loss  4.39 | ppl    80.93\n",
      "| epoch  12 | batch  1150/ 2250 | ms/batch  6.14 | loss  4.42 | ppl    82.89\n",
      "| epoch  12 | batch  1200/ 2250 | ms/batch  6.12 | loss  4.34 | ppl    76.77\n",
      "| epoch  12 | batch  1250/ 2250 | ms/batch  6.39 | loss  4.36 | ppl    77.93\n",
      "| epoch  12 | batch  1300/ 2250 | ms/batch  6.09 | loss  4.38 | ppl    79.87\n",
      "| epoch  12 | batch  1350/ 2250 | ms/batch  6.14 | loss  4.39 | ppl    80.42\n",
      "| epoch  12 | batch  1400/ 2250 | ms/batch  6.11 | loss  4.45 | ppl    85.23\n",
      "| epoch  12 | batch  1450/ 2250 | ms/batch  5.93 | loss  4.45 | ppl    85.60\n",
      "| epoch  12 | batch  1500/ 2250 | ms/batch  6.09 | loss  4.45 | ppl    85.64\n",
      "| epoch  12 | batch  1550/ 2250 | ms/batch  6.09 | loss  4.33 | ppl    76.32\n",
      "| epoch  12 | batch  1600/ 2250 | ms/batch  6.09 | loss  4.30 | ppl    73.36\n",
      "| epoch  12 | batch  1650/ 2250 | ms/batch  6.09 | loss  4.31 | ppl    74.34\n",
      "| epoch  12 | batch  1700/ 2250 | ms/batch  6.07 | loss  4.31 | ppl    74.47\n",
      "| epoch  12 | batch  1750/ 2250 | ms/batch  6.53 | loss  4.31 | ppl    74.34\n",
      "| epoch  12 | batch  1800/ 2250 | ms/batch  6.01 | loss  4.35 | ppl    77.53\n",
      "| epoch  12 | batch  1850/ 2250 | ms/batch  5.92 | loss  4.36 | ppl    78.04\n",
      "| epoch  12 | batch  1900/ 2250 | ms/batch  5.89 | loss  4.36 | ppl    78.20\n",
      "| epoch  12 | batch  1950/ 2250 | ms/batch  5.90 | loss  4.43 | ppl    84.11\n",
      "| epoch  12 | batch  2000/ 2250 | ms/batch  5.90 | loss  4.37 | ppl    78.65\n",
      "| epoch  12 | batch  2050/ 2250 | ms/batch  5.87 | loss  4.36 | ppl    77.92\n",
      "| epoch  12 | batch  2100/ 2250 | ms/batch  5.88 | loss  4.33 | ppl    75.69\n",
      "| epoch  12 | batch  2150/ 2250 | ms/batch  5.94 | loss  4.34 | ppl    77.07\n",
      "| epoch  12 | batch  2200/ 2250 | ms/batch  5.89 | loss  4.42 | ppl    83.21\n",
      "| epoch  12 | batch  2250/ 2250 | ms/batch  5.88 | loss  4.39 | ppl    80.58\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time: 17.28s | valid ppl    76.27\n",
      "-----------------------------------------------------------------------------------------\n",
      "New best model saved with perplexity:    76.27\n",
      "| epoch  13 | batch    50/ 2250 | ms/batch  6.02 | loss  4.45 | ppl    85.79\n",
      "| epoch  13 | batch   100/ 2250 | ms/batch  6.21 | loss  4.30 | ppl    73.88\n",
      "| epoch  13 | batch   150/ 2250 | ms/batch  5.99 | loss  4.28 | ppl    72.41\n",
      "| epoch  13 | batch   200/ 2250 | ms/batch  6.08 | loss  4.30 | ppl    74.01\n",
      "| epoch  13 | batch   250/ 2250 | ms/batch  5.90 | loss  4.31 | ppl    74.31\n",
      "| epoch  13 | batch   300/ 2250 | ms/batch  5.86 | loss  4.36 | ppl    78.46\n",
      "| epoch  13 | batch   350/ 2250 | ms/batch  5.88 | loss  4.30 | ppl    74.01\n",
      "| epoch  13 | batch   400/ 2250 | ms/batch  5.90 | loss  4.32 | ppl    75.19\n",
      "| epoch  13 | batch   450/ 2250 | ms/batch  5.88 | loss  4.30 | ppl    73.80\n",
      "| epoch  13 | batch   500/ 2250 | ms/batch  5.96 | loss  4.29 | ppl    73.32\n",
      "| epoch  13 | batch   550/ 2250 | ms/batch  6.03 | loss  4.34 | ppl    76.84\n",
      "| epoch  13 | batch   600/ 2250 | ms/batch  5.91 | loss  4.36 | ppl    77.90\n",
      "| epoch  13 | batch   650/ 2250 | ms/batch  5.88 | loss  4.33 | ppl    75.77\n",
      "| epoch  13 | batch   700/ 2250 | ms/batch  5.86 | loss  4.34 | ppl    76.62\n",
      "| epoch  13 | batch   750/ 2250 | ms/batch  5.89 | loss  4.31 | ppl    74.12\n",
      "| epoch  13 | batch   800/ 2250 | ms/batch  5.91 | loss  4.38 | ppl    79.52\n",
      "| epoch  13 | batch   850/ 2250 | ms/batch  5.89 | loss  4.33 | ppl    76.10\n",
      "| epoch  13 | batch   900/ 2250 | ms/batch  5.89 | loss  4.39 | ppl    80.72\n",
      "| epoch  13 | batch   950/ 2250 | ms/batch  5.88 | loss  4.37 | ppl    79.24\n",
      "| epoch  13 | batch  1000/ 2250 | ms/batch  5.89 | loss  4.35 | ppl    77.83\n",
      "| epoch  13 | batch  1050/ 2250 | ms/batch  5.93 | loss  4.35 | ppl    77.33\n",
      "| epoch  13 | batch  1100/ 2250 | ms/batch  5.96 | loss  4.37 | ppl    79.43\n",
      "| epoch  13 | batch  1150/ 2250 | ms/batch  5.95 | loss  4.39 | ppl    80.94\n",
      "| epoch  13 | batch  1200/ 2250 | ms/batch  5.95 | loss  4.32 | ppl    75.41\n",
      "| epoch  13 | batch  1250/ 2250 | ms/batch  5.93 | loss  4.33 | ppl    76.14\n",
      "| epoch  13 | batch  1300/ 2250 | ms/batch  5.96 | loss  4.37 | ppl    78.81\n",
      "| epoch  13 | batch  1350/ 2250 | ms/batch  5.94 | loss  4.37 | ppl    79.23\n",
      "| epoch  13 | batch  1400/ 2250 | ms/batch  5.94 | loss  4.42 | ppl    83.09\n",
      "| epoch  13 | batch  1450/ 2250 | ms/batch  5.94 | loss  4.44 | ppl    84.55\n",
      "| epoch  13 | batch  1500/ 2250 | ms/batch  5.98 | loss  4.43 | ppl    83.85\n",
      "| epoch  13 | batch  1550/ 2250 | ms/batch  5.96 | loss  4.32 | ppl    75.10\n",
      "| epoch  13 | batch  1600/ 2250 | ms/batch  5.93 | loss  4.28 | ppl    72.33\n",
      "| epoch  13 | batch  1650/ 2250 | ms/batch  5.93 | loss  4.29 | ppl    72.81\n",
      "| epoch  13 | batch  1700/ 2250 | ms/batch  5.98 | loss  4.30 | ppl    73.83\n",
      "| epoch  13 | batch  1750/ 2250 | ms/batch  6.26 | loss  4.30 | ppl    73.72\n",
      "| epoch  13 | batch  1800/ 2250 | ms/batch  6.08 | loss  4.33 | ppl    76.16\n",
      "| epoch  13 | batch  1850/ 2250 | ms/batch  6.11 | loss  4.34 | ppl    76.99\n",
      "| epoch  13 | batch  1900/ 2250 | ms/batch  5.97 | loss  4.34 | ppl    76.81\n",
      "| epoch  13 | batch  1950/ 2250 | ms/batch  5.90 | loss  4.41 | ppl    82.14\n",
      "| epoch  13 | batch  2000/ 2250 | ms/batch  5.89 | loss  4.34 | ppl    76.87\n",
      "| epoch  13 | batch  2050/ 2250 | ms/batch  5.94 | loss  4.35 | ppl    77.18\n",
      "| epoch  13 | batch  2100/ 2250 | ms/batch  6.11 | loss  4.32 | ppl    75.30\n",
      "| epoch  13 | batch  2150/ 2250 | ms/batch  6.01 | loss  4.33 | ppl    75.79\n",
      "| epoch  13 | batch  2200/ 2250 | ms/batch  5.95 | loss  4.40 | ppl    81.12\n",
      "| epoch  13 | batch  2250/ 2250 | ms/batch  5.86 | loss  4.38 | ppl    79.81\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  13 | time: 17.15s | valid ppl    75.78\n",
      "-----------------------------------------------------------------------------------------\n",
      "New best model saved with perplexity:    75.78\n",
      "| epoch  14 | batch    50/ 2250 | ms/batch  6.22 | loss  4.43 | ppl    83.83\n",
      "| epoch  14 | batch   100/ 2250 | ms/batch  6.10 | loss  4.28 | ppl    72.26\n",
      "| epoch  14 | batch   150/ 2250 | ms/batch  6.11 | loss  4.27 | ppl    71.66\n",
      "| epoch  14 | batch   200/ 2250 | ms/batch  6.24 | loss  4.29 | ppl    73.15\n",
      "| epoch  14 | batch   250/ 2250 | ms/batch  5.97 | loss  4.29 | ppl    72.93\n",
      "| epoch  14 | batch   300/ 2250 | ms/batch  5.89 | loss  4.34 | ppl    76.45\n",
      "| epoch  14 | batch   350/ 2250 | ms/batch  5.94 | loss  4.28 | ppl    71.97\n",
      "| epoch  14 | batch   400/ 2250 | ms/batch  5.91 | loss  4.30 | ppl    73.51\n",
      "| epoch  14 | batch   450/ 2250 | ms/batch  5.92 | loss  4.29 | ppl    73.01\n",
      "| epoch  14 | batch   500/ 2250 | ms/batch  6.14 | loss  4.28 | ppl    72.18\n",
      "| epoch  14 | batch   550/ 2250 | ms/batch  5.95 | loss  4.34 | ppl    76.37\n",
      "| epoch  14 | batch   600/ 2250 | ms/batch  6.01 | loss  4.34 | ppl    76.47\n",
      "| epoch  14 | batch   650/ 2250 | ms/batch  6.34 | loss  4.31 | ppl    74.40\n",
      "| epoch  14 | batch   700/ 2250 | ms/batch  6.04 | loss  4.33 | ppl    75.78\n",
      "| epoch  14 | batch   750/ 2250 | ms/batch  5.99 | loss  4.29 | ppl    73.16\n",
      "| epoch  14 | batch   800/ 2250 | ms/batch  5.92 | loss  4.36 | ppl    78.21\n",
      "| epoch  14 | batch   850/ 2250 | ms/batch  5.90 | loss  4.32 | ppl    75.35\n",
      "| epoch  14 | batch   900/ 2250 | ms/batch  5.88 | loss  4.37 | ppl    79.40\n",
      "| epoch  14 | batch   950/ 2250 | ms/batch  5.87 | loss  4.36 | ppl    78.24\n",
      "| epoch  14 | batch  1000/ 2250 | ms/batch  5.95 | loss  4.33 | ppl    75.73\n",
      "| epoch  14 | batch  1050/ 2250 | ms/batch  6.03 | loss  4.33 | ppl    76.06\n",
      "| epoch  14 | batch  1100/ 2250 | ms/batch  5.88 | loss  4.37 | ppl    78.72\n",
      "| epoch  14 | batch  1150/ 2250 | ms/batch  5.90 | loss  4.39 | ppl    80.37\n",
      "| epoch  14 | batch  1200/ 2250 | ms/batch  5.89 | loss  4.31 | ppl    74.51\n",
      "| epoch  14 | batch  1250/ 2250 | ms/batch  5.93 | loss  4.32 | ppl    74.89\n",
      "| epoch  14 | batch  1300/ 2250 | ms/batch  5.89 | loss  4.34 | ppl    76.98\n",
      "| epoch  14 | batch  1350/ 2250 | ms/batch  5.89 | loss  4.36 | ppl    78.04\n",
      "| epoch  14 | batch  1400/ 2250 | ms/batch  5.87 | loss  4.42 | ppl    82.80\n",
      "| epoch  14 | batch  1450/ 2250 | ms/batch  5.90 | loss  4.42 | ppl    82.81\n",
      "| epoch  14 | batch  1500/ 2250 | ms/batch  5.95 | loss  4.42 | ppl    82.89\n",
      "| epoch  14 | batch  1550/ 2250 | ms/batch  5.94 | loss  4.30 | ppl    73.46\n",
      "| epoch  14 | batch  1600/ 2250 | ms/batch  5.92 | loss  4.26 | ppl    70.93\n",
      "| epoch  14 | batch  1650/ 2250 | ms/batch  5.92 | loss  4.28 | ppl    72.15\n",
      "| epoch  14 | batch  1700/ 2250 | ms/batch  6.08 | loss  4.29 | ppl    72.64\n",
      "| epoch  14 | batch  1750/ 2250 | ms/batch  6.11 | loss  4.28 | ppl    71.90\n",
      "| epoch  14 | batch  1800/ 2250 | ms/batch  6.08 | loss  4.32 | ppl    75.34\n",
      "| epoch  14 | batch  1850/ 2250 | ms/batch  6.08 | loss  4.33 | ppl    75.80\n",
      "| epoch  14 | batch  1900/ 2250 | ms/batch  6.09 | loss  4.33 | ppl    76.26\n",
      "| epoch  14 | batch  1950/ 2250 | ms/batch  6.11 | loss  4.38 | ppl    80.10\n",
      "| epoch  14 | batch  2000/ 2250 | ms/batch  5.95 | loss  4.34 | ppl    76.63\n",
      "| epoch  14 | batch  2050/ 2250 | ms/batch  6.11 | loss  4.33 | ppl    75.97\n",
      "| epoch  14 | batch  2100/ 2250 | ms/batch  5.95 | loss  4.30 | ppl    73.82\n",
      "| epoch  14 | batch  2150/ 2250 | ms/batch  5.99 | loss  4.32 | ppl    74.83\n",
      "| epoch  14 | batch  2200/ 2250 | ms/batch  5.91 | loss  4.38 | ppl    80.24\n",
      "| epoch  14 | batch  2250/ 2250 | ms/batch  5.97 | loss  4.37 | ppl    79.16\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  14 | time: 17.18s | valid ppl    75.23\n",
      "-----------------------------------------------------------------------------------------\n",
      "New best model saved with perplexity:    75.23\n",
      "| epoch  15 | batch    50/ 2250 | ms/batch  6.37 | loss  4.43 | ppl    83.95\n",
      "| epoch  15 | batch   100/ 2250 | ms/batch  6.54 | loss  4.27 | ppl    71.66\n",
      "| epoch  15 | batch   150/ 2250 | ms/batch  6.08 | loss  4.26 | ppl    70.51\n",
      "| epoch  15 | batch   200/ 2250 | ms/batch  6.09 | loss  4.27 | ppl    71.87\n",
      "| epoch  15 | batch   250/ 2250 | ms/batch  6.40 | loss  4.28 | ppl    72.04\n",
      "| epoch  15 | batch   300/ 2250 | ms/batch  6.13 | loss  4.33 | ppl    75.57\n",
      "| epoch  15 | batch   350/ 2250 | ms/batch  6.48 | loss  4.27 | ppl    71.51\n",
      "| epoch  15 | batch   400/ 2250 | ms/batch  6.58 | loss  4.30 | ppl    73.63\n",
      "| epoch  15 | batch   450/ 2250 | ms/batch  6.67 | loss  4.28 | ppl    72.45\n",
      "| epoch  15 | batch   500/ 2250 | ms/batch  6.14 | loss  4.26 | ppl    71.12\n",
      "| epoch  15 | batch   550/ 2250 | ms/batch  6.46 | loss  4.32 | ppl    75.33\n",
      "| epoch  15 | batch   600/ 2250 | ms/batch  6.09 | loss  4.31 | ppl    74.32\n",
      "| epoch  15 | batch   650/ 2250 | ms/batch  6.36 | loss  4.30 | ppl    73.45\n",
      "| epoch  15 | batch   700/ 2250 | ms/batch  6.20 | loss  4.31 | ppl    74.58\n",
      "| epoch  15 | batch   750/ 2250 | ms/batch  6.32 | loss  4.27 | ppl    71.69\n",
      "| epoch  15 | batch   800/ 2250 | ms/batch  6.09 | loss  4.34 | ppl    77.04\n",
      "| epoch  15 | batch   850/ 2250 | ms/batch  6.10 | loss  4.30 | ppl    73.92\n",
      "| epoch  15 | batch   900/ 2250 | ms/batch  6.08 | loss  4.36 | ppl    78.37\n",
      "| epoch  15 | batch   950/ 2250 | ms/batch  6.10 | loss  4.34 | ppl    77.04\n",
      "| epoch  15 | batch  1000/ 2250 | ms/batch  6.06 | loss  4.31 | ppl    74.69\n",
      "| epoch  15 | batch  1050/ 2250 | ms/batch  6.02 | loss  4.32 | ppl    75.01\n",
      "| epoch  15 | batch  1100/ 2250 | ms/batch  6.52 | loss  4.35 | ppl    77.85\n",
      "| epoch  15 | batch  1150/ 2250 | ms/batch  6.06 | loss  4.37 | ppl    79.26\n",
      "| epoch  15 | batch  1200/ 2250 | ms/batch  5.94 | loss  4.29 | ppl    73.28\n",
      "| epoch  15 | batch  1250/ 2250 | ms/batch  5.95 | loss  4.31 | ppl    74.13\n",
      "| epoch  15 | batch  1300/ 2250 | ms/batch  6.12 | loss  4.33 | ppl    75.91\n",
      "| epoch  15 | batch  1350/ 2250 | ms/batch  6.28 | loss  4.33 | ppl    76.06\n",
      "| epoch  15 | batch  1400/ 2250 | ms/batch  6.04 | loss  4.41 | ppl    81.92\n",
      "| epoch  15 | batch  1450/ 2250 | ms/batch  6.06 | loss  4.40 | ppl    81.28\n",
      "| epoch  15 | batch  1500/ 2250 | ms/batch  6.21 | loss  4.41 | ppl    81.86\n",
      "| epoch  15 | batch  1550/ 2250 | ms/batch  6.28 | loss  4.29 | ppl    72.86\n",
      "| epoch  15 | batch  1600/ 2250 | ms/batch  6.40 | loss  4.25 | ppl    70.32\n",
      "| epoch  15 | batch  1650/ 2250 | ms/batch  6.50 | loss  4.26 | ppl    70.87\n",
      "| epoch  15 | batch  1700/ 2250 | ms/batch  6.07 | loss  4.27 | ppl    71.55\n",
      "| epoch  15 | batch  1750/ 2250 | ms/batch  6.10 | loss  4.26 | ppl    70.91\n",
      "| epoch  15 | batch  1800/ 2250 | ms/batch  6.14 | loss  4.30 | ppl    73.96\n",
      "| epoch  15 | batch  1850/ 2250 | ms/batch  6.29 | loss  4.31 | ppl    74.73\n",
      "| epoch  15 | batch  1900/ 2250 | ms/batch  6.24 | loss  4.32 | ppl    75.56\n",
      "| epoch  15 | batch  1950/ 2250 | ms/batch  6.20 | loss  4.39 | ppl    80.33\n",
      "| epoch  15 | batch  2000/ 2250 | ms/batch  5.94 | loss  4.31 | ppl    74.81\n",
      "| epoch  15 | batch  2050/ 2250 | ms/batch  6.11 | loss  4.32 | ppl    75.26\n",
      "| epoch  15 | batch  2100/ 2250 | ms/batch  6.23 | loss  4.29 | ppl    73.32\n",
      "| epoch  15 | batch  2150/ 2250 | ms/batch  6.20 | loss  4.30 | ppl    73.72\n",
      "| epoch  15 | batch  2200/ 2250 | ms/batch  6.07 | loss  4.38 | ppl    80.13\n",
      "| epoch  15 | batch  2250/ 2250 | ms/batch  6.08 | loss  4.35 | ppl    77.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  15 | time: 17.62s | valid ppl    74.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "New best model saved with perplexity:    74.69\n",
      "| epoch  16 | batch    50/ 2250 | ms/batch  6.23 | loss  4.41 | ppl    82.59\n",
      "| epoch  16 | batch   100/ 2250 | ms/batch  6.54 | loss  4.26 | ppl    70.51\n",
      "| epoch  16 | batch   150/ 2250 | ms/batch  6.21 | loss  4.25 | ppl    70.16\n",
      "| epoch  16 | batch   200/ 2250 | ms/batch  6.63 | loss  4.26 | ppl    71.03\n",
      "| epoch  16 | batch   250/ 2250 | ms/batch  6.15 | loss  4.27 | ppl    71.32\n",
      "| epoch  16 | batch   300/ 2250 | ms/batch  6.52 | loss  4.32 | ppl    74.91\n",
      "| epoch  16 | batch   350/ 2250 | ms/batch  5.98 | loss  4.26 | ppl    70.66\n",
      "| epoch  16 | batch   400/ 2250 | ms/batch  5.94 | loss  4.27 | ppl    71.74\n",
      "| epoch  16 | batch   450/ 2250 | ms/batch  5.99 | loss  4.26 | ppl    70.46\n",
      "| epoch  16 | batch   500/ 2250 | ms/batch  6.10 | loss  4.25 | ppl    70.14\n",
      "| epoch  16 | batch   550/ 2250 | ms/batch  6.30 | loss  4.31 | ppl    74.32\n",
      "| epoch  16 | batch   600/ 2250 | ms/batch  6.18 | loss  4.30 | ppl    74.05\n",
      "| epoch  16 | batch   650/ 2250 | ms/batch  6.33 | loss  4.28 | ppl    72.27\n",
      "| epoch  16 | batch   700/ 2250 | ms/batch  6.28 | loss  4.30 | ppl    73.46\n",
      "| epoch  16 | batch   750/ 2250 | ms/batch  6.15 | loss  4.27 | ppl    71.47\n",
      "| epoch  16 | batch   800/ 2250 | ms/batch  6.40 | loss  4.33 | ppl    76.22\n",
      "| epoch  16 | batch   850/ 2250 | ms/batch  6.28 | loss  4.29 | ppl    72.81\n",
      "| epoch  16 | batch   900/ 2250 | ms/batch  6.15 | loss  4.35 | ppl    77.28\n",
      "| epoch  16 | batch   950/ 2250 | ms/batch  6.17 | loss  4.33 | ppl    76.00\n",
      "| epoch  16 | batch  1000/ 2250 | ms/batch  6.24 | loss  4.30 | ppl    74.05\n",
      "| epoch  16 | batch  1050/ 2250 | ms/batch  6.23 | loss  4.30 | ppl    73.78\n",
      "| epoch  16 | batch  1100/ 2250 | ms/batch  6.10 | loss  4.34 | ppl    76.55\n",
      "| epoch  16 | batch  1150/ 2250 | ms/batch  6.00 | loss  4.35 | ppl    77.51\n",
      "| epoch  16 | batch  1200/ 2250 | ms/batch  6.50 | loss  4.29 | ppl    73.12\n",
      "| epoch  16 | batch  1250/ 2250 | ms/batch  6.16 | loss  4.29 | ppl    72.74\n",
      "| epoch  16 | batch  1300/ 2250 | ms/batch  6.07 | loss  4.33 | ppl    76.09\n",
      "| epoch  16 | batch  1350/ 2250 | ms/batch  6.12 | loss  4.34 | ppl    76.90\n",
      "| epoch  16 | batch  1400/ 2250 | ms/batch  6.17 | loss  4.39 | ppl    80.31\n",
      "| epoch  16 | batch  1450/ 2250 | ms/batch  6.05 | loss  4.40 | ppl    81.32\n",
      "| epoch  16 | batch  1500/ 2250 | ms/batch  5.94 | loss  4.39 | ppl    80.27\n",
      "| epoch  16 | batch  1550/ 2250 | ms/batch  5.95 | loss  4.28 | ppl    72.05\n",
      "| epoch  16 | batch  1600/ 2250 | ms/batch  5.95 | loss  4.24 | ppl    69.29\n",
      "| epoch  16 | batch  1650/ 2250 | ms/batch  5.94 | loss  4.25 | ppl    70.16\n",
      "| epoch  16 | batch  1700/ 2250 | ms/batch  5.94 | loss  4.26 | ppl    71.10\n",
      "| epoch  16 | batch  1750/ 2250 | ms/batch  5.91 | loss  4.26 | ppl    70.62\n",
      "| epoch  16 | batch  1800/ 2250 | ms/batch  5.90 | loss  4.30 | ppl    73.57\n",
      "| epoch  16 | batch  1850/ 2250 | ms/batch  5.94 | loss  4.30 | ppl    73.94\n",
      "| epoch  16 | batch  1900/ 2250 | ms/batch  5.94 | loss  4.31 | ppl    74.23\n",
      "| epoch  16 | batch  1950/ 2250 | ms/batch  5.92 | loss  4.37 | ppl    78.91\n",
      "| epoch  16 | batch  2000/ 2250 | ms/batch  5.92 | loss  4.31 | ppl    74.20\n",
      "| epoch  16 | batch  2050/ 2250 | ms/batch  5.92 | loss  4.30 | ppl    73.81\n",
      "| epoch  16 | batch  2100/ 2250 | ms/batch  5.89 | loss  4.28 | ppl    72.01\n",
      "| epoch  16 | batch  2150/ 2250 | ms/batch  5.89 | loss  4.29 | ppl    73.15\n",
      "| epoch  16 | batch  2200/ 2250 | ms/batch  5.90 | loss  4.37 | ppl    78.85\n",
      "| epoch  16 | batch  2250/ 2250 | ms/batch  5.89 | loss  4.34 | ppl    76.52\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  16 | time: 17.35s | valid ppl    74.74\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  17 | batch    50/ 2250 | ms/batch  6.00 | loss  4.40 | ppl    81.30\n",
      "| epoch  17 | batch   100/ 2250 | ms/batch  5.88 | loss  4.24 | ppl    69.64\n",
      "| epoch  17 | batch   150/ 2250 | ms/batch  5.89 | loss  4.23 | ppl    68.57\n",
      "| epoch  17 | batch   200/ 2250 | ms/batch  5.90 | loss  4.25 | ppl    70.10\n",
      "| epoch  17 | batch   250/ 2250 | ms/batch  5.88 | loss  4.25 | ppl    69.97\n",
      "| epoch  17 | batch   300/ 2250 | ms/batch  5.88 | loss  4.31 | ppl    74.25\n",
      "| epoch  17 | batch   350/ 2250 | ms/batch  5.88 | loss  4.24 | ppl    69.33\n",
      "| epoch  17 | batch   400/ 2250 | ms/batch  6.02 | loss  4.27 | ppl    71.59\n",
      "| epoch  17 | batch   450/ 2250 | ms/batch  6.22 | loss  4.26 | ppl    70.62\n",
      "| epoch  17 | batch   500/ 2250 | ms/batch  6.13 | loss  4.24 | ppl    69.62\n",
      "| epoch  17 | batch   550/ 2250 | ms/batch  6.09 | loss  4.30 | ppl    73.65\n",
      "| epoch  17 | batch   600/ 2250 | ms/batch  6.06 | loss  4.30 | ppl    73.71\n",
      "| epoch  17 | batch   650/ 2250 | ms/batch  6.08 | loss  4.27 | ppl    71.80\n",
      "| epoch  17 | batch   700/ 2250 | ms/batch  6.07 | loss  4.29 | ppl    73.05\n",
      "| epoch  17 | batch   750/ 2250 | ms/batch  6.10 | loss  4.26 | ppl    70.54\n",
      "| epoch  17 | batch   800/ 2250 | ms/batch  6.11 | loss  4.33 | ppl    75.60\n",
      "| epoch  17 | batch   850/ 2250 | ms/batch  6.10 | loss  4.27 | ppl    71.84\n",
      "| epoch  17 | batch   900/ 2250 | ms/batch  6.06 | loss  4.34 | ppl    76.43\n",
      "| epoch  17 | batch   950/ 2250 | ms/batch  6.13 | loss  4.32 | ppl    75.35\n",
      "| epoch  17 | batch  1000/ 2250 | ms/batch  6.38 | loss  4.31 | ppl    74.31\n",
      "| epoch  17 | batch  1050/ 2250 | ms/batch  6.45 | loss  4.29 | ppl    72.84\n",
      "| epoch  17 | batch  1100/ 2250 | ms/batch  6.09 | loss  4.33 | ppl    76.15\n",
      "| epoch  17 | batch  1150/ 2250 | ms/batch  6.52 | loss  4.35 | ppl    77.70\n",
      "| epoch  17 | batch  1200/ 2250 | ms/batch  6.10 | loss  4.28 | ppl    71.97\n",
      "| epoch  17 | batch  1250/ 2250 | ms/batch  6.11 | loss  4.29 | ppl    72.77\n",
      "| epoch  17 | batch  1300/ 2250 | ms/batch  6.20 | loss  4.31 | ppl    74.45\n",
      "| epoch  17 | batch  1350/ 2250 | ms/batch  6.14 | loss  4.33 | ppl    75.62\n",
      "| epoch  17 | batch  1400/ 2250 | ms/batch  6.07 | loss  4.38 | ppl    80.09\n",
      "| epoch  17 | batch  1450/ 2250 | ms/batch  5.94 | loss  4.38 | ppl    79.89\n",
      "| epoch  17 | batch  1500/ 2250 | ms/batch  5.93 | loss  4.38 | ppl    79.83\n",
      "| epoch  17 | batch  1550/ 2250 | ms/batch  5.95 | loss  4.27 | ppl    71.61\n",
      "| epoch  17 | batch  1600/ 2250 | ms/batch  5.90 | loss  4.23 | ppl    68.72\n",
      "| epoch  17 | batch  1650/ 2250 | ms/batch  5.98 | loss  4.24 | ppl    69.58\n",
      "| epoch  17 | batch  1700/ 2250 | ms/batch  6.10 | loss  4.26 | ppl    70.57\n",
      "| epoch  17 | batch  1750/ 2250 | ms/batch  6.07 | loss  4.25 | ppl    70.00\n",
      "| epoch  17 | batch  1800/ 2250 | ms/batch  6.05 | loss  4.28 | ppl    72.46\n",
      "| epoch  17 | batch  1850/ 2250 | ms/batch  6.25 | loss  4.28 | ppl    72.42\n",
      "| epoch  17 | batch  1900/ 2250 | ms/batch  6.07 | loss  4.29 | ppl    73.33\n",
      "| epoch  17 | batch  1950/ 2250 | ms/batch  5.97 | loss  4.36 | ppl    78.51\n",
      "| epoch  17 | batch  2000/ 2250 | ms/batch  5.89 | loss  4.29 | ppl    72.94\n",
      "| epoch  17 | batch  2050/ 2250 | ms/batch  5.89 | loss  4.30 | ppl    73.40\n",
      "| epoch  17 | batch  2100/ 2250 | ms/batch  5.88 | loss  4.27 | ppl    71.49\n",
      "| epoch  17 | batch  2150/ 2250 | ms/batch  5.87 | loss  4.28 | ppl    72.39\n",
      "| epoch  17 | batch  2200/ 2250 | ms/batch  5.88 | loss  4.35 | ppl    77.70\n",
      "| epoch  17 | batch  2250/ 2250 | ms/batch  5.83 | loss  4.34 | ppl    76.62\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  17 | time: 17.24s | valid ppl    74.07\n",
      "-----------------------------------------------------------------------------------------\n",
      "New best model saved with perplexity:    74.07\n",
      "| epoch  18 | batch    50/ 2250 | ms/batch  6.03 | loss  4.39 | ppl    80.60\n",
      "| epoch  18 | batch   100/ 2250 | ms/batch  5.90 | loss  4.24 | ppl    69.37\n",
      "| epoch  18 | batch   150/ 2250 | ms/batch  5.91 | loss  4.22 | ppl    68.37\n",
      "| epoch  18 | batch   200/ 2250 | ms/batch  5.93 | loss  4.23 | ppl    69.03\n",
      "| epoch  18 | batch   250/ 2250 | ms/batch  5.89 | loss  4.24 | ppl    69.71\n",
      "| epoch  18 | batch   300/ 2250 | ms/batch  5.88 | loss  4.30 | ppl    74.05\n",
      "| epoch  18 | batch   350/ 2250 | ms/batch  5.91 | loss  4.23 | ppl    68.88\n",
      "| epoch  18 | batch   400/ 2250 | ms/batch  5.88 | loss  4.26 | ppl    70.78\n",
      "| epoch  18 | batch   450/ 2250 | ms/batch  5.89 | loss  4.24 | ppl    69.22\n",
      "| epoch  18 | batch   500/ 2250 | ms/batch  5.87 | loss  4.23 | ppl    69.00\n",
      "| epoch  18 | batch   550/ 2250 | ms/batch  6.07 | loss  4.29 | ppl    72.81\n",
      "| epoch  18 | batch   600/ 2250 | ms/batch  6.11 | loss  4.28 | ppl    72.57\n",
      "| epoch  18 | batch   650/ 2250 | ms/batch  5.85 | loss  4.27 | ppl    71.37\n",
      "| epoch  18 | batch   700/ 2250 | ms/batch  5.93 | loss  4.28 | ppl    71.95\n",
      "| epoch  18 | batch   750/ 2250 | ms/batch  5.94 | loss  4.24 | ppl    69.56\n",
      "| epoch  18 | batch   800/ 2250 | ms/batch  5.92 | loss  4.31 | ppl    74.59\n",
      "| epoch  18 | batch   850/ 2250 | ms/batch  5.94 | loss  4.28 | ppl    72.06\n",
      "| epoch  18 | batch   900/ 2250 | ms/batch  6.15 | loss  4.32 | ppl    75.47\n",
      "| epoch  18 | batch   950/ 2250 | ms/batch  6.16 | loss  4.31 | ppl    74.55\n",
      "| epoch  18 | batch  1000/ 2250 | ms/batch  6.07 | loss  4.28 | ppl    72.39\n",
      "| epoch  18 | batch  1050/ 2250 | ms/batch  6.21 | loss  4.29 | ppl    72.83\n",
      "| epoch  18 | batch  1100/ 2250 | ms/batch  6.20 | loss  4.32 | ppl    75.48\n",
      "| epoch  18 | batch  1150/ 2250 | ms/batch  6.07 | loss  4.35 | ppl    77.58\n",
      "| epoch  18 | batch  1200/ 2250 | ms/batch  6.02 | loss  4.27 | ppl    71.45\n",
      "| epoch  18 | batch  1250/ 2250 | ms/batch  6.06 | loss  4.27 | ppl    71.82\n",
      "| epoch  18 | batch  1300/ 2250 | ms/batch  6.09 | loss  4.30 | ppl    73.97\n",
      "| epoch  18 | batch  1350/ 2250 | ms/batch  6.18 | loss  4.31 | ppl    74.67\n",
      "| epoch  18 | batch  1400/ 2250 | ms/batch  6.04 | loss  4.37 | ppl    79.32\n",
      "| epoch  18 | batch  1450/ 2250 | ms/batch  6.09 | loss  4.37 | ppl    79.18\n",
      "| epoch  18 | batch  1500/ 2250 | ms/batch  6.39 | loss  4.37 | ppl    79.31\n",
      "| epoch  18 | batch  1550/ 2250 | ms/batch  6.09 | loss  4.26 | ppl    70.87\n",
      "| epoch  18 | batch  1600/ 2250 | ms/batch  6.12 | loss  4.22 | ppl    67.83\n",
      "| epoch  18 | batch  1650/ 2250 | ms/batch  6.47 | loss  4.23 | ppl    69.03\n",
      "| epoch  18 | batch  1700/ 2250 | ms/batch  6.11 | loss  4.24 | ppl    69.53\n",
      "| epoch  18 | batch  1750/ 2250 | ms/batch  6.15 | loss  4.23 | ppl    68.62\n",
      "| epoch  18 | batch  1800/ 2250 | ms/batch  6.14 | loss  4.29 | ppl    72.73\n",
      "| epoch  18 | batch  1850/ 2250 | ms/batch  6.11 | loss  4.28 | ppl    72.54\n",
      "| epoch  18 | batch  1900/ 2250 | ms/batch  6.11 | loss  4.29 | ppl    73.32\n",
      "| epoch  18 | batch  1950/ 2250 | ms/batch  6.08 | loss  4.35 | ppl    77.72\n",
      "| epoch  18 | batch  2000/ 2250 | ms/batch  6.09 | loss  4.29 | ppl    72.92\n",
      "| epoch  18 | batch  2050/ 2250 | ms/batch  6.11 | loss  4.28 | ppl    72.58\n",
      "| epoch  18 | batch  2100/ 2250 | ms/batch  6.13 | loss  4.27 | ppl    71.47\n",
      "| epoch  18 | batch  2150/ 2250 | ms/batch  6.08 | loss  4.26 | ppl    70.97\n",
      "| epoch  18 | batch  2200/ 2250 | ms/batch  6.11 | loss  4.35 | ppl    77.40\n",
      "| epoch  18 | batch  2250/ 2250 | ms/batch  6.02 | loss  4.33 | ppl    75.89\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  18 | time: 17.27s | valid ppl    73.81\n",
      "-----------------------------------------------------------------------------------------\n",
      "New best model saved with perplexity:    73.81\n",
      "| epoch  19 | batch    50/ 2250 | ms/batch  6.18 | loss  4.38 | ppl    79.93\n",
      "| epoch  19 | batch   100/ 2250 | ms/batch  6.06 | loss  4.23 | ppl    68.46\n",
      "| epoch  19 | batch   150/ 2250 | ms/batch  6.06 | loss  4.22 | ppl    68.08\n",
      "| epoch  19 | batch   200/ 2250 | ms/batch  6.08 | loss  4.23 | ppl    68.87\n",
      "| epoch  19 | batch   250/ 2250 | ms/batch  6.23 | loss  4.23 | ppl    68.84\n",
      "| epoch  19 | batch   300/ 2250 | ms/batch  6.09 | loss  4.29 | ppl    72.67\n",
      "| epoch  19 | batch   350/ 2250 | ms/batch  6.06 | loss  4.23 | ppl    68.63\n",
      "| epoch  19 | batch   400/ 2250 | ms/batch  6.07 | loss  4.25 | ppl    69.78\n",
      "| epoch  19 | batch   450/ 2250 | ms/batch  6.16 | loss  4.23 | ppl    69.01\n",
      "| epoch  19 | batch   500/ 2250 | ms/batch  6.05 | loss  4.22 | ppl    67.92\n",
      "| epoch  19 | batch   550/ 2250 | ms/batch  5.87 | loss  4.28 | ppl    71.99\n",
      "| epoch  19 | batch   600/ 2250 | ms/batch  5.88 | loss  4.28 | ppl    72.47\n",
      "| epoch  19 | batch   650/ 2250 | ms/batch  5.89 | loss  4.25 | ppl    70.32\n",
      "| epoch  19 | batch   700/ 2250 | ms/batch  5.89 | loss  4.27 | ppl    71.51\n",
      "| epoch  19 | batch   750/ 2250 | ms/batch  5.92 | loss  4.24 | ppl    69.30\n",
      "| epoch  19 | batch   800/ 2250 | ms/batch  5.90 | loss  4.31 | ppl    74.17\n",
      "| epoch  19 | batch   850/ 2250 | ms/batch  5.91 | loss  4.27 | ppl    71.34\n",
      "| epoch  19 | batch   900/ 2250 | ms/batch  5.90 | loss  4.32 | ppl    75.10\n",
      "| epoch  19 | batch   950/ 2250 | ms/batch  5.89 | loss  4.30 | ppl    73.63\n",
      "| epoch  19 | batch  1000/ 2250 | ms/batch  5.87 | loss  4.28 | ppl    72.43\n",
      "| epoch  19 | batch  1050/ 2250 | ms/batch  5.87 | loss  4.27 | ppl    71.77\n",
      "| epoch  19 | batch  1100/ 2250 | ms/batch  5.86 | loss  4.31 | ppl    74.32\n",
      "| epoch  19 | batch  1150/ 2250 | ms/batch  5.85 | loss  4.34 | ppl    76.53\n",
      "| epoch  19 | batch  1200/ 2250 | ms/batch  5.87 | loss  4.26 | ppl    70.50\n",
      "| epoch  19 | batch  1250/ 2250 | ms/batch  5.89 | loss  4.27 | ppl    71.29\n",
      "| epoch  19 | batch  1300/ 2250 | ms/batch  5.94 | loss  4.29 | ppl    73.01\n",
      "| epoch  19 | batch  1350/ 2250 | ms/batch  6.10 | loss  4.31 | ppl    74.55\n",
      "| epoch  19 | batch  1400/ 2250 | ms/batch  6.13 | loss  4.37 | ppl    78.84\n",
      "| epoch  19 | batch  1450/ 2250 | ms/batch  6.05 | loss  4.36 | ppl    78.25\n",
      "| epoch  19 | batch  1500/ 2250 | ms/batch  6.06 | loss  4.36 | ppl    78.62\n",
      "| epoch  19 | batch  1550/ 2250 | ms/batch  6.07 | loss  4.25 | ppl    69.97\n",
      "| epoch  19 | batch  1600/ 2250 | ms/batch  6.06 | loss  4.21 | ppl    67.24\n",
      "| epoch  19 | batch  1650/ 2250 | ms/batch  6.07 | loss  4.22 | ppl    68.28\n",
      "| epoch  19 | batch  1700/ 2250 | ms/batch  6.14 | loss  4.23 | ppl    68.58\n",
      "| epoch  19 | batch  1750/ 2250 | ms/batch  6.18 | loss  4.23 | ppl    68.43\n",
      "| epoch  19 | batch  1800/ 2250 | ms/batch  6.15 | loss  4.27 | ppl    71.24\n",
      "| epoch  19 | batch  1850/ 2250 | ms/batch  6.25 | loss  4.27 | ppl    71.87\n",
      "| epoch  19 | batch  1900/ 2250 | ms/batch  6.09 | loss  4.29 | ppl    72.62\n",
      "| epoch  19 | batch  1950/ 2250 | ms/batch  6.34 | loss  4.34 | ppl    77.05\n",
      "| epoch  19 | batch  2000/ 2250 | ms/batch  6.22 | loss  4.28 | ppl    71.90\n",
      "| epoch  19 | batch  2050/ 2250 | ms/batch  6.12 | loss  4.28 | ppl    71.98\n",
      "| epoch  19 | batch  2100/ 2250 | ms/batch  6.22 | loss  4.26 | ppl    70.59\n",
      "| epoch  19 | batch  2150/ 2250 | ms/batch  6.10 | loss  4.27 | ppl    71.33\n",
      "| epoch  19 | batch  2200/ 2250 | ms/batch  6.12 | loss  4.34 | ppl    76.55\n",
      "| epoch  19 | batch  2250/ 2250 | ms/batch  6.09 | loss  4.33 | ppl    75.57\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  19 | time: 17.28s | valid ppl    72.67\n",
      "-----------------------------------------------------------------------------------------\n",
      "New best model saved with perplexity:    72.67\n",
      "| epoch  20 | batch    50/ 2250 | ms/batch  6.14 | loss  4.38 | ppl    79.79\n",
      "| epoch  20 | batch   100/ 2250 | ms/batch  5.90 | loss  4.21 | ppl    67.62\n",
      "| epoch  20 | batch   150/ 2250 | ms/batch  5.98 | loss  4.21 | ppl    67.28\n",
      "| epoch  20 | batch   200/ 2250 | ms/batch  5.97 | loss  4.22 | ppl    68.19\n",
      "| epoch  20 | batch   250/ 2250 | ms/batch  5.94 | loss  4.23 | ppl    68.39\n",
      "| epoch  20 | batch   300/ 2250 | ms/batch  5.97 | loss  4.27 | ppl    71.75\n",
      "| epoch  20 | batch   350/ 2250 | ms/batch  5.93 | loss  4.21 | ppl    67.53\n",
      "| epoch  20 | batch   400/ 2250 | ms/batch  5.92 | loss  4.24 | ppl    69.38\n",
      "| epoch  20 | batch   450/ 2250 | ms/batch  5.89 | loss  4.22 | ppl    67.93\n",
      "| epoch  20 | batch   500/ 2250 | ms/batch  5.89 | loss  4.22 | ppl    68.05\n",
      "| epoch  20 | batch   550/ 2250 | ms/batch  5.95 | loss  4.27 | ppl    71.75\n",
      "| epoch  20 | batch   600/ 2250 | ms/batch  5.94 | loss  4.28 | ppl    71.94\n",
      "| epoch  20 | batch   650/ 2250 | ms/batch  5.93 | loss  4.25 | ppl    69.90\n",
      "| epoch  20 | batch   700/ 2250 | ms/batch  5.95 | loss  4.26 | ppl    70.93\n",
      "| epoch  20 | batch   750/ 2250 | ms/batch  5.90 | loss  4.23 | ppl    68.46\n",
      "| epoch  20 | batch   800/ 2250 | ms/batch  5.95 | loss  4.29 | ppl    73.17\n",
      "| epoch  20 | batch   850/ 2250 | ms/batch  5.94 | loss  4.25 | ppl    70.45\n",
      "| epoch  20 | batch   900/ 2250 | ms/batch  5.90 | loss  4.31 | ppl    74.53\n",
      "| epoch  20 | batch   950/ 2250 | ms/batch  5.91 | loss  4.29 | ppl    73.31\n",
      "| epoch  20 | batch  1000/ 2250 | ms/batch  6.13 | loss  4.26 | ppl    71.12\n",
      "| epoch  20 | batch  1050/ 2250 | ms/batch  6.06 | loss  4.26 | ppl    71.16\n",
      "| epoch  20 | batch  1100/ 2250 | ms/batch  6.07 | loss  4.30 | ppl    73.76\n",
      "| epoch  20 | batch  1150/ 2250 | ms/batch  6.10 | loss  4.32 | ppl    75.56\n",
      "| epoch  20 | batch  1200/ 2250 | ms/batch  6.13 | loss  4.25 | ppl    70.25\n",
      "| epoch  20 | batch  1250/ 2250 | ms/batch  6.20 | loss  4.26 | ppl    70.58\n",
      "| epoch  20 | batch  1300/ 2250 | ms/batch  6.11 | loss  4.30 | ppl    73.37\n",
      "| epoch  20 | batch  1350/ 2250 | ms/batch  6.12 | loss  4.29 | ppl    72.86\n",
      "| epoch  20 | batch  1400/ 2250 | ms/batch  6.24 | loss  4.35 | ppl    77.52\n",
      "| epoch  20 | batch  1450/ 2250 | ms/batch  6.36 | loss  4.35 | ppl    77.66\n",
      "| epoch  20 | batch  1500/ 2250 | ms/batch  6.65 | loss  4.35 | ppl    77.79\n",
      "| epoch  20 | batch  1550/ 2250 | ms/batch  6.38 | loss  4.24 | ppl    69.27\n",
      "| epoch  20 | batch  1600/ 2250 | ms/batch  6.17 | loss  4.19 | ppl    66.31\n",
      "| epoch  20 | batch  1650/ 2250 | ms/batch  6.12 | loss  4.22 | ppl    68.03\n",
      "| epoch  20 | batch  1700/ 2250 | ms/batch  6.05 | loss  4.23 | ppl    68.59\n",
      "| epoch  20 | batch  1750/ 2250 | ms/batch  6.11 | loss  4.22 | ppl    68.13\n",
      "| epoch  20 | batch  1800/ 2250 | ms/batch  6.17 | loss  4.26 | ppl    70.55\n",
      "| epoch  20 | batch  1850/ 2250 | ms/batch  6.17 | loss  4.27 | ppl    71.34\n",
      "| epoch  20 | batch  1900/ 2250 | ms/batch  6.07 | loss  4.27 | ppl    71.69\n",
      "| epoch  20 | batch  1950/ 2250 | ms/batch  6.19 | loss  4.34 | ppl    76.40\n",
      "| epoch  20 | batch  2000/ 2250 | ms/batch  6.12 | loss  4.27 | ppl    71.56\n",
      "| epoch  20 | batch  2050/ 2250 | ms/batch  6.11 | loss  4.27 | ppl    71.39\n",
      "| epoch  20 | batch  2100/ 2250 | ms/batch  6.09 | loss  4.25 | ppl    69.97\n",
      "| epoch  20 | batch  2150/ 2250 | ms/batch  6.27 | loss  4.26 | ppl    71.02\n",
      "| epoch  20 | batch  2200/ 2250 | ms/batch  6.20 | loss  4.32 | ppl    75.55\n",
      "| epoch  20 | batch  2250/ 2250 | ms/batch  6.24 | loss  4.31 | ppl    74.56\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  20 | time: 17.34s | valid ppl    73.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "=========================================================================================\n",
      "| End of training | test ppl    67.55\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "try:\n",
    "    best_val_ppl = float('inf')\n",
    "    print(\"Starting training...\")\n",
    "\n",
    "    val_ppls = []\n",
    "    train_ppls = []\n",
    "\n",
    "\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train(model, train_data, criterion, optimizer, seq_length)\n",
    "        val_ppl = evaluate(model, valid_data, criterion, seq_length)\n",
    "        train_ppl = evaluate(model, train_data, criterion, seq_length)\n",
    "\n",
    "        val_ppls.append(val_ppl)\n",
    "        train_ppls.append(train_ppl)\n",
    "        \n",
    "        print('-' * 89)\n",
    "        print(f'| end of epoch {epoch:3d} | time: {(time.time() - epoch_start_time):5.2f}s | '\n",
    "              f'valid ppl {val_ppl:8.2f}')\n",
    "        print('-' * 89)\n",
    "        \n",
    "        # Save the model if validation performance improves\n",
    "        if val_ppl < best_val_ppl:\n",
    "            best_val_ppl = val_ppl\n",
    "            torch.save(model.state_dict(), 'best_rnn_model.pth')\n",
    "            print(f\"New best model saved with perplexity: {val_ppl:8.2f}\")\n",
    "\n",
    "    # Load best model and evaluate on test set\n",
    "    try:\n",
    "        model.load_state_dict(torch.load('best_rnn_model.pth'))\n",
    "        test_ppl = evaluate(model, test_data, criterion, seq_length)\n",
    "        print('=' * 89)\n",
    "        print(f'| End of training | test ppl {test_ppl:8.2f}')\n",
    "        print('=' * 89)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading best model: {e}\")\n",
    "        print(\"Evaluating with current model instead.\")\n",
    "        test_ppl = evaluate(model, test_data, criterion, seq_length)\n",
    "        print('=' * 89)\n",
    "        print(f'| End of training | test ppl {test_ppl:8.2f}')\n",
    "        print('=' * 89)\n",
    "\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    # Plot learning curves\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Plot Validation and Train Perplexity\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, num_epochs + 1), val_ppls, label='Validation Perplexity')\n",
    "    plt.plot(range(1, num_epochs + 1), train_ppls, label='Train Perplexity')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Perplexity')\n",
    "    plt.title('Perplexity')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
